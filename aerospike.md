
![aerospike_logo_set_horizontal2.png](aerospike_logo_set_horizontal2.png)

# 구조(ARCHITECTURE)

## 개요(Overview)

#### 시스템 개요

에어로스파이크는 분산,확장가능한 NoSQL입니다. 이것은 3가지 주요 목적으로 설계되었습니다:

* 요즘의 웹 규모 어플리케이션의 요구를 만족시키는 유연하고,확장가능한 플랫폼을 생성하기 위해서

* 기존 데이터베이스에서 기대하는 견고함과 신뢰성을 제공하기 위해서(즉,ACID)

* 운영 효율성을 제공하기 위해서(최소 설명서 관여)

[2011년에 VLDB의 절차](http://www.aerospike.com/docs/architecture/assets/vldb2011.pdf)에 처음으로 게시된 에어로스파이크 구조는 3계층으로 구성:

1. 클러스터 인식 [클라이언트 계층](http://www.aerospike.com/docs/architecture/clients.html)은 에어로스파이크 APIs와 트랙노드를 구현하고 데이터가 클러스터에 존재하는 곳을 아는 오픈 소스 클라이어트 라이브러리를 포함합니다.

2. 자기관리 [클러스터링](http://www.aerospike.com/docs/architecture/clustering.html)과 [데이터 분산 계층](http://www.aerospike.com/docs/architecture/data-distribution.html)는 클러스터 통신을 감독하고 페일오버,복제,크로스 데이터 센터를 자동화합니다.

3. 플래시 최적화된 [데이터 스토리지](http://www.aerospike.com/docs/architecture/storage.html) 계층은 확실하게 데이터를 DRAM과 플래시에 저장합니다.

##### 클라이언트 계층

에어로스파이크 "스마트 클라이언트"는 속도를 위해 설계되었습니다. 이것은 C,C#,Java,PHP에서 사용가능한 오픈 소스 링크 라이브러리로 구현되고,개발자들은 새로운 클라이언트 기여나 필요에 따라 그들을 변경해도 좋습니다. 클라이언트 계층은 다음과 같은 기능을 가집니다:

* 에어로스파이크 API,클라이언트-서버 프로토콜을 구현하고 직접 클러스터에 논의합니다.

* 노드를 추적하고 데이터가 저장되는 곳,바로 클러스터 설정의 변화의 학습 또는 노드가 오르내릴때를 압니다.

* 효율성을 위해 자신의 TCP/IP 연결 풀을 구현합니다. 또한 클러스터의 노드 실패 수준까지 오르지않는 트랜젝션 실패를 감지하고 데이터의 복사본을 지닌 노드에 그 트랜젝션을 재전송합니다.
* 확실하게 요청을 바로 데이터를 가진 노드에 전송하고 재시도하거나 필요에 따라 요청을 재전송합니다. 하나의 예는 클러스터가 재설정하는 것입니다.

이 구조는 트랜젝션 지연시간을 줄이고,클러스터에서 작업을 없애고 개발자를 위한 작업을 제거합니다. 이것은 또한 노드가 나오거나 사라질때 어플리케이션이 재시작할 필요가 없음을 보장합니다. 마지막으로, 이것은 설정하고 추가의 클러스터 관리 서버나 프록시를 관리하는 요구를 제거합니다.

##### 분산 계층

에어로스파이크 "아무것도 공유되지 않은" 구조는 자동 페일오버,복제 그리고 크로스 데이터 센터 동기를 지닌 데이터의 테라바이트를 확실하게 저장하도록 설계되었습니다. 이 계층은 선형적으로 크기를 조정하고 많은 [ACID 보장](http://www.aerospike.com/docs/architecture/acid.html)을 구현합니다. 이 분산 계층은 또한 모든 클러스터 관리 기능의 체계적인 자동화를 지닌 수동 작업을 제거하도록 설계되었습니다. 이것은 3개의 모듈을 포함:

* **클러스터 관리 모듈**은 클러스터의 노드를 추적합니다. 주요 알고리즘은 클러스터의 부분으로 간주되는 어느 노드를 결정하는 합의 투표 프로세스 같은 Paxos입니다. 에어로스파이크는 노드간의 연결을 감시하는 특별한 하트비트(능동 및 수동)를 구현합니다.
* 노드가 추가되거나 제거되고 클러스터 멤버쉽이 확인될때, 각 노드는 기본 인덱스 공간을 데이터 '조각'으로 나누고 소유자를 할당하는 분산된 해쉬 알고리즘을 사용합니다. 그 다음에 **데이터 이동 모듈**은 지능적으로 클러스터 노드간에 데이터의 분산의 균형을 맞추고, 시스템의 설정된 복제 요소에 의해 지정되도록 각 데이터의 조각이 노드와 데이터 센터간에 복제되는 것을 보장합니다.

> 분산은 시스템이 마스터없이 크기 조정하고 조각난 환경에서 요구되는 추가 설정의 필요를 제거하는,순수하게 알고리즘입니다.(Division is purely algorithmic, the system scales without a master and eliminates the need for additional configuration that is required in a sharded environment.)

* **트랜젝션 처리 모듈**은 데이터를 요구에 따라 읽고 쓰고 많은 일관성과 분리 보장을 제공합니다. 이 모듈은 1,2,3에 대해 책임이 있습니다.

 1. **동기/비동기 복제**: 즉각적인 일관성을 지닌 쓰기를 위해서, 이것은 데이터를 커밋하고 클라이언트에 결과를 반환하기전에 모든 복제본에 변화를 전파합니다.
 2. **프록시**: 클러스터가 재구성하는 드문 경우에 클라리어트 계층이 잠시 데이터 밖으로 나갈때, 이것은 확실하게 다른 노드의 요청을 프록시합니다.
 3. **복제 해결**: 클러스터가 분산된 후 회복될때, 이것은 다른 데이터의 복사본사이에 발생하는 모든 충돌을 해겹합니다. 해결책은 다음으로 구성됩니다.

   * 마지막 타임스탬프를 지닌 데이터가 기본인 경우,자동
   * 데이터의 두 복사본이 더 높은 수준의 해결을 위해 어플리케이션에 반환되는 경우,유저 기반

==클러스터링==

![architecture-cluster.png](architecture-cluster.jpg)

너가 첫번째 클러스터 업을 가질때, 너는 선택적으로 다른 데이터 센터에 추가 클러스터를 설치하고 [크로스 데이터 센터 복제](http://www.aerospike.com/docs/architecture/xdr.html)를 설정할 수 있습니다- 이것은 너의 데이터 센터가 내려갈때, 원격 클러스터가 유저의 최소한으로나 아무 방해없이 작업량을 인수받는걸 보장합니다.

##### 데이터 저장 계층

에어로스파이크는 스키마없는 [데이터모델](http://www.aerospike.com/docs/architecture/data-model.html)을 가진 키-값 저장소 입니다. 데이터는 의미상으로 RDBMS 시스템의 ==데이터베이스==와 비슷한,==네임스페이스==라고 불리는 정책 컨테이너로 구성되어 있습니다. 네임스페이스내에서, 데이터는 ==세트==(==테이블==과 비슷한)와 ==레코드==(==열==과 비슷한)로 세분화됩니다. 각 레코드는 세트에서 고유한 인덱스된 ==키==와 하나 이상의 레코드와 연관된 값을 보유하는 ==빈==(행과 비슷한)을 가집니다.

* 세트와 빈은 먼저 정의될 필요는 없지만, 최대 유연성을 위해 실행시간동안 추가될 수 있습니다.
* 빈의 값은 강하게 입력되고, 지원된 [데이터타입](http://www.aerospike.com/docs/guide/data-types.html) 중 하나를 포함할 수 있습니다. 빈은 스스로 입력될수 없어서, 다른 레코드는 다른 타입의 값을 가진 동일한 빈을 가질 수 있습니다.

인덱스([기본키](http://www.aerospike.com/docs/architecture/primary-index.html)와 [보조키](http://www.aerospike.com/docs/architecture/secondary-index.html))는 초고속 접근을 위해서 DRAM에 저장되고 값은 DRAM이나 더 효율적인 비용을 가지는 SSDs에 저장됩니다. 각 네임스페이스는 따로따로 설정될 수 있어서, 작은 네임스페이스는 DRAM을 이용하고 더 큰 네임스페이스는 SSDs의 비용 이익을 얻습니다.

> 데이터 계층은 특히 속도와 하드웨어 비용의 극적인 감소를 위해서 설계됩니다. 이것은 캐싱 계층의 요구를 제거하면서 모든 인메모리형태로 작동하거나 플래시 저장을 위해 고유의 최적화를 이용할 수 있습니다. 두 경우에, 데이터는 전혀 손실되지 않습니다.

* 100만 키는 오직 6.4GB만 차지합니다. 비록 키가 아무 크기 제한이 없더라도, 각 키는 효율적으로 오직 64바이트에만 저장됩니다.
* 기존,멀티 스레드된,멀티 코어 플래시 I/O와 **에어로스파이크 로그 구조된 파일 시스템**은 저수준의 SSD 읽기 및 쓰기 패턴을 이용합니다. 게다가, 디스크에 쓰기는 지연시간을 최소화하기 위해 큰 블록에서 작업됩니다. 이 메커니즘은 역사상 회전 디스크에 조정된 표준 파일 시스템을 건너뜁니다
* 또한 내장은 **스마트 조각 모음**과 **지능형 에빅터(Evictor)**입니다. 이런 프로세스는 DRAM에 공간이 있음을 보장하기 위해 같이 작업하고 그 데이터는 절대 손실되지 않고 안전하게 디스크에 기록됩니다.

  * 조각모음은 각 블록의 활성 레코드의 수를 추적하고 사용의 최소 수준보다 떨어지는 블록을 회수합니다.
  * 에빅터는 만기된 레코드를 제거하고 시스템이 세트 하이 워터 마크 이상으로 얻을때 메모리를 회수합니다. 유효 시간은 네임스페이스당 설정되고, 레코드의 연도는 이것이 마지막으로 개정된 시간에서 계산되고, 어플리케이션은 언제든지 기본 수명시간을 오버라이드하고 레코드가 쫓겨나지 않게 지정됩니다.

##### 에어로스파이크 작업

기존(분산되지 않은) RDBMS에서, 데이터베이스 소프트웨어를 설치후 너는 데이터베이스 스키마를 설정하고 데이터베이스와 테이블 정의를 생성할 수 있습니다. 에어로스파이크 데이터베이스를 가진 프로세스는 매우 다릅니다.  

분산된 데이터베이스에서, 데이터는 클러스터의 모든 서버중에 하나로 분산(분할)됩니다. 이것은 너가 단순히 서버로 로그하지 않고 한곳에서 너의 데이터의 전부를 접근하는 걸 의미합니다.  

에어로스파이크 데이터베이스에서, 너는 데이터베이스를 생성/관리:

* 초기 데이터베이스 설정을 구성함으로써, 에어로스파이크 문법에서, 데이터베이스는 네임스페이스라고 불리고 시스템을 설치할때, 클러스터의 어떻게 데이터베이스가 생성되고 복제되는지를 지정하는 설정된 각 네임스페이스를 가져야합니다. 너가 서버를 재시작할때 데이터베이스는 생성됩니다,여기에 나와있듯이.
* 어플리케이션을 통해 데이터베이스 작업을 수행함으로써. 데이터베이스 스키마는 너의 어플리케이션이 처음으로 너의 어플리케이션에 의해 사용되는 세트와 빈(테이블과 필드)을 언급할때 생성됩니다. 에어로스파이크 데이터베이스는 플렉스 스키마입니다-먼저 데이터베이스 스키마를 정의할 필요가 없습니다. 예를들어, 새로운 빈(필드)을 추가하기 위해서, 어플리케이션은 단순히 지정된 빈에 데이터를 저장하는 걸 시작합니다. 에어로스파이크 데이터베이스에서, 명령줄 인터페이스를 통한 DBA에 의해 보통 수행되는 작업은 어플리케이션을 통해 수행됩니다.
* 필요에 따라 설정 파일을 업데이트함으로써. 네임스페이스 파라미터를 바꾸기위해서, 너는 단순히 극적으로(재시작 없이)또는 새로운 설정 파일을 가진 서버를 재시작함으로써 설정 파일을 업데이트합니다.

에어로스파이크는 좋은 성능과 중복을 제공하기위해 필요한 노드의 수를 결정하도록 계획되고 설정되고, [용량 계획](http://www.aerospike.com/docs/operations/plan/capacity/index.html) 자원을 확인하세요.  

너는 [관리 지원 프로그램](http://www.aerospike.com/docs/amc/index.html)과 [감시하는 도구](http://www.aerospike.com/docs/operations/monitor/index.html)를 사용하는 클러스터의 노드를 감시하고 관리할 수 있습니다. 너는 클러스터에 노드를 추가하거나 업그레이드/서비싱을 위해 노드를 치우고 클러스터는 자동으로 자신을 재설정합니다. 노드가 실패할때, 클러스터의 다른 노드들은 작업량의 균형을 맞추고 거기에서 마지막 유저에게 최소한의 영향을 줍니다.

##### 어플리케이션 구축

네임스페이스가 생성될때, 에어로스파이크는 데이터베이스가 정확하게 데이터를 저장하는지 확인하는 도구를 제공합니다(데이터베이스의 작업을 확인하는 방법에 대한 설명서를 확인하세요). 그러나,생산 데이터베이스에서, 데이터는 클러스터에 분산됩니다. 데이터베이스 작업을 수행하기 위해서, 너는 너의 어플리케이션을 예시로 둔 스마트 클라이언트를 통해 작업해야 합니다.(In order to perform database operations, you need to work through the smart client that instantiates with your application.) 스마트 클라이언트는 작업에 영향을 끼치지 않고 클러스터에 데이터를 저장/회수하는 방법을 알고 인식하는 장소입니다.  

에어로스파이크는 빅 데이터 어플리케이션을 구축하는 여러가지의 언어로 APIs를 제공합니다. APIs의 개요는 클라이언트 가이드에 있습니다.  

너가 어플리케이션을 컴파일할때, API 라이브러리는 스마트 클라이언트와 함께 포함되어 있습니다. 스마트 클라이언트는 작동중인 클러스터 상태를 감시하는 스레드/프로세스로 주어진 시간에 데이터가 어디에 있는지를 결정하기 위해서 분리됩니다. 스마트 클라이언트의 위치 인식은 대부분의 경우에 데이터가 단일 홉의 노드에서 회수되는 걸 보장합니다.  

우리가 빅 데이터 어플리케이션을 참조할때, 우리는 일반적으로 웹서버에 위치하는 어플리케이션을 참조합니다, 이와 같이:

![ARCH_user_mw_as.png](ARCH_user_mw_as.png)

스마트 클라이언트는 데이터 분산의 자세한 내용을 무시하는 어플리케이션을 허용합니다. 더 자세한 내용을 위해서, 구조 가이드를 확입합니다.

> 이 문서에서, 우리는 용어 API와 통합된 너의 어플리케이션과 교환할 수 있는 클라이언트를 사용합니다-에어로스파이크는 또한 스마트 클라이언트와 통합됩니다.

## 데이터 관리

#### 데이터 관리

##### 개요

에어로스파이크는 향상된 키-값 작업을 지원합니다. 기본 put() 과 get() 작업에 비해, 에어로스파이크는 "CAS"(안전한 읽기/수정/쓰기) 작업, 인데이터베이스 카운터,그리고 멤캐시 작업을 지원합니다. 데이터는 빈(기존 관계형 시스템의 열과 유사한)으로 구성됩니다, 각 빈은 타입을 가집니다. 그 타입은 정수,스트링,바이너리 객체,또는 언어 직렬화 객체가 될 수 있습니다.  

데이터 관리 포함:

* 행이 입력된 키-값 작업과 증가와 같은 인데이터베이스 작업
* 고 가용성을 위한 데이터 복제
* 열 단위의 퇴거 정책
* 원활한 업그레이드와 클러스터 크기 변경
* 플래시(SSD) 최적화
* 크로스 데이터센터 복제(XDR)

에어로스파이크는 아래의 있는 걸 포함하기 위해 확장됨:

* 빈의 [복잡한 데이터 타입](http://www.aerospike.com/docs/guide/data-types.html)(중첩된 리스트와 맵)
* 스트링과 빈 수치 값이 인덱스되는 [쿼리](http://www.aerospike.com/docs/guide/query.html)와  균등(스트링 또는 수치) 또는 범위(수치)에 의해 조사된 데이터베이스
* 에어로스파이크의 어플리케이션 코드를 실행함으로써 확장되는 데이터베이스 처리를 허용하는 [사용자 정의 함수](http://www.aerospike.com/docs/guide/udf.html)
* 레코드 무리가 사용자 정의 함수와 동작하고 반환된 값을 집계하는 [집계](http://www.aerospike.com/docs/guide/aggregation.html)
* 빈이 최적으로 저장된 매우 큰(1MB 에서 1GB) 스택,리스트,또는 맵인 데이터 구조를 포함하는 [큰 데이터 타입](http://www.aerospike.com/docs/guide/ldt.html)

### 데이터 모델

에어로스파이크는 데이터베이스에 저장된 데이터가 엄격한 스키마를 따르지 않는걸 의미하는 스키마없는 데이터모델을 가집니다.  

이것은 에어로스파이크에 데이터를 저장하는 방법의 유연성을 제공합니다-데이터에 대한 변경은 스키마 변경을 요구하지 않고 데이터베이스의 현재 데이터는 특정 스키마를 따를 필요가 없습니다.  

에어로스파이크의 스키마없는 모델은 플라이에 새로운 타입의 빈을 추가할 수 있습니다. 그러나 너는 여전히 빈 이름과 데이터를 저장하는 방법에 대해 훈련될 필요가 있습니다. 어플리케이션은 정확하게 작동하는 [쿼리](http://www.aerospike.com/docs/guide/query.html)와 [집계](http://www.aerospike.com/docs/guide/aggregation.html)를 위해서 항상 빈을 순서대로 사용해야 합니다.

##### 어떻게 데이터가 구성되는지

==저장소 구조==

![architecture-storage.jpg](architecture-storage.jpg)

##### 네임스페이스

네임스페이스는 데이터를 위한 최상위 컨테이너입니다. 네임스페이스는 사실상 데이터베이스의 부분이거나 표준 RDBMS의 그들로 생각할수 있듯이 데이터베이스의 그룹일 수 있습니다(A namespace can actually be a part of a database or it can be a group of databases as you would think of them in a standard RDBMS)-너가 데이터가 저장되고 관리되는 방법에 관한 네임스페이스로 데이터를 모으기 때문에  

네임스페이스는 레코드,인덱스,그리고 정책을 포함합니다. 정책은 아래내용을 포함하는 네임스페이스의 행동을 지시합니다:

* 데이터가 저장되는 방법: DRAM 또는 디스크
* 얼마나 많은 복제본이 레코드를 위해 존재해야 하는지.
* 언제 레코드가 만기되는지.

네임스페이스를 위해 사용가능한 설정에 대한 자세한 내용을 위해선, [네임스페이스 설정](http://www.aerospike.com/docs/operations/configure/namespace/)을 참고하세요.  

데이터베이스는 어플리케이션의 필요에 의존하는 다른 정책을 지닌 각각의 여러 네임스페이스를 지정할 수도 있습니다. 네임스페이스는 데이터를 RAM의 조각,디스크 나 파일인 저장 장치에 바인드하기 때문에 물리적 컨테이너로 간주됩니다.  

(아래의)표 1에서, 우리는 ==ns1==과 ==ns2==라는 두 개의 네임스페이스를 정의합니다. ==ns1== 네임스페이스는 디스크에 레코드를 저장하는 반면에, ==ns2== 네임스페이스는 RAM에 레코드를 저장합니다.

![model_namespace.png](model_namespace.png)

> 표1  
각각 다른 저장 엔진을 사용하는 두 네임스페이스가 정의됩니다

##### 세트

네임스페이스내에서, 레코드는 ==세트==라는 논리 컨테이너에 속할 수 있습니다. 세트는 컬렉션에 레코드를 그룹하는 어플리케이션 기능을 제공합니다. 세트는 그들이 속한 네임스페이스에 의해 정의된 정책을 상속받고 세트에 대한 구체적인 추가 정책을 정의할 수 있습니다.  

(아래의)표 2에서, 우리는 ==사람==과 ==장소==라는 두 개의 세트를 ==ns1== 네임스페이스에 추가합니다. 두 개의 세트는 타입에 기반한 레코드를 저장하는데 사용됩니다. 두개의 세트에 저장된 레코드에 더하여, 세트없이 네임스페이스에 일부 레코드가 있습니다.

![model_set.png](model_set.png) 

 >표2  
==사람==과 ==장소==라는 두 개의 세트는 ==프리머리==라는 네임스페이스를 위해 정의됩니다. 프리머리는 또한 세트에 속하지 않은 레코드를 포함합니다.

##### 레코드

에어로스파이크 데이터베이스는 열 저장소라서 초점은 개별 레코드(표준 RDBMS에서 열로 불리는)에 있습니다. 레코드는 데이터베이스에서 저장의 기본단위입니다. 앞에서 언급된 것과 같이, 레코드는 네임스페이스내에서 세트나 네임스페이스에 속할 수 있습니다. 레코드는 네임스페이스에서 레코드를 유일하게 식별하는데 사용되는 키를 통해 주소를 지정합니다.  

레코드는 다음으로 구성됩니다:  

부품 | 묘사 
----|------ 
키 | 레코드는 다이제스트(digets)라고 불리는 키의 해쉬를 통해 주소를 지정합니다. 
메타데이터 | 메타데이터는 레코드 버전(세대)과 타임-투-라이브(time-to-live)(ttl)에 대한 정보를 제공합니다. 
빈(필드) | 빈은 기본 RDBMS의 필드와 동등합니다.

##### 키/다이제스트

어플리케이션에서, 각 레코드는 이것과 연관된 키를 가질 수 있습니다. 이 키는 어플리케이션이 레코드를 읽거나 쓰기 위해 사용하는 것 입니다.  

그러나,키가 데이터베이스에 전송될때,키(세트 정보와 함께)는 160 비트 다이제스트로 해시됩니다. 데이터베이스내에서, 다이제스트는 모든 작업에 대한 레코드의 주소에 사용됩니다.  

다이제스트가 주로 데이터베이스의 레코드 주소 지정을 위해 사용될때, 키는 주로 어플리케이션에서 사용됩니다.  

키는 아마도 정수,스트링 또는 바이트 값입니다. 이러한 값에 대한 자세한 내용은 [데이터 타입](http://www.aerospike.com/docs/guide/data-types.html)에서 볼 수 있습니다.

##### 메타데이터

각 레코드는 아래에 나와있는 것을 포함하는 레코드 자체에 대한 메타데이터와 함께 저장됩니다:

* **세대**는 레코드가 변경된 횟수를 반영합니다. 이 숫자는 읽기의 어플리케이션에 다시 전달되고 기록된 데이터가 마지막으로 읽은 이후 수정되지 않은 걸 확인하는데 사용됩니다.
* **타임-투-라이브(TTL)**은 레코드가 존재하는 시간을 지정합니다. 에어로스파이크는 자동으로 그 TTL에 기반한 레코드를 만기합니다. 레코드의 TTL은 쓰기 작업이 객체에서 실행될 때마다 증가됩니다.

##### 빈

레코드내에서, 데이터는 하나이상의 빈에 저장됩니다. 빈은 이름과 값으로 구성됩니다. 빈이 타입을 지정하지 않는 대신에 타입은 빈에 포함된 값에 의해 정의됩니다.  

이 동적 타이핑은 데이터 모델에 많은 유연성을 제공합니다. 예를들어, 레코드는 =="밥"==의 스트링 값을 가지는 =="아이디"==라는 빈을 포함합니다. 빈의 값은 항상 다른 스트링 값으로 변경할 수 있지만, 또한 정수 ==72==와 같은 다른 타입의 값으로 변경할 수 있습니다.  

또한, 네임스페이스 또는 세트 내의 레코드는 아마 매우 다른 빈의 컬렉션으로 구성됩니다. 레코드에 대한 스키마가 없어서, 각 레코드가 완전히 다른 세트의 빈을 가지는 것이 가능합니다. 또한, 빈은 레코드의 수명시간에 언제든지 추가되거나 제거될 수 있습니다.  

최적화된 스트링-테이블 구현 때문에 네임스페이스내에서 현재 사용하는 빈 이름의 수에 제한이 있습니다. 그 제한은 32K개의 고유한 빈 이름입니다.  

빈의 값은 [기본 지원된 타입](http://www.aerospike.com/docs/guide/data-types.html)과 [LDTs](http://www.aerospike.com/docs/guide/ldt.html) 중 하나가 될 수 있습니다.

### 기본 인덱스

운영 데이터베이스에서, 가장 빠르고 예측 가능한 인덱스는 기본 키 인덱스여야 합니다. 이 인덱스는 데이터베이스의 열 정보를 위해 예측가능하고 제일 빠른 접근을 제공합니다.  

에어로스파이크의 기본 키 인덱스는 각 서버에서 분산된 트리 구조를 가진 분산된 해시 테이블 기술의 조합입니다. 네임스페이스(데이터베이스)에서 전체 키스페이스는 튼튼한 해시 기능을 사용하면서 ==파티션==으로 분할됩니다. 총 4096개의 파티션이 있고 클러스터의 노드에 동등하게 분산됩니다. 해싱과 파티셔닝에 대한 자세한 내용은 [데이터-분산](http://www.aerospike.com/docs/architecture/data-distribution.html)을 참고하세요.  

최하위 수준에서,인기있는 맴캐쉬 시스템에서 사용되는 데이터구조와 유사한 레드-블랙-인메모리 구조가 사용됩니다.  

기본 색인은 지정된 기본 키의 20바이트 해시(==다이제스트==라는 에어로스파이크 문법에서)에 있습니다. 일부 레코드의 키 크기를 확장하는 (예를들어,고유한 8 바이트 키를 가지는)동안에, 입력 키 크기나 입력 키 분산에 관계없이 코드가 예상한대로 작업하기 때문에 이것은 유익합니다.  

단일 서버가 실패할때,두번째 서버에 인덱스를 바로 사용할 수 있습니다. 실패된 서버가 다운되어 있을때, 데이터는 재균형을 시작합니다. 데이터의 균형을 재조정하는동안에,데이터가 도착할때 인덱스는 새로운 서버에서 계산됩니다.

##### 인덱스 메타데이터

각 인덱스 항목은 현재 64 바이트를 필요로 합니다. 다이제스트와 마찬가지로 다음의 메타데이터는 또한 인덱스에 저장됩니다.

* **쓰기 세대** - 또는 벡터 클럭: 이것은 시스템의 키에 모든 업데이트를 추적합니다. 이것은 충돌 업데이트를 해결하는동안에 사용됩니다
* **빈 시간** : 이것은 시스템의 키 수명을 추적합니다. 이것은 키가 만료된 시간이고 퇴거 서브 시스템에 의해 사용됩니다.
* **저장소 주소**: 데이터를 위한 저장소(인메모리와 지속성 모두)의 위치

##### 인덱스 지속성

처리량을 유지하기 위해서, 기본 인덱스는 저장소에 커밋되지 않습니다- 오직 RAM에만. 이것은 매우 높은 성능과 고도로 병렬하는 쓰기를 허용합니다. 데이터 저장소 계층은 또한 저장소를 사용하지 않도록 구성됩니다.  

에어로스파이크 서버가 시작할때, 이것은 저장소의 데이터를 통해 지나가고 모든 데이터 파티션을 위해 기본 인덱스를 생성합니다.

###### 빠른 재시작

다운타임없이 클러스터의 빠른 업그레이드를 지원하기 위해서, 에어로스파이크는 "빠른 재시작"이라는 특징을 지원합니다. 인덱스 목록은 공유된 메모리로 저장되는 메모리의 조각에서 할당됩니다. "빠른 재시작"이 설정될때, 인덱스 메모리는 리눅스 공유된 메모리 세그먼트에서 할당됩니다. 재시작 서버에 에어로스파이크의 계획된 차단과 재시작의 경우는(예를들어 업그레이드) 단순히 공유된 메모리 세그먼트를 붙이고 살아있는 기본 인덱스를 가져옵니다. 이것은 저장소에 아무 데이터 스캔을 필요로하지 않습니다.

##### 단일 빈 정수 최적화

값이 단일 정수인 키-값 항목을 저장하는 것은 매우 유용합니다. "단일 빈" 특징이 네임스페이스에 활성화될때-각 노드에 에어로스파이크 빈 구조를 지원하는 것보다 더 낮은 메모리 사용을 제공하는 것은- 더 최적화 할 수 있습니다. 저장된 값이 정수일때, 빈 정포를 가리키는 공간은 정수로 재사용됩니다. 이 특별한 경우에, 정수값을 위해 필요한 저장소의 양은 단순히 인덱스를 위해 필요한 공간입니다.

### 보조 인덱스

보조 인덱스는 많은 관계중 하나를 모델하는 기능을 제공하는 기본이 아닌 키에 있습니다. 인덱스는 빈-바이-빈(RDBMS에 행과 같은) 기본에 지정됩니다. 이것은 효율적인 업데이트를 가능하게 하고 인덱스를 저장하도록 요구되는 자원의 양을 최소화합니다.  

데이터 묘사(DDL)은 어느 빈과 타입을 인덱스할지 결정하는데 사용됩니다. 인덱스는 제공되는 도구 또는 API를 통해 극적으로 생성되거나 제거될 수 있습니다. RDBMS 스카마와 비슷하게 나타나는 이 DDL은 데이터의 검증을 위해 사용되지 않습니다- 인덱스된 것으로 빈이 DDL에 있지않더라도, 그 빈은 선택적입니다. 인덱스된 빈을 위해서, 빈을 포함하는 레코드를 갱신하는 것은 인덱스를 업데이트합니다.  

예를들어, 인덱스는 오직 스트링 또는 정수에서만 생성될 수 있습니다. 유저의 나이와 나이값을 저장하기 위해 너가 빈을 가지는 경우를 고려하는 것은 한 복제에 의한 스트링과 다른 어플리케이션에 의한 정수로 저장됩니다. 스트링 인덱스가 인덱스된 빈에 저장된 정수 값을 가진 레코드를 제외하는 동안에 정수 인덱스는 인덱스된 빈에 저장된 스트링 값을 포함하는 레코드를 제외합니다.  

보조 인덱스는 :

* 빠른 조회를 위해 RAM에 저장된
* 클러스터의 모든 노드에 구축과 기본과 동일한 위치에 배정됩니다. 보조 인덱스의 각 항목은 노드에만 로컬 레코드에 대한 참조를 포함합니다.
* 보조 인덱스는 마스터 레코드와 클러스터에 복제된 레코드 모두에 대한 포인터를 포함합니다.

##### 데이터 구조

![data_structure.jpg](data_structure.jpg)

> 표1  
B-트리를 지닌 보조 인덱스

에어로스파이크 기본 인덱스처럼, 보조 인덱스는 B-트리를 가진 해시 테이블의 조합입니다. 보조 인덱스는 구조적으로 B-트리의 해시입니다. 각 논리 보조 인덱스는 32개의 물리적 트리를 가집니다. 인덱스 작업을 위해 키를 구별할때, 해시 기능은 보조 인덱스 항목이 32개의 물리적 트리에서 만들어질 필요가 있는 어떤 물리적 트리를 결정하는데 사용됩니다. B-트리를 식별한후 업데이트는 트리에 만들어집니다, 단일 보조 인덱스 키에 해당하는 많은 주요 레코드 참조가 있다는 점을 주목하세요. 따라서, 이 구조의 최하위 수준은 저장할 필요가 있는 레코드 수에 기반한 B-트리의 모든 목록입니다.

##### 인덱스 관리

###### 인덱스 메타데이터

에어로스파이크는 어떤 인덱스가 특별하게 전세계적으로 유지되는 데이터 구조에 생성되는지에 대한 정보를 유지합니다-시스템 메타데이터(SMD) 시스템. 시스템 메타데이터 모듈은 여러 노드에 여러 보조 인덱스 모듈의 중간에 있습니다. 결국 보조 인덱스에서 만들어진 변화는 항상 SMD에서 트리거됩니다.

![index_metadata.jpg](index_metadata.jpg)

> 표1  
보조 인덱스는 시스템 메타 데이터에서 트리거됩니다.

1. 클라이언트 요청은 보조 인덱스 메타데이터와 관련된 생성/제거/업데이트를 생성합니다. 요청은 SMD에 보조 인덱스 모듈을 거쳐 통과됩니다.
2. SMD는 paxos 마스터애 요청을 보냅니다.
3. Paxos 마스터는 클러스터의 모든 모드에서 적절한 메타데이터 정보를 요청합니다. 모든 데이터를 받을때, 이것을 보조 인덱스 병합 콜백 기능이라고 부릅니다. 이 기능은 위닝 메타데이터 버전을 해결하는 책임이 있습니다.
4. 위닝 버전이 보조 인덱스에 대해 결정할때, 요청은 새로운 메타데이터 정보를 받아들이기 위해 모든 노드에 전송됩니다.
5. 각 노드는 보조 인덱스 생성/제거 DDL 기능을 수행하고나서, 스캔을 트리거하고 클라이언트에 응답합니다.

###### 인덱스 생성

에어로스파이크는 보조 인덱스의 동적 생성을 지원합니다. ==aq1==과 같은 도구는 현재 사용가능한 인덱스를 읽을 수 있고 인덱스의 생성과 파괴를 허용합니다.  

1. 보조 인덱스를 구축하기 위해서, 유저는 네임스페이스,세트,빈 그리고 인덱스의 타입을 지정할 필요가 있습니다(예를들어, 정수,스트링,등등.).
2. **SMD**에서 확인을 받는 경우에(위를 확인), 각 노드는 쓰기-활성 모드에 보조 인덱스를 생성하고 모든 데이터를 스캔하고 보조 인덱스로 항목을 넣는 백그라운드 스캔 작업을 시작합니다.

  * 인덱스 항목은 모든 인덱스 사양과 일치하는 레코드를 위해서만 생성됩니다.
  * 보통 스캔과 달리 인덱스 생성 스캔에 네트워크 구성요소가 없다고 생각하면서, 보조 인덱스가 있는 스캔 작업은 보통의 스캔이 하는 것과 정확히 같은 방법으로 읽기/쓰기 트랜젝션과 상호 작용합니다.(The scan job that populates the secondary index will interact with read/write transactions in exactly the same way a normal scan would, except there is no network component to the index creation scan unlike for the normal scan.) 인덱스 생성 기간동안에, 인덱싱 속성에 영향을 끼치는 모든 새로운 쓰기는 인덱스를 업데이트합니다.

3. 인덱스 생성 스캔이 완성되고 모든 인덱스 항목이 생성되자마자, 인덱스는 바로 쿼리에서 사용할 준비를 하고 읽기-활성으로 표시됩니다.
4. 보조 인덱스는 인덱스가 모든 노드에 성공적으로 생성된 후에 보통의 쿼리를 위해 사용할 수 있습니다.

**추천**  

* 인덱스 DDL(인덱스를 생성/드롭)은 클러스터가 잘 형성되지 않을때나 클러스터가 무결성 오류가 발생할때를 방지해야합니다. 인덱스 구축은 I/O 서브시스템에 모진 작업이라서, 낮은 로드 시간에서 수행되야 합니다.
* 데이터를 지닌 노드가 클러스터에 합류되지만 없어진 인덱스 정의를 가질때, 없어진 인덱스는 생성되고 클러스터가 합류되는 위치에 덧붙여집니다. 인덱스 이동동안에, 쿼리는 이것에 허용되지 않습니다. 이런 상황을 예방하기 위해서, 들어오는 노드의 데이터는 이것이 시작되기 전에 정리해야합니다.

###### 인덱스 우선순위 생성

인덱스 생성 스캔은 이미 트랜젝션에서 커밋된 레코드만을 읽습니다(더티 읽기 아님). 이것은 스캔이 최고 스피드에서 실행되고, 읽기를 막는 레코드의 업데이트가 없다는 걸 의미합니다. 그러므로 인덱스 생성 스캔이 진행중인 읽기와 쓰기 트랜젝션의 지연시간에 불리하게 영향을 끼치지 않는걸 보장하기 위해 적절한 수준에서 인덱스 구축 우선순위를 설정하는 것이 중요합니다. 에어로스파이크 실시간 엔진에서 작업의 우선순위 설정은 효율적으로 인덱스 생성 스캔의 자원 이용을 제어하는데 사용됩니다. 그것들이 데이터의 균형을 재조정하는 것과 낮은 지연시간에 맞서 읽기/쓰기 트랜젝션을 백업하는 것과 같은 장시간 실행하는 작업의 균형을 맞추는 배치 경험에 기반하기 때문에 기본 설정은 대부분의 시간에 충분합니다.

##### 인덱스를 가진 데이터 쓰기

데이터가 서버에 기록될때, 현재 인덱스의 시스템 메타데이터(SMD)사양은 체크됩니다. 인덱스를 지닌 모든 빈을 위해서, 보조 인덱스 업데이트/삽입/제거가 수행됩니다. 에어로스파이크가 플렉스-스키마 시스템이라는 걸 주의하세요. 특정 빈을 위한 값이 없거나 빈 갑이 인덱스된 타입이 아닐때, 그 해당하는 보조 작업은 수행되지 않습니다.  

보조 인덱스의 이런 모든 변화는 자동으로 단일 잠금 동기 아래 레코드 변경을 가지고 수행됩니다. 인덱스가 유지되지 않기때문에, 인덱스와 데이터 커밋의 다른 커밋 문제는 속도를 올리면서 제거됩니다.

##### 가비지 컬렉션

데이터가 기본(예를들어, 제거/만기/퇴거/이주)에서 삭제될때 데이터는 보조 인덱스의 항목을 제거하기 위해서 디스크에서 읽지 않습니다. 이것은 I/O 서브시스템에 필요없는 짐을 놓는 걸 방지합니다. 보조 인덱스에 왼쪽 항목은 정기적으로 일어나고 클린업을 수행하는 백그라운드 스레드에 의해 제거됩니다. 가비지 컬렉터는 복잡하지 않게 설계됩니다. 이것은 작은 배치에서 제거될 항목의 목록을 생성하고나서 천천히 인덱스에서 그들을 제거합니다. 이것은 만기와 퇴거의 최대량을 가지는 시스템에, 가비지 컬렉션을 수용하기 위해 보조 인덱스에 대한 메모리의 공급 이상을 요구합니다.

##### 분산된 쿼리

![query_diagram.png](query_diagram.png)

보조 인덱스에서 결과를 회수하는 쿼리는 모든 클러스터 노드에 전송됩니다. 기본 구조는 다음 페이지에 있는 표 B에서 설명되고 그 단계는 다음과 같습니다:

1. 모든 노드에 "흩뿌리다" 요청
2. 기본 키에 빠른 2차 매핑을 위한 RAM의 인덱스
3. ACID를 관리하고 이주를 관리하기 위해 SSDs에 데이터를 지닌 각 노드와 동일한 위치를 가지는 인덱스
4. 모든 SSDs/DRAM에서 병렬로 레코드 읽기
5. 각 노드에 결과를 전파
6. 클라이언트에 모든 노드에서 결과를 "모으다"

보조 인덱스 검색은 기본 키 레코드의 아주 긴 목록을 평가할 수 있습니다. 이런 이유로, 우리는 작은 배치에서 보조 인덱스 검색을 하기 위해 선택합니다. 또한 메모리 한계점에 도달했을때, 응답은 바로 네트워크에 플러시되도록 클라이언트의 응답에 일부 배치가 있습니다. 이것은 에어로스파이크 배치 요청의 반환 값과 비슷하게 행동합니다. 일반적인 아이디어는 쿼리의 선택성에 관계없이 개별 보조 검색의 메모리 사용을 일정한 크기로 유지하는 것입니다.

##### 쿼리 결과

쿼리 프로세스는 결과가 쿼리가 실행되고 레코드가 스캔되는 시간에 실제 데이터를 가지는 동기에 있는 걸 보장합니다. 쿼리 프로세스가 커밋되지 않는 동안에 그 어디에도 데이터 읽기가 쿼리의 부분으로 발생하지 않습니다. 그러나, 쿼리는 삭제된 데이터를 스스로 반환할 수 있습니다.

###### 클러스터 상태 변화의 존재

다음 테이블은 재구성된 보조 인덱스와 쿼리 결과의 일관성 시나리오를 설명합니다.

시나리오 | 영구적인 네임스페이스 부트 타입 | 데이터-인-메모리 | 보조 인덱스 생성 | 노드 부트 시간 | 이동하는동안 쿼리의 일관성
-------|------------------------------|--------------|-----------------|--------------|----------------------
노드가 합류 | 빠른 재시작없이 데이터를 가지는; | 거짓 | 디스크에서 데이터 로드를 게시; 병렬 데이터 파티션 스캔 | 보조 인덱스가 없는 것보다 더 높은 데이터 로드 시간 | 최선*
노드가 합류 | 빠른 재시작을 지닌 데이터를 가지는;(공유된 메모리에 기본 키 인덱스 사용가능한) | 거짓 | 빠른 재시작 게시; 병렬 데이터 파티션 스캔** | 보조 인덱스가 없는 것보다 더 높은 데이터 로드 시간 | 최선*
노드가 합류 | 빠른 재시작 없이 데이터를 가지는; | 참 | 디스크의 데이터로드에 | 보조 인덱스 유무의 큰 차이 없음 | 최선*
노드가 합류 | 항상 빠른 재시작없이 데이터를 가지지 않는; | 참/거짓 | -NA- | -NA- | 일관된 복사
노드가 떠남 | -NA- | 참/거짓 | -NA- | -NA- | 일관된 복사

> **최선**은 업무적으로 반드시 최신이 아닌 일관된 데이터의 복사입니다(중복 레코드 복사의 존재에서,합병은 보조 인덱스 쿼리에서 결과가 반환되기 전에 수행되지**않습니다**). 모든 이주가 완료된 후에 이것은 항상 최신의 일관성된 복사입니다.  
> **빠른 재시작**은 보조 인덱스를 위해 지원되지 않습니다.

정상 작동 환경 아래, 노드는 클러스터에서 완전한 쿼리 가용성을 가지고 단순히 추가되고 제거될 수 있습니다. 데이터가 디스크에서 로드될때 그리고 이주가 일어날때 에어로스파이크는 데이터 로딩을 다룹니다(결과 일관성을 위해 테이블을 참조).

##### 쿼리 노드

데이터 이동동안 정확환 쿼리 결과를 얻는 것은 복잡합니다. 노드가 클러스터에서 추가되거나 제거될때, 데이터 이동 모듈은 노드의 트랜젝션을 위해 데이터를 언급합니다(When a node is added or removed from the cluster, the Data Migation Module is invoked to transition the data to and from nodes as appropriate for the new configuration). 이런 이주 활동 동안에, 파티션은 많은 노드의 다른 버전에서 사용할 수 있습니다. 요구된 데이터를 가지는 파티션의 위치를 찾는 쿼리를 위해, 에어로스파이크 쿼리 처리는 클러스터의 노드간에 공유되는 추가의 파티션 상태를 이용하고, 쿼리가 실행되고 있는 각 파티션을 위해 **쿼리 노드**의 신중한 선택을 만듭니다. 주어진 파티션에 대한 쿼리 노드는 다양한 요소에 기반해서 선택됩니다(예를들어, 파티션의 레코드 수,클러스터에 존재하는 파티션의 복제수,등등). 여기서의 목표는 가장 정확한 쿼리의 결과를 얻는 것이고 시스템은 그것을 하기위해 설계됩니다.

##### 전파

쿼리 레코드는 필터,전파,등등을 수행하기 위해 전파 프레임워크로 제공할 수 있습니다. 각 노드에서, 쿼리 결과는 레코드의 스트림으로 결과의 처리를 시작하기 위해 UDF 서브 시스템에 전송됩니다. 유저에 의해 언급된 스트림 UDF는 적용되고 유저에 의해 정의된 작업의 순서는 쿼리 결과에 적용됩니다. 각 노드의 결과는 데이터에 추가 작업을 수행하는 클라이언트 어플리케이션에 의해 수집됩니다.

###### 성능

전파가 전반적인 데이터베이스 성능에 영향을 주지 않는걸 보장하기 위해서, 우리는 다양한 기술을 사용:  

글로벌 큐는 다양한 처리 단계를 통해 공급되는 레코드를 관리하기 위해 사용되고 스레드 풀은 효과적으로 CPU 병렬화를 이용하기 위해 사용됩니다. 시스템이 적절히 스트림 UDF 파이프라인을 관리하도록 쿼리 상태는 전체 스레드 풀 사이에 공유됩니다. 초기 데이터 페치 부분을 제외하고 전파의 모든 단계는 CPU 바운드 작업이라는 걸 주의하세요. 그래서 여러 단계의 처리를 빠르고 최적으로 종료하는 것이 중요합니다. 이것을 가능하게 하기 위해서, 우리는 실시간 레코드를 처리하는 최대량의 시스템 오버헤드를 최적화하기 위해 레코드의 배칭,UDF 상태의 캐싱,기타등등과 같은 기술을 사용합니다.  

게다가, 인메모리에 저장된 데이터를 지닌 네임스페이스에서의 작업을 위해서(저장소 페치 없음), 스트림 처리는 단일 스레드 맥락에서 구현됩니다- 심지어 에어로스파이크가 기본적으로 데이터를 고정된 파티션 수로 나뉘기 때문에 시스템은 여전히 데이터 파티션에서의 작업을 병렬화할 수 있는 이런 경우에도

### 하이브리드 저장소

하이브리드 메모리 시스템은 각 노드에 저장된 인덱스와 데이터를 보유하고, 물리적 저장소와의 상호작용을 다룹니다. 이것은 또한 자동으로 데이터베이스에서 오래된 데이터를 제거하고 디스크 사용량을 최적화하기위해 물리적 저장소를 디프래그하는 모듈을 포함합니다.  

에어로스파이크는 데이터를 DRAM, 기존 회전 미디어,그리고 SSDs에 저장할 수 있고 각 네임스페이스는 따로따로 설정될 수 있습니다. 이 구성의 유연성은 자주 DRAM에 접근하는 작은 네임스페이스를 넣기위해 어플리케이션 개발자를 허용합니다,하지만 SSD와 같이 더 저렴한 저장소에는 더 큰 네임스페이스를 배치합니다.  

중요한 작업은 저수준의 SSD 읽기 및 쓰기 패턴을 이용하는 파일 시스템을 바이패싱하는 걸 포함하는 SSDs의 데이터 저장소를 최적화하기 위해 실시됩니다.

##### 철학

[큰 데이터 형식](http://www.aerospike.com/docs/architecture/ldt.html)외에,레코드에 대한 모든 데이터는 같이 저장되어 있습니다. 각 열에 대한 저장소의 양은 기본적으로 1MB 크기로 제한됩니다.  

저장소는 최적화 프로세스에 의해 재요구되는 자유 공간을 가진 copy-on-write 입니다.  

각 ==네임스페이스==는 저장소의 고정된 양으로 설정됩니다. 각 노드는 각 서버에 동일한 네임스페이스와 각 네임스페이스를 위한 동일한 저장소의 양을 가집니다.  

저장소는 순수한 지속성이없는 DRAM,저장소 지속성을 지닌 DRAM,또는 플래시 저장소(SSDs)를 사용하여 구성될 수 있습니다.  

영구적인 저장소(디스크)는 플래시 또는 다른 고성능 블록 저장소 장치(클라우드)중 하나이거나 또는 저장 장치에 파일일 수 도 있습니다.  

##### DRAM의 데이터

지속성없이 순수하게 DRAM의 데이터는 더 높은 처리량의 이익을 가집니다. 현대의 플래시 저장소가 매우 높은 성능이더라도, DRAM은 더 높은 성능이고, DRAM의 조각은 하락하고 있습니다.  

데이터는 ==JEMalloc== 할당자를 통해 할당됩니다. ==JEMalloc==은 다른 풀로 할당을 허용합니다. 저장소 계층에 대한 것과 같은 긴 시간 할당은 따로따로 할당될 수 있습니다. 우리는 ==JEMalloc==할당자가 낮은 조각화에 관하여 우수한 속성을 가지는 걸 발견합니다.  

DRAM의 여러 복사본을 사용함으로써, 매우 높은 수준의 신뢰성을 얻을 수 있습니다. 에어로스파이크가 자동으로 다시 조각나고 데이터를 실패 또는 클러스터 노드 추가에 복제하기 때문에 높은 수준의 "k-안전"을 얻을 수 있습니다. 온라인에서 노드를 가져오는 것은 자동으로 복사본 중 하나에서 이것의 데이터를 생성합니다.  

에어로스파이크의 랜덤 [데이터 분산](http://www.aerospike.com/docs/architecture/data-distribution.html)때문에, 일부 노드가 손실될때 데이터 비가용성은 매우 작을 수 있습니다. 예를들어, 데이터의 두 개 복사본을 가지는 10개의 클러스터 노드에서, 두 노드가 빨리 손실될때, 복제가 약 2%가 되기전에 데이터 비가용성의 양은 데이터의 1/50입니다.  

지속성 계층이 설정될때, 읽기는 항상 DRAM 복사에서 발생합니다. 쓰기는 아래에서 묘사된 데이터 경로를 통해 발생합니다.  

##### SSD/플래시의 데이터

데이터가 작성될때, 쓰기 래치는 열마다 동일한 레코드에서 충돌하는 두 쓰기를 피하기 위해 사용합니다. 어떤 클러스터 상태에서, 데이터는 다른 노드와 해결된 충돌에서 읽을 필요가 있습니다.  

쓰기가 입증된 후에, 레코드의 인메모리 표현은 마스터에 업데이트됩니다. 작성된 데이터는 쓰기 버퍼에 추가됩니다. 쓰기 버퍼가 꽉 찰때, 이것은 디스크에 대기하고 있습니다. 최대 열 크기와 쓰기의 처리량과 동일한 쓰기버퍼의 크기에 따라, 커밋되지 않은 데이터의 일부 위험이 있습니다.  

복제가 있을때, 그들은 업데이트되고 또한 그들의 인메모리 인덱스들도 업데이트됩니다. 데이터가 모든 인메모리 복사에 업데이트된 후에, 결가는 클라이언트에 반환됩니다.  

시스템은 모든 쓰기 지연된 일관성 전에 클라이언트에 결과를 반환하도록 설정될 수 있습니다.

##### 데이터 저장

에어로스파이크의 데이터는 정수,스트링,블롭(blob),선천적으로 직렬화된 타입,목록,맵,그리고 [LDTs](http://www.aerospike.com/docs/architecture/ldt.html)를 포함합니다.  

조금 더 효율적인 "단일 빈 모드"외에, 에어로스파이크의 열인 빈은 각각 스트링 테이블을 사용하여 저장되는 빈 이름을 가집니다. 행의 이름은 한 번 저장되지만, 네임스페이스에서 사용되는 고유한 빈 이름은 오직 32K개가 있습니다.  

더 많은 빈 이름이 필요하면, 맵을 사용하는 걸 고려해보세요. 맵에서, 너는 키-값 쌍의 임의의 세트를 저장할 수 있고, 효율성을 위해 UDF의 그 값에 접근할 수 있습니다.  

너가 자바에서 너의 클래스처럼 복잡한 언어 타입을 데이터 콜에 전달할때, 에어로스파이크 클라이언트는 언어의 고유 직렬화 시스템을 사용할 수 있습니다. 그 데이터는 특정 언에어서 "블롭 타입"으로 저장됩니다. 이것은 클린 코드를 지닌 데이터를 읽는 같은 언어의 클라이언트를 허용하지만, 대부분 언어의 기본 직렬자는 안 좋습니다.  

정수는 현재 버전에서 정수 값을 제한하는 8 바이트 양으로 저장됩니다. 에어로스파이크 네트워크 프로토콜은 다양한 크기의 정수를 허용하고 확장을 가능하게 합니다.  

스트링은 UTF-8로 저장됩니다. UTF-8은 유니코드보다 많은 스트링에 대해 더 컴팩트합니다. 크로스 언어 호환성을 허용하기 위해서, 클라이언트 라이브러리는 기존 문자 세트에서 유니코드를 UTF-8,과 백으로 전환합니다.(In order to allow cross-language compatibility,client libraries convert from the native character set unicode,to UTF-8,and back)  

최대 효율은 바이너리 객체(블롭)으로 사용할 수 있습니다. 이들은 오직 레코드 크기에 의해서만 크기가 제한됩니다. 많은 배치는 자신의 직렬 변화기를 사용하고 아마 그 객체를 압축하고 그 객체를 바로 저장합니다. 이렇게하면 데이터가 쉽게 UDF를 통해 접근할 수 없음을 의미합니다.  

복잡한 타입은 로컬 저장소를 위해 ==msgpack==으로 제공됩니다. 복잡한 객체는 클라이언트에 직렬화되고, 무선의 프로토콜을 사용해서 전송됩니다. 단순한 겟 및 풋 작업을 사용할때, 네트워크 포맷은 직렬화 또는 전환 없이 저장소에 바로 작성됩니다.

##### 플래시 최적화

조각모음은 디스크에 각 블록의 활성 레코드 수를 추적하고 사용의 최소 수준보다 떨어지는 블록을 재사용합니다. 조각모음 시스템은 지속적으로 사용가능한 블록을 스캔하고 일정 양 이상의 블록을 바랍니다.

##### 저장소에 기반한 퇴거

조각모음은 디스크에 각 블록의 활성 레코드 수를 추적하고 사용의 최소 수준보다 떨어지는 블록을 재사용합니다. 에빅터는 만기된 레코드에 참조를 제거하고 시스템이 세트 하이 워터 마크이상으로 얻을때 메모리를 재사용하는 것에 대해 책임이 있습니다. 네임스페이스를 설정할때, 관리자는 네임스페이스의 데이터를 위한 기본 수명뿐만 아니라 그 네임스페이스를 위해 사용되는 DRAM의 최대량을 지정합니다. 일반 작업아래, 에빅터는 메모리의 인덱스를 해제하고 디스크에 레코드를 풀어주면서 만기된 데이터를 찾습니다. 메모리가 설정된 하이 워터 마크를 초과할때 만기된 레코드가 필요없더라도, 에빅터는 또한 네임스페이스에서 사용되는 메모리를 추적하고 더 오래된 것을 방출합니다. 시스템이 그것의 메모리 제한을 칠때 에빅터가 이전 데이터를 제거하도록 함으로써 에어로스파이크는 효과적으로 LRU 캐쉬로 사용될 수 있습니다. 레코드의 시대는 이것이 수정된 마지막 시간에서 측정되고 어플리케이션은 레코드에 데이터를 쓰는 기본 수명시간에 언제든지 오버라이드 할 수 있습니다. 어플리케이션은 또한 특정 레코드가 절대 자동으로 퇴거되지 않는 시스템을 말합니다.

##### 큰 레코드

큰 레코드는 다른 방법으로 저장되지만, 단일 레코드 제한 이상으로 가는 데이터를 허용합니다. [큰 데이터 타입 구조](http://www.aerospike.com/docs/architecture/ldt.html)를 참조하세요.

### 대규모 데이터 타입

큰 데이터 타입(LDTs)는 제한이 사용가능한 저장소에 기반하고 레코드의 최대량에 기반하지 않는 데이터의 매우 큰 양을 포함하기 위해 개별 기록을 허용합니다.  

에어로스파이크 LDT 기능은 우리가 "서브-레코드"로 언급하는 에어로스파이크 유저 정의 함수 메커니즘과 새로운 저장소 타입을 이용합니다. 서브-레코드는 그들이 부모 레코드와 연결된 주요 예외를 뺀 정규 에어로스파이크 기록과 매우 비슷합니다. 그들은 부모 레코드와 동일한 파티션 주소와 내부 기록 잠금을 공유해서, 그들은 이동하는 동안에 그들의 부모 레코드를 가지고 이동하고 그들은 부모 레코드와 같은 분리 메커니즘 아래에 보호됩니다.  

에어로스파이크 큰 객체는 연관된 레코드와 인접하여 저장되지 않지만, 대신에 표 1에서 보이는 것처럼 서브 레코드(약 2Kb 에서 32Kb 범위의 크기를 가진)로 분할딥니다. 서브 레코드는 같이 인덱스되고 링크되고 유저 정의 함수(UDFs)를 통해 인-데이터베이스를 관리합니다.

![Record_with_without_LDT.png](Record_with_without_LDT.png)

> 표1  
큰 데이터 타입이 있거나 없는 레코드

표1은 에어로스파이크 데이터베이스 레코드의 두가지 예를 보여줍니다. 왼쪽은 3개의 빈을 가지는 보통의 레코드입니다. 오른쪽은 LDT 빈에서 증가한 것과 같은 레코드입니다. 에어로스파이크는 큰 스택(lstack), 큰 세트(lset), 큰 리스트(llist) 그리고 큰 맵(lmap) 같이 몇개의 큰 데이터 타입을 정의하기 위해 UDFs를 사용합니다.  

아래에서 설명되듯이,서브 레코드 관리의 모양과 스타일은 특정 LDT 컬렉션 타입에 의존합니다.  

에어로스파이크는 몇개의 큰 데이터 타입을 정의하기 위해서 사용: 큰 스택(lstack), 큰 세트(lset), 큰 리스트(llist) 그리고 큰 맵(lmap). 이런 객체는 클라이언트 사이드 APIs를 사용하여 서버에 인-데이터베이스를 처리합니다.  

특정 LDT 작업(예를들어, 100바이트 삽입)의 비용만 지불하고 전체 LDT를 업데이트하는 비용(예를들어, 100 메가바이트)과 클라이언트와 서버사이의 전체 LDT를 이동하는 비용은 지불하지 않는 동안 LDTs는 매우 큰 데이터의 컬렉션을 관리하기 위해서 새로운 레코드 빈 타입과 새로운 서브-레코드 저장소 컨테이너 타입을 이용합니다.  

새로운 LDT 특징은 새로운 특별한 빈 타입과 새로운 저장소 컨테이너에 의해 가능하게 됩니다. 새로운 특별한 빈 타입은 직접적인 방법으로 접근할 수 없는 "LDT 빈" 이지만, 대신에 시스템 LDT 기능에서만 접근할 수 있습니다. LDT 빈은 LDT 인스턴스의 설정과 레이아웃을 정의하는 복잡한 제어 구조(==ldtCtrl==라는)를 포함합니다([LDT 내부](http://www.aerospike.com/docs/guide/ldt_internals.html)섹션은 복잡한 ==ldtCtrl== 구조를 포함합니다.). 파일 시스템 인덱스 노드(inode)가 파일에 대한 저장소 블록을 설명하는 복잡한 객체로 구성된 유닉스-스타일 파일 시스템 같이, 에어로스파이크 LDT 구조는 LDT 컬렉션에 대한 설정과 저장소 컨테이너를 설명합니다.  

LDT 제어 구조는 LDT 컬렉션 경우에서 사용되는 설정과 저장소 컨테이너를 설명합니다. 저장소 컨테이너는 "서브-레코드"라고 불리는,레코드의 새로운 타입입니다. 서브-레코드는 그들이 부모 레코드에 연결되는 주요 예외로 보통의 에어로스파이크 레코드와 매우 비슷합니다. 서브-레코드는 내부 레코드 잠금과 같은 다른 자원뿐만 아니라 그들의 부모와 동일한 파티션 주소를 공유합니다. 그들이 잠금을 공유하기 때문에, 그들은  부모 레코드와 같은 분리 메커니즘아래 보호됩니다. 서브 레코드는 이동하는 동안에 부모 레코드를 가지고 이동합니다. 따라서, LDT 객체는 균형을 재조정하는 에어로스파이크의 튼튼한 복제와 고가용성과 즉각적인 일간성을 보장하는 이동 메커니즘을 이용합니다. LDT 객체는 클라이언트 사이드 APIs를 사용하여 서버에 인데이터베이스를 처리합니다.  

표1에서 보여주는 것과 같이, 에어로스파이크 LDT 객체는 여러 서브레코드로 구성됩니다(대략 2kb 에서 1mb 범위의 크기를 지닌). 서브 레코드는 같이 인덱스되고 링크되고 [유저 정의 함수](http://www.aerospike.com/docs/architecture/udf.html)(UDFs)를 통해 인-데이터베이스를 관리합니다. 서브레코드의 사용은 LDT 인스턴스에 대한 접근이 전형적으로 전체 레코드 빈 값보다 단일 서브 레코드에 영향을 끼치는 걸 의미합니다.

##### 서브레코드

서브레코드는 부모 레코드에 연결되는 레코드입니다. 부모 레코드는 어플리케이션이 저장하고 회수하기 위해 데이터와 상호 작용하는 일반 레코드입니다. 일반 레코드와 달리, 서브레코드는 바로 접근할 수 없습니다. 대신에, 서브레코드는 일반 (부모) 레코드를 통해서만 접근될 수 있습니다.  

부모 레코드와 서브 레코드를 사용하여, 링크된 데이터 구조는 데이터의 큰 양을 저장하기 위해 생성됩니다. 이것을 트리로 보면, 부모 레코드는 트리의 뿌리 노드이고 각 서브레코드는 트리의 브랜치나 나뭇잎 노드입니다. 아무 브랜치나 나무잎에 접근하기 위해서, 너는 루트에서 시작해야 합니다.  

서브레코드가 부모 레코드와 인접하게 저장되있지 않더라도, 부모 레코드와 같이 복제되고 이동하기 위해 서브레코드를 허용함으로써 그들은 부모 레코드와 동일한 파티션에 저장됩니다.

##### 대규모 스택

**대규모 스택 객체(lstack)**는 "나중에 들어간게 먼저 나오는(LIFO)"와 비슷한 노드를 따릅니다. 이것은 스택에 푸시된 대부분의 최신 아이템이 스택에서 팝되거나 피크되는 첫번째 아이템이라는 걸 의미합니다. 엄격한 시간에 기반한 것이 아닐지라도, 스택의 아이템 삽입 순서는 전형적으로 아이템이 생성되거나 발견되는 순서를 나타냅니다.(표 2a)

![LDT_Operations_LStack.png](LDT_Operations_LStack.png)

> 표 2a  
큰 스택 작동

클라이언트 사이드 LStack 기능에서 지시된 호출이더라도, 작업은 데이터베이스 서버에서 실행됩니다. 데이터의 큰 양은 이것이 클라이언트에 반환되기 전에 서버에 페치되고 필터될 수 있습니다.  

대규모 스택 데이터 저장소는 계층으로 구성되어 있습니다. 최상의 성능을 실현하기 위해서, 스택의 최상위에 접근하는 것이 가장 빠릅니다. "웜 데이터"는 하나의 I/O 간접 방식입니다. "콜드 데이터"는 두개의 I/O 간접 방식입니다.(표 2c)

![LDT_Logical_LStack.png](LDT_Logical_LStack.png)

> 표 2c  
핫,중간 그리고 콜드 데이터를 지닌 대규모 스택

물리적으로, lstack 구조는 다음과 같이 구성되어 있습니다(표 2d). LSTACK LDT 제어 구조는 설정 데이터,"핫 리스트" 데이터 항목, "웜 리스트" 서브 레코드 포인터와 "콜드 리스트" 디렉토리 체인 포인터를 보유합니다.  

"핫 리스트" 데이터는 부모 레코드에 바로 저장되기 때문에, 핫 리스트 데이터에 바로 접근합니다; 읽기 또는 쓰기에 관여하는 추기의 I/O가 없습니다. 크기는 유저의 필요에 맞게 설정할 수 있지만, 기본적으로 핫 리스트 크기는 100개의 객체입니다.  

부모 레코드는 또한 서브레코드 포인터의 목록인 "웜 리스트"를 포함합니다. 기본적으로 웜 리스트 크기는 100이고, 10000 객체의 웜 리스트 기본 용량을 제공하는 서브레코드 수용력도 100입니다. 핫 리스트와 마찬가지로, 이러한 모든 매개변수는 최적의 조화를 위해 관라자에 의해서 설정될 수 있습니다.

![LDT_Physical_LStack.png](LDT_Physical_LStack.png)

> 표 2d  
대규모 스택 물리적 레이아웃

마지막으로, 부모 레코드는 각 디렉토리가 데이터 서브레코드의 포인터를 포함하는 디렉토리를 포함하는 서브레코드의 목록에 링크된 콜드 데이터 디렉토리에 포인터를 포함합니다. 각 콜드 리스트 디렉토리 노드는 기본적으로 웜 리스트와 동등합니다. 스택 객체는 자연스럽게 핫 리스트에서 웜 리스트로 이동하고 시간이 지나선 콜드 리스트로 이동합니다. 이 계층 조직은 핫 리스트에 접근이 추가의 I/O 발생이 없고, 웜 리스트에 접근이 오직 하나의 추가 I/O가 발생하고 콜드 리스트에 접근이 두개 이상의 I/Os가 발생하는 걸 보장합니다.  

콜드 리스트의 크기가 바운드하지 않기 때문에, 대규모 스택 인스턴스는 어떤 크기의 제한이 없습니다. 또한, 데이터가 자연스럽게 핫에서 웜이나 콜드로 이동하기 때문에, 대규모 스택의 크기는 일정한 크기에 캡할 수 있습니다. 캡 이상으로 이동하는 데이터는 함축적으로 버려지고 서브레코드는 재사용됩니다.  

lstack의 컨텐츠는 핫,웜,콜드인 계층에 저장됩니다. "핫" 계층은 가장 최근에 작성된 데이터 아이템입니다. "핫" 계층이 가득찰때, 더 오래된 아이템은 "웜" 계층으로 푸시될 것입니다. "웜" 계층이 가득찰때, 더 오래된 아이템은 "콜드" 계층으로 푸시될 것입니다.

##### 대규모 세트

**대규모 세트 객체(lset)**는 고유한 객체의 컬렉션입니다(표 3a). 객체는 원자(예를들어, 숫자,스트링) 또는 복합체(예를들어, 맵,리스트)로 할 수 있습니다. lset는 요소가 존재하는지 여부를 결정하는 빠르고 효과적인 검색을 위해 인덱스를 유지합니다.

![LDT_Operations_LSet.png](LDT_Operations_LSet.png)

> 표 3a  
대규모 세트 작업

LSET LDT 제어 구조는 큰 맵 특유의 구성 설정과 큰 맵 해시 테이블을 포함합니다. 해시 테이블은 세트의 크기가 자라는 선형 해싱 알고리즘을 사용합니다.

![LDT_Physical_LSet.png](LDT_Physical_LSet.png)

> 표 3b  
대규모 세트 물리적 레이아웃

해시 테이블은 각 셀 상태가 다음 중 하나를 보여주는 셀을 포함합니다:

* 빈
* 짧은 리스트
* 단일 서브레코드
* 여러 서브레코드의 뿌리 트리

대규모 세트의 최대 크기가 최고 레코드의 LDT 빈에 있는 해시 테이블의 크기에 의존하기 때문에, 대규모 세트는 함축적으로 2GB보다 크지않은 사이즈에 바운드하고 다른 큰 값이 레코드에 있으면 아마 그것보다 더 적게 바운드합니다.  

대규모 세트 값은 내부 해시 테이블에 저장됩니다. 해시는 전체 객체(이것이 숫자나 스트링 같은 원자 타입일때)나 객체가 복합체일때(예를들어, 리스트 또는 맵) "스트링필드" 객체에서 계산됩니다; 또는 사용자가 적절한 "unique_identifier()" 기능을 지원할때 해시는 복합 객체의 서브세트에서 계산됩니다.

##### 대규모 정렬된 리스트

**대규모 정렬된 리스트 인스턴스(llist)**는 큰 규모로 분류된 목록을 관리합니다. 복합 객체에서 원자 값, 검색 키을 얻기 위해 사용가능한 방법이 있다는 조건하에 정렬된 목록의 객체는 원자(예를들어 숫자,스트링) 또는 복합체(예를들어 맵,리스트)가 될 수 있습니다(표 5a).

![LDT_Operations_LList.png](LDT_Operations_LList.png)

> 표 5a  
대규모 정렬된 리스트 작업

물리적으로, 대규모 리스트 구조는 다음과 같이 구성됩니다(표 5b). 대규모 리스트는 내부 트리 노드와 나뭇잎이 서브레코드인 B+트리에 구현됩니다. B+ 트리의 루트는 부모 레코드에 있습니다.

![LDT_Physical_LList.png](LDT_Physical_LList.png)

> 표 5b  
대규모 정렬된 리스트 물리적 레이아웃

B+ 트리 구조의 깊이에는 제한이 없습니다, 따라서 대규모 정렬된 리스트 인스턴스의 크기에도 제한이 없습니다.  

LLIST LDT 제어 구조는 대규모 리스트 LDT와 관련된 모든 정보를 포함합니다. 이것은 다음과 같은 정보를 포함:

* 사용자 모듈과 변형/비변형/필터/키 기능
* 키 타입
* 저장소 구성과 제한
* 루트,노드와 leaf 카운트
* 저장소 상태와 기준치
* 루트 값과 노드 포이터 배열(B+ 트리 루트 노드)

##### 대규모 맵

**대규모 맵 객체(lmap)**는 큰 규모를 제외하고 맵의 기본 이름/값/속성을 구현합니다(표 4a).

![LDT_Operations_LMap.png](LDT_Operations_LMap.png)

> 표 4a  
대규모 맵 작업

대규모 맵은 원자 이름 값(숫자,스트링)과 문서 또는 객체 값이 있는 사전 저장에 적합합니다.  

대규모 세트와 마찬가지로 LMAP LDT 제어 구조는 대규모 맵 고유의 구성 설정과 대규모 맵 해시 테이블을 포함합니다. 해시 테이블은 세트의 크기로 커지는 선형 해싱 알고리즘을 사용합니다(표 4b).   

해시 테이블은 각 셀 상태가 다음 중 하나를 보여주는 셀을 포함합니다:

* 빈
* 짧은 리스트
* 단일 서브레코드
* 여러 서브레코드의 라디스 트리

![LDT_Physical_LSet.png](LDT_Physical_LSet.png)

> 표 4b  
대규모 맵 물리적 뷰

대규모 맵의 최대 크기가 최고 레코드의 LDT 빈에 있는 해시 테이블의 크기에 의존하기 때문에, 대규모 맵은 함축적으로 2 기가바이트보다 크기 않은 사이즈에 바운드하고, 다른 큰 값이 레코드에 있을때 아마 그것보다 더 적게 바운드합니다.

##### 유용한 링크

* [LDT 특징 가이드](http://www.aerospike.com/docs/guide/ldt.html)
* [LDT 내부](http://www.aerospike.com/docs/guide/ldt_internals.html)

## 분산

에어로스파이크 데이터베이스는 항상 사용가능하고 신뢰성을 가지는 큰 데이터를 다루는 어플리케이션을 위해 기어합니다. 이것은 여러가지 영향이 있습니다:

* 너의 어플리케이션을 개발할때, 너는 데이터가 어디에 위치되는지에 대해 걱정할 필요가 없습니다. 클라이언트는 데이터 위치를 자동으로 감지하고 요청의 대다수가 단일 홉에 처리되는 걸 보장하고 에어로스파이크의 스마트 클라이언트는 클러스터 분산 문제를 처리합니다.
* 너가 용량을 추가하고 싶을때, 너는 단순히 클러스터에 노드를 추가하고 클러스터는 새로운 노드를 포함하기 위해 재조정합니다. 너가 용량을 추가할때 처리량과 성능 규모는 선형적으로 확장합니다.
* 실패의 한 포인트가 없습니다. 노드가 실패하거나 유지 또는 업그레이드를 위해 오프라인을 취할때 노드의 SSD는 실패할 수 있습니다.
* 전체 데이터 센터는 신뢰성에 영향을 주지 않고 실패할 수 있습니다.

확실하게 클러스터를 관리하는 것은 에어로스파이크 데이터베이스의 코어라서, 우리는 매우 중요하게 그 작업을 취해야 합니다. 에어로스파이크는 이것을 아래 나와있는 것에 의해서 실현합니다:

* [데이터 분산](http://www.aerospike.com/docs/architecture/data-distribution.html) : 에어로스파이크는 핫 스팟과 아무 수동 간섭없이 자동으로 재조정하는 데이터를 피하기 위해 데이터가 균일하게 분산되는 걸 확실히 하고 강력한 파티셔닝을 가집니다.
* [클러스터링](http://www.aerospike.com/docs/architecture/clustering.html) : 에어로스파이크는 자동으로 실패와 치유를 감지하는 능력을 가지는 클러스터된 데이터베이스입니다.
* **복제** : 에어로스파이크는 실패의 한 포인트를 피하기 위해 다음과 같은 복제 능력을 제공합니다.

   1. **인트라 클러스터 복제**
   2. [랙 인식 복제](http://www.aerospike.com/docs/architecture/rack-aware.html)
   3. [크로스 데이터 센터 복제](http://www.aerospike.com/docs/architecture/xdr.html)

### 데이터 분산

에어로스파이크 데이터베이스는 **아무것도 공유되지 않은** 구조를 가집니다: 에어로스파이크 클러스터의 모든 노드는 동일하고,모든 노드가 동료이고 실패의 단일 포인트가 없습니다.  

데이터는 에어로스파이크 스마트 파티션^tm^ 알고리즘을 사용하여 클러스터의 노드에 고르게 분배됩니다. 우리는 필드에 우리의 방법을 테스트해보고 이 랜덤 해시 기능은 파티션이 1-2% 에러 허용범위내에서 매우 고르게 분산되는 걸 보장합니다.  

레코드가 가는 곳을 결정하기 위해서, 레코드 키(아무 크기의)는 RIPEMD 160을 사용하여 20바이트로 고정된 길이 스트링에 해시됩니다. 그리고 첫번째 12비트는 어떤 파티션이 이 레코드를 포함할지 결정하는 파티션 아이디를 형성합니다. 파티션이 클러스터 노드 사이에서 균등하게 분산됩니다, 그래서 만약에 클러스터에 N개의 노드가 있으면, 각 노드는 약 데이터의 n분의 일을 저장합니다.  

데이터가 노드에 균등하게(무작위로) 분산되기 때문에, 한 노드가 다른 노드보다 더 많은 요청을 처리하는 핫스팟 또는 버틀넥이 없습니다.  

예를들어, 미국에서, R로 시작하는 많은 성이 있습니다. 알파벳순으로 데이터가 저장되면, R로 시작하는 성을 다루는 서버는 x,y또는 z로 시작하는 성을 다루는 서버보다 더 많은 트래픽을 가집니다. 데이터의 무작위 할당은 서버 로드가 균형하다고 보장합니다.  

확실성을 위해서, 에어로스파이크는 하나이상의 노드에 파티션을 복제합니다. 한 노드는 파티션에 대해 읽기와 쓰기를 위한 데이터 마스터가 되고 다른 노드들은 복제본을 저장합니다.  

예를들어, 4-노드 에어로스파이크 클러스터에서, 각 노드는 대략 데이터의 1/4에 대한 데이터 마스터이고 데이터의 1/4을 위한 복제본입니다. 한 노드가 데이터 마스터인 파티션은 복제본으로 다른 모든 노드에 분산됩니다. 그래서 이 예에서, 노드 #1이 사용할 수 없을대, 노드 #1에서 복제본은 다른 모든 노드 3개에 분산됩니다.

![ARCH_shared_nothing.png](ARCH_shared_nothing.png)

> 복제 인자는 설정 매개변수입니다. 이것은 너의 클러스터의 노드 수를 초과할 수 없습니다. 더 많은 복제본은 더 많은 확실성을 의미하지만, 쓰기 요청과 같은 클러스터에 더 높은 수요는 모든 데이터의 복제본에 가야합니다. 사실, 대부분의 배치는 복제 요소 2개로 사용합니다(하나의 마스터 복사와 하나의 복제본).

동기 복제는 즉각적인 일관성과 데이터의 손실 없음을 보장합니다. 쓰기 트랜젝션은 데이터를 커밋하고 클라이언트에 결과를 반환하기 전에 모든 복제본에 전파합니다. 클러스터가 재구성하는 드문 경우에 이것이 잠시 데이터 밖에 있기때문에 에어로스파이크 스마트 클라이언트^tm^가 잘못된 노드에 요청을 전송할때 에어로스파이크 스마트 클러스터^tm^은 확실하게 오른쪽 노드에 요청을 프록시합니다. 마지막으로, 클러스터가 분산된 후 복구할때, 이것은 데이터의 다른 복제본 사이에서 발생하는 모든 충돌을 해결합니다. 해결책은 최신 타임스탬프를 가지는 데이터가 표준이거나 데이터의 두 복사본이 더 높은 수준의 해결책을 위해 어플리케이션에 반환할 수 있는 경우에 자동으로 구성할 수 있습니다.

##### 에어로스파이크가 파티션을 생성하는 방법

에어로스파이크 데이터베이스의 네임스페이스는 같은 방법으로 저장되는 데이터의 컬렉션입니다. 각 네임스페이스는 4096개의 파티션으로 나뉘고 파티션은 클러스터 노드 사이에 동등하게 나뉩니다. 이것은 클러스터에 n개의 노드가 있을때, 각 노드는 데이터의 1/n까지 저장하는 걸 의미합니다.  

우리는 랜덤 해싱 방법을 파티션이 균등하게 분산되는 걸 보장하기 위해 사용합니다. 우리는 필드에 우리의 방법을 테스트해봤고 데이터는 1-2%의 오류 허용 범위내에서 고르게 분산합니다.  

데이터가 노드에 고르게(임의로) 분산되기 때문에, 한 노드가 다른 노드보다 더 많은 요청을 처리하는 핫스팟 또는 버특넥이 없습니다.  

예를들어, 미국에서, R로 시작하는 많은 성이 있습니다. 데이터가 알파벳순으로 저장되면, R로 시작하는 성을 다루는 서버는 X,Y,또는 Z로 시작하는 성을 가지는 서버보다 더 많은 트래픽을 가집니다. 데이터 임의 할당은 서버 로드가 균등한 걸 보장합니다.  

다음에, 수동 조각은 필요하지 않습니다. 클러스터의 노드는 파티션을 나누기 위해서 스스로 조정합니다. 클라이언트는 클러스터 변화를 감지하고 올바른 노드에 요청을 전송합니다. 노드가 추가되거나 제거될때, 클러스터는 자동으로 재조정합니다. 클러스터의 모든 노드는 동료입니다- 실패하고 전체 데이터베이스를 치우는 하나의 데이터베이스 마스터 노드가 없습니다.  

데이터베이스가 레코드를 생성할때, 레코드 키의 해시는 파티션에 레코드를 할당하는데 사용됩니다. 해싱은 결정적입니다-즉, 해싱 프로세스는 항상 동일한 파티션에 지정된 레코드를 맵합니다. 데이터 레코드는 그들의 전체 생활을 위해 동일한 파티션에 남아있습니다. 파티션은 하나의 서버에서 다른 서버로 이동하지만, 파티션은 기본으로 레코드를 다른 파티션에 분할 또는 재할당하지 않습니다.

> 클러스터의 각 노드는 설정 파일을 가집니다. 네임스페이스 설정 매개변수는 각 노드에 대해서 동일합니다.

#### 데이터가 어떻게 근처에 복제/동기 되는지

##### 복제본을 가지지 않는 에어로스파이크 클러스터

4개의 노드 클러스터의 경우를 생각해보자. 에어로스파이크 데이터베이스에서, 복제 요소 = 1로 언급되는 복제된 데이터가 없는 것은, 데이터베이스의 단일 복제본이 없다는 걸 의미합니다.  

총 4096 파티션과 클러스터에 4개의 노드가 있기때문에, 각 노드는 데이터의 1/4(임의로 할당되는 1024개의 파티션)을 가집니다. 클러스터는 파티션의 컬렉션을 관리하는 각 서버/노드를 가지는 아래 그림과 같이 보입니다(단순히, 두개 노드의 파티션만 보여줌):

![ARCH_no_repl.png](ARCH_no_repl.png)


각 노드는 데이터 파티션의 1/4에 대한 데이터 마스터입니다- 이것이 그 데이터의 읽기 및 쓰기에 관한 기본 소스라면 노드는 데이터 마스터입니다.  

클라이언트는 데이터에 대한 위치 인식을 가집니다- 클라이언트는 각 파티션이 위치한 곳을 압니다- 그ㅐ서 데이터는 노드 단일 홉에서 검색됩니다. 모든 읽기 및 쓰기 요청은 처리를 위해 데이터 마스터에 전송됩니다. 스마트 클라이언트가 레코드를 읽을때, 이것은 바람직한 레코드에 대한 데이터 마스터인 노드에 요청을 전송합니다.

##### 복제본을 가지는 에어로스파이크 클러스터

복제된 데이터의 경우를 고려해보자. 가장 흔한 경우는 마스터와 복제인 데이터의 두 복사본을 유지하는 것입니다. 에어로스파이크 데이터베이스에서, 이것은 복제 요소 = 2로 참고됩니다.  

이 경우에, 각 노드는 데이터의 1/4(1024 파티션)을 위한 데이터 마스터이고 각 노드는 데이터의 1/4(1024 파티션)을 위한 복제본입니다. 그래서 이것은 이것과 같습니다: (다시,간단하게 하기 위해서, 두 개의 노드를 자세하게 보여줍니다.)

![ARCH_repl2.png](ARCH_repl2.png)

한 데이터 마스터에 대한 데이터는 복제본으로 다른 모든 노드에 분산됩니다. 즉,예를들어, 노드 #1이 데이터 마스터인 파티션은 복제에 대한 클러스터의 다른 모든 노드에 분산됩니다. 노드 #1이 사용가능하지 않은 상황에서, 노드 #1에서 데이터의 복제본은 다른 모든 노드에 분산됩니다.  

이전에 복제되지 않은 예시와 동일한 방식에서, 클라이언트는 처리하기 위해서 읽기 및 쓰기 요청을 데이터 마스터에 전송합니다.  

비 복제된 상항에서, 읽기 요청은 스마트 클라이언트에 의해서 올바른 노드에 전송됩니다. 또한 쓰기 요청도 올바른 노드에 전송됩니다. 노드가 쓰기 요청을 받을때, 이것은 데이터를 저장하고 복제 노드에 쓰기 요청을 전달합니다. 복제 노드가 그 데이터가 성공적으로 기록되고 노드가 스스로 데이터를 기록된걸 확인한후 승인은 쓰기 작업을 성공적으로 하는 클라이언트에 전송됩니다.  

> 복제 인자는 너의 클러스터의 노드수를 초과할 수 없습니다. 더 많은 복제본은 더 좋은 신뢰성을 의미하지만, 쓰기 요청과 같은 클러스터에 더 높은 요구는 모든 데이터의 복사본에 가야합니다. 사실, 대부분의 데이터베이스는 2개의 복제요소를 가집니다.

##### 자동 데이터 재조정

수동 조각이 없습니다.  

에어로스파이크의 데이터 재조정 메커니즘은 쿼리 용량이 모든 노드에 균등하게 분산되는 걸 보장합니다,그리고 스스로 재조정하는 동안에 발생하는 노드 실패의 경우를 튼튼하게합니다. 시스템은 지속적으로 사용할 수 있도록 설계되서 데이터의 재조정은 클러스터 행동에 영향을 주지 않습니다. 트랜젝션 알고리즘은 데이터 분산 시스템과 통합되고 클러스터 변화를 조정하는 유일한 합의 투표가 있습니다. 유일한 한 투표에서, 클라이언트가 새로운 클러스터 설정을 발견하는 동안에 클러스터 내부 재지시 메커니즘이 사용되는 짧은 시간이 있습니다. 따라서, ACID 특성을 유지하는 동안에 이 메커니즘은 확장가능한 조각된 환경이 없는 곳에서 트랜젝션의 단순 최적화합니다.  

에어로스파이크는 노드 사이에 데이터를 재조정하는 것과 같은 관리 작업을 위해 얼마나 사용가능한 운영 오베헤드가 사용되는지 지정하기 위해 구성 옵션을 허용합니다.(Aerospike allows configuration options to specify how much available operating overhead should be used for administrative tasks like rebalancing data between nodes as compared to running client transactions) 트랜젝션 스피드와 용량이 유지되어야 하는 예에서, 클러스터는 더 느리게 재조정합니다.  

몇가지 경우에서, 복제 요소는 충족되지 않습니다. 클러스터는 복제 요소 감소와 모든 데이터 유지 또는 처리하도록 표시된 가장 오래된 데이터 퇴거를 시작하도록 설정될 수 있습니다. 클러스터가 더 많은 데이터를 받아들일 수 없을때, 이것은 새로운 용량이 사용가능할 때까지 읽기 전용 모드에서 작업을 시작합니다- 이것이 자동으로 어플리케이션 쓰기를 받아들이는 시점에  

운영자 개입을 요구하지 않음으로써, 클러스터가 요구하는 시간에 스스로 치유합니다. 한 클러스터 배치에서, 랙 회로 브레이커는 8개의 노드 클러스터 중 하나를 제거합니다. 아무 운영자 개입은 필요하지 않습니다. 정전이 데이터 센터에 대해 절정이더라도, 트랙젝션은 완전한 ACID 충실도로 계속했습니다. 몇시간에,  실패가 올바르게 되고 고질적인 랙이 온라인으로 다시 돌아올때, 오퍼레이터는 에어로스파이크 클러스터를 유지하기 위해 특별한 단계를 수행할 필요가 없습니다.  

우리의 용량 계획과 모니터링 시스템은 너에게 서비스의 손실없이 실제로 예상치못한 실패를 처리하는 능력을 제공합니다. 너는 설정하고 하드웨어 용량을 제공하고 복제/동기화 정책을 설정하도록 데이터베이스는 유저에게 영향을 주지 않고 실패를 복구합니다.

##### 트래픽 포화 다루기

피크 트래픽 로드를 처리하기 위해 요구되는 네트워크 하드웨어의 자세한 논의는 이 문서의 범위를 초과합니다. 에어로스파이크 데이터베이스는 너한테 버틀넥을 평가하는 감시 툴을 제공합니다. 네트워크가 버틀넥일때 데이터베이스는 용량에서 실행되지 않고 요청은 느려집니다.  

##### 용량 오버플로우 다루기

우리는 용량 계획,저장소 관리 그리고 저장소가 오버플로우되지 않았다고 보장하는 클러스터 감시에 대한 제안을 많이 가집니다, 하지만 이것이 없는 경우에, 에어로스파이크는 그만 쓰기 제한에 도달합니다-더 이상 새로운 레코드를 받아들이지 않는 이 경우에. 하지만 데이터 업데이트 및 읽기는 계속 처리됩니다.  

즉, 심지어 최적 용량을 초과해도, 데이터베이스는 처리중인 요청을 중지하지 않습니다, 이것은 처리중인 사용자 요청을 유지하기 위해 가능한 대로 실행을 계속합니다.

### 클러스터링

에어로스파이크의 항시 안정적인 보장은 클러스터 실패와 클러스터를 개혁하는 상황에서의 빠른 회복을 감지하는 능력을 가지고 시작합니다.  

사용자로서,클러스터를 설정하기 위해서, 너는 먼저 단일 노드를 설치합니다. 그 다음에 단순히 필요한 대로 추가적인 노드를 추가합니다.  

##### 하트비트

그들이 스스로 조정할 수 있도록 클러스터의 노드는 [하트비트](http://www.aerospike.com/docs/operations/configure/network/heartbeat/)를 통해 서로서로를 추적합니다. 노드는 쌍입니다- 모든 노드가 클러스터의 다른 노드들을 추적하는 마스터인 노드가 없습니다. 노드가 추가되거나 제거될때, 이것은 하트비트 메커니즘을 사용하여 클러스터의 노드에 의해서 감지됩니다. 에어로스파이크는 클러스터를 정의하는 두 가지 방법이 있습니다

1. 이 경우에 멀티캐스트 IP인 **멀티캐스트** : 포트는 하트비트 메세지를 브로드캐스트하는데 사용됩니다.
2. 이 경우에 한 에어로스파이크 서버의 주소인 **메시**는 클러스터를 합류하는데 사용됩니다.

##### 고속 분산된 합의

클러스터 변경이 발견될때, 모든 살아있는 노드는 클러스터에서 어떤 노드를 결정하는 합의 투표 프로세스와 자동으로 파티션을 재할당하고 재조정하는 에어로스파이크 스마트 파티션^tm^ 알고리즘과 같은 Paxos를 사용합니다. 해싱 알고리즘은 결정적입니다- 즉, 이것은 항상 동일한 파티션에 주어진 레코드를 맵합니다. 파티션이 한 서버에서 다른 서버로 이동할지라도 데이터 레코드는 그들의 전체 생활을 위해 동일한 파티션에 머뭅니다.  

에어로스파이크 시스템의 모든 노드는 중대한 공유 상태의 최소한의 합의를 보장하기 위해 사용되는 분산된 합의 알고리즘인 Paxos에 참여합니다. 이 공유 상태의 가장 중대한 부분은 클러스터에 참여하는 노드의 목록입니다. 따라서, 노드가 도착하거나 출발할때마다, 합의 알고리즘은 합의에 도달한 걸 보장하기 위해 실행합니다. 이 프로세스는 잠깐 사용합니다.(This process takes a fraction of a second) 합의가 달성된 후에, 각 개별 노드는 참여자와 클러스터내의 순서에 모두 동의합니다. 이 정보를 사용하면서 모든 트랜젝션의 마스터 노드는 복제 노드와 같이 계산될 수 있습니다.  

모든 트랜젝션에 대한 중요한 정보는 계산할 수 있기 때문에, 트랜젝션은 더 간단하고 입증된 데이터베이스 알고리즘을 사용할 수 있습니다. 이것은 오직 노드의 최소 서브세트만을 포함하는 최소 지연시간 트랜젝션의 결과입니다.

##### 클러스터링의 이득

에어로스파이크는 데이터 안정성을 보장하는 분산 처리를 사용합니다. 이론적으로, 많은 데이터베이스는 실제로 큰 SSD를 가진 단일 서버에서 필요한 모든 처리량을 얻을 수 있습니다(우리는 우리의 랩의 단일 서버에서 백만 TPS를 얻습니다). 그러나 이것은 모든 중복성을 제공하지 않고 서버가 다운될때, 모든 데이터베이스 접근은 멈출 수 있습니다. 그래서 더 일반적인 설정은 여러 SSD 장치를 가지는 각각의 노드를 지닌 여러 노드입니다.  

소유의 총 비용(TCO)다운을 유지하기 위해서, 에어로스파이크는 일반적으로 다른 데이터베이스보다 더 적은 서버에서 실행합니다. 우리는 너가 최적의 중복을 얻는 배치를 계획하는 걸 도와줄 수 있습니다(한 서버가 중복성과 안정성을 제공하는 데 충분하지 않지만, 유지 골칫거린인 백개의 서버는 유지하는 데 더 어려움이 있고 실패의 더 많은 포인트를 가지고 있습니다.). 우리의 분산된 비공유 구조는 노드가 스스로 관리하고 트래픽 증가에 따라 클러스터를 확장하기 쉬운 동일한 시간동안에 사용자에게 정전이 없다는 걸 보장하기 위해 조정하는 걸 의미합니다.  

스마트 클라이언트 소프트웨어를 가지고(에어로스파이크 APIs를 사용하는 모든 어플리케이션과 통합된), 너의 어플리케이션은 클러스터가 여러 노드로 구성되고 클라이언트가 클러스터 소통을 다루는 사실을 무시할 수 있습니다. 추가로, 에어로스파이크 데이터베이스는 너가 하드웨어 실패,등을 진단하고,버틀넥이 있는 공간에 접근하는 능력을 결정하는 훌륭한 감시 도구를 제공합니다.  

에어로스파이크 데이터베이스의 특징 중 하나는 저장소가 용량에 도달하거나 하드웨어 실패가 발생한 경우라도, 서비스에 최소한의 영향을 끼치고, 데이터베이스를 성공적으로 대응합니다.

##### 노드가 실패할때 무슨 일이 일어나는지?

4개 노드 클러스터의 경우를 다루자. 노드 #3은 하드웨어 실패와 충돌을 가지고 있다고 가정하자. 이 시점에서, 노드 #1,#2 그리고 #4는 #3 노드가 실패를 가지는 걸 감지합니다. 노드 #3은 데이터의 약 1/4에 대한 데이터 마스터이고 그 파티션은 지금 노드 #1,#2,그리고 #4,에 복제본에만 존재합니다. 나머지 노드는 자동으로 새로운 데이터 마스터에 복제본 파티션을 복사하기 위해 데이터 이동을 수행합니다. 그래서 예를들어, 파티션23은 노드 4에 복제 될 수 있고 이것은 파티션23에 대해 새로운 데이터 마스터가 되는 노드2를 지닌 노드2에 복사됩니다.  

동시에, 어플리케이션(에어로스파이크 스마트 클라이언트^tm^을 통합한)은 노드 #3이 실패했고 클라이언트가 자동으로 새로운 파티션 맵을 계산하는 걸 발견합니다.  

노드가 클러스터에 추가될때 같은 프로세스는 반대로 발생합니다. 위의 예에서, 아마 노드 #3은 클러스터에 재시작되고 재결합됩니다 또는 다른 노드는 더 좋은 용량을 제공하기 위해 클러스터에 추가됩니다. 두 경우 모두,노드가 서로를 찾기 위해 하트비트를 사용합니다. 노드가 클러스터에 추가될때, 새로운 노드가 몇몇의 파티션과 다른 파티션을 위한 복제본에 대한 데이터 마스터가 되도록 클러스터는 데이터 이동의 프로세스를 시작합니다. 클라이언트는 또한 자동으로 이 변화를 감지하고 미래 요청은 올바른 노드에 전송됩니다.  

일반적인 구성은 인구 기반의 근처에 클러스터를 가지는 것입니다(예를들어, 미국의 동쪽 해안에 한 클러스터와 서쪽 해안에 하나와 그리고 유럽,남미 또는 아시아에 필요에 따라 클러스터를 추가). 클러스터가 동기화될때, 그들은 서로 핫 백업으로 작용할 수 있습니다.  

예를들어,전체 동쪽 해얀 클러스터가 다운되면 어떤일이 발생합니까? [크로스 데이터 센터 복제](http://www.aerospike.com/docs/architecture/xdr.html)를 사용.

### 크로스 데이터 센터 복제

#### XDR 구조

XDR- 크로스 데이터센터 복제- 는 더 긴 지연 링크를 통해 한 클러스터가 다른 클러스터와의 동기화를 가능하게 하는 에어로스파이크 특징입니다. 이 복제는 비동기이지만, 지연 시간은 종종 초 아래에 있습니다. 각 쓰기는 로그되고, 그 로그는 원격 클러스터에 복제하는데 사용됩니다. 파티션에 대한 각 마스터는 그 파티션 쓰기를 복제하는 데 책임이 있고 현재 쓰기 상태는 로컬 클러스터의 파티션 복제에 복제됩니다, 그래서 그 복제본이 촉진될때, 이것은 이전의 마스터가 중단된 곳을 대신할 수 있습니다.

![XDR_image.png](XDR_image.png)

XDR 프로세스는 에어로스파이크 사이드를 따라 클러스터의 모든 노드에서 실행됩니다. XDR 프로세스의 주요 작업은 "로컬" 클러스터에 데이터베이스 업데이트를 감시하고 모든 쓰기 요청의 복사본을 하나이상의 "원격" 대상 클러스터에 전송하는 것입니다. XDR은 주요 에어로스파이크 설정 파일에서 원격 클러스터의 세부사항을 결정합니다. 이것은 다른 클러스터에 다른 네임스페이스(또는 심지어 세트)를 수송할 수 있습니다. 추가로, XDR 프로세스는 실패 처리를 다룰 수 있습니다. 실패는 원격 클러스터나 모든 곳에 로컬 노드 실패나 링크 실패 중 하나입니다.  

각 노드는 다음을 실행합니다:

* 에어로스파이크 데몬 프로세스(asd)
* 다음으로 구성되는 XDR 데몬 프로세스(xdr):

  *  로거 모듈
  *  Shipper 모듈
  *  실패 핸들러 모듈

![XDR_arch2.png](XDR_arch2.png)

XDR 프로세스는 클러스터의 모든 노드에서 실행합니다. 로컬 클러스터의 각 노드에서 발생하는 모든 쓰기/업데이트는 하나 이상의 원격 클러스터에 전송해야합니다. 이것을 효과적으로 수행하기 위해서, XDR은 운송될 필요가 있는 모든 키 다이제스트의 로그를 사용합니다. XDR이 원격 클러스터에 쓰일때, 이것은 그 시점에 키의 현재 값을 얻습니다. 동일한 레코드에 여러 변경이 있을때, 중개값이 아닌 최신 값만 전송되도록 이것이 수행됩니다. XDR은 다이제스트 로그에 기록의 모든 값을 저장하지 않습니다.  

이것의 자세한 내용은 메인 데이터베이스 시스템에 의한 읽기 및 업데이트가 지명된 파이프를 통해 이것의 XDR 프로세스와 소통하는 것입니다. 이 통신은 다이제스트 로그에서 이 정보를 저장하는 로거 모듈에 의해 수신됩니다. 다이제스트 로그 파일을 작게 유지하기 위해서, 나중에 실제 레코드를 운송하기 충분한 오직 최소한의 정보(키 다이제스트)는 다이제스트 로그에 저장됩니다. 다이제스트 로그는 링 버퍼 파일입니다.  즉, 가장 최근의 데이터는 잠재적으로 가장 오래된 데이터를 오버라이트합니다(버퍼가 가득찰때). 이것은 너가 파일 크기를 체크하는 걸 유지해줍니다. 하지만 이것은 또한 용량 계획 문제를 도입합니다. 너는 운송되는 보류중인 데이터의 손실을 피하기 위해 충분히 큰 다이제스트 로그 파일을 설정할 필요가 있습니다.  데이터 센터간 문제 소통때문에 너는 장기 정전에 대해 계획해야 합니다. 예를들어, 데이터 센터 중 하나의 사건은 날씨나 지진때문에 다운됩니다.

> 다이제스트 로그 파일 크기는 이전 파일의 내용을 삭제하지 않고 한번 설정한 것을 변경할 수 없습니다.  또한, 기존의 다이제스트 로그 파일은 XDR이 새로운 파일 크기 설정으로 시작되기 전에 제거되어야 할 필요가 있습니다.

Shipper 모듈은 다이제스트 로그를 읽기와 데이터를 운송하는 것에 대한 책임이 있습니다. 일부 특별한 특권과 설정을 가지고 있더라도 이 모듈은 원격 클러스터에 클라이언트 어플리케이션처럼 작동합니다. 데이터는 원격 클러스터에 일반 쓰기 같이 원격 클러스터에 운송됩니다.  

XDR이 데이터를 원격 사이트에 운송하는 속도는 대부분 다음에 의존합니다:

* 각 노드의 쓰기 속도
* 사용가능한 대역폭

작성된 데이터의 비율이 지속적으로 XDR이 데이터를 원격 클러스터에 운송할 수 있는 속도를 초과할때, XDR은 원격 클러스터에 모든 데이터를 업으로 동기할 수 없습니다. 보류중인 데이터는 성장만을 계속 유지하다보면 궁극적으로 폐기될 수 있습니다. 일반적으로 생산 환경에서, 낮은 시간의 피크 로드 사이클이 있습니다. 사용가능한 대역폭은 적은 기간동안 적어도 보류중인 운송되는 데이터를 유지하기 위해선 충분합니다.  

실패 핸들러 모듈은 다음과 같은 실패의 경우에 대비해서 시스템이 운송중인 데이터를 유지하는 걸 확인하는데 책임이 있습니다:

* 클러스터의 노드가 실패할때
* 원격 데이터 센터에 대한 링크가 다운될때

일반적으로 XDR은 다이제스트 로그 오버플로우와 같은 극도의 상황 또는 마스터와 복제 모두 실패하는 상황을 제외한 이러한 경우 모두에 데이터 손실이 없다는 걸 보장합니다. 노드가 실패할때, 복제 노드는 이 노드가 이전에 책임을 진 데이터를 운송하는 책임을 인수받습니다. 이처럼 XDR은 단일 노드 실패동안에 데이터 손실이 없음을 보장합니다.  

동작하는 방법:

* 시작할때, 로컬 클러스터는 원격 클러스터와 동기화되야하는 네임스페이스의 목록을 발견합니다. 원격 클러스터의 크기(노드 수)가 소스 클러스터의 크기와 다를 수 있다는 점을 유의하세요.
* 각 노드 프로세스는 근처 요청을 읽습니다(로컬 복제를 사용하여). 쓰기 요청을 위해, 데이터 마스터는 쓰기를 수행하고 마스터와 복제본 둘다 성공적으로 데이터를 작성한 후에만 쓰기를 확인하면서 복제 노드(로컬 복제)에 요청을 전송합니다.
* 클러스터의 각 노드는 쓰기/업데이트/제거 기록을 모으고 운송 로그라고 불리는 큐를 생성하는 XDR 데몬을 사용합니다. XDR은 메인 데이터베이스 프로세스보다 더 낮은 우선 순위에서 실행합니다. 피크타임에서, XDR은 매우 느리게 실행하고, 트래픽이 낮을때 따라 잡습니다. 시간이 허락하는 한, XDR은 원격 클러스터 데이터가 로컬 클러스터와 동기화하도록 원격 데이터 센터의 운송 로그의 요청을 운송합니다.
* 각 노드의 XDR 데몬은 데이터를 특정 원격 노드에 운송합니다- 메인 데이터베이스와 마찬가지로, 키 다이제스트는 원격 파티션에 레코드를 할당하는데 사용됩니다. 원격 클러스터에, 데이터는 다른 노드에 임의로 할당된 파티션으로 분배됩니다. XDR 데몬은 자동으로 원격 클러스터의 어떤 노드가 각 파티션에 대한 동기화 데이터인지 계산하는 클러스터 인식 데몬 입니다.

##### XDR 토폴로지

XDR은 단순한 액티브-액티브,액티브-패시브,스타 그리고 이들의 조합과 같은 다양한 토폴로지로 구성될 수 있습니다. 스타 토폴로지는 한 데이터 센터가 동시에 여러 데이터 센터에 데이터를 복제하는 걸 허용합니다. 이것은 복잡한 다중 마스터 링 복제 토폴로지에 대한 에어로스파이크의 지원을 보완합니다. 에어로스파이크는 기업이 스타 토폴로지, 복잡한 링 토폴로지, 또는 심지어 둘다 같은 배치의 구현을 선택하는 NoSQL 데이터베이스입니다. 그 결과, 회사는 그들의 사업과 기술 요구를 최고로 지원하는 복제 접근을 구현하기 위해 전례없는 유연성을 가집니다.

##### 단순 액티브-패시브

액티브-패시브 토폴로지에서, 초기 쓰기는 오직 한 클러스터에서 발생합니다(여기서는 로컬 클러스터로 부름). 원격 클러스터는 읽기를 위해 사용되는 대기 클러스터입니다. 시스템은 원격 클러스터에 어플리케이션 쓰기를 멈추는 메커니즘(non-xdr writes)을 가지고 있지 않습니다. 그러므로 어플리케이션은 대상 클러스터에 아무 데이터를 바로 쓸 수 없습니다. 대상 클러스터의 XDR 운송은 원격 클러스터의 부주의한 쓰기가 다른 클러스터에 운송되지 않도록 "xdr 가능" 설정 옵션을 사용하여 억제해야 합니다. 이 옵션은 강렬한 데이터의 분석이 필요할때 사용됩니다, 하지만 너는 메인 클러스터의 성능에 영향을 끼치고 싶어하지 않습니다. 메인 클러스터는 액티브 하나와 패시브 분석 클러스터로 구성되야 합니다.

![XDR_active_passive.png](XDR_active_passive.png)

##### 단순 액티브-액티브

액티브-액티브 토폴로지에서, 쓰기는 두 클러스터에서 발생할 수 있습니다. 클러스터에서 발생하는 쓰기는 다른 클러스터에 전송됩니다. XDR은 운송된 데이터가 백의 무한루프와 클러스터간 네번째 쓰기를 방지함으로써 더 멀리 전송되지 않음을 조심합니다. XDR은 쓰기가 두 노드에 발생하는 걸 허용하기 때문에, 동일한  키는 모순되는 데이터를 연결함으로써 동시에 두 클러스터에 업데이트 될 수 있습니다. 에어로스파이크 데터베이스가 어플리케이션 데이터에 불가지론자이기 때문에, 이것은 이 모순을 자동으로 수정할 수 없습니다. 이 모순이 발생하는 윈도우는 첫번째 쓰기가 발생하는 시간과 이것이 재운송되고 두번째 클러스터에 재작성되는 시간 사이에서 발생할 수 있습니다, 즉, 쓰기가 이 시간 윈도우에서 원격 클러스터에 발생할때, 이것은 자동으로 서버에서 해결할 수 없는 모순으로 이어집니다. 그러나, 다음 업데이트 작업은 동시에 일어나는 동일한 쓰기 행동이 스스로 반복할 수 없다고 가정하는 데이터의 동기화를 강요합니다. 동일한 레코드가 동시에 다른 두 클러스터에 업데이트된 경우에, 이 메커니즘은 적합하지 않습니다. 많은 다른 경우에, 레코드에 기본 쓰기는 강하게 단일 클러스터와 연관되고 다른 클러스터는 핫 백업처럼 수행합니다. 이것은 액티브-액티브에 대해 아주 좋은 사용 사례입니다.  

예를들어, 회사는 북미에 퍼지는 사용자를 가지고 있습니다. 트래픽은 서해안과 동해안 데이터 센터간에 분할됩니다. 보통 서해안의 사용자가 동해안을 여행하기 위해 동해안 데이터 센터에서 서비스를 받는 동안, 이것은 이 사용자에 대한 쓰기가 동시에 두 데이터 센터에서 동시에 발생하는 걸 믿지 않습니다.(While it is possible for a user normally on the West Coast to be traveling to the East Coast and thus be serviced by the East Coast data center, it is unlikely that writes for this user will occur simulateously in both data centers at the same time.) 이것은 액티브-액티브 토폴리지에 대해 아주 좋은 사용 사례입니다.

![XDR_active_active.png](XDR_active_active.png)

##### 스타 복제

XDR은 데이터를 여러 대상 클러스터에 운송할 수 있습니다. 너는 단순히 네임스페이스 설정에서 여러 대상 클러스터를 지정함으로써 이것을 성취할 수 있습니다. 각 대상 클러스터는 설정 매개변수 xdr-원격 데이터센터에 별도의 라인에 지정되어 있습니다. 데이터가 중앙으로 게시되고 로컬 시스템에서 낮은 지연시간 읽기 접근을 위해 여러 위치에 복제될때 이것이 가장 흔하게 사용됩니다.

![XDR_star.png](XDR_star.png)

##### 더 복잡한 토폴로지

이것은 위의 토폴로지를 결합하고 아래와 같은 더 복잡한 토폴로지를 가지는 것이 가능합니다.

![XDR_complex.png](XDR_complex.png)

##### 장애 다루기

XDR은 장애의 다른 유형을 관리:

* 로컬 노드 장애
* 원격 링크 장애
* 위의 조합

##### 로컬 노드 장애

로컬 노드 장애의 경우에, 복제 노드는 원격 클러스터 간에 데이터를 동기화하는데 사용됩니다. 에어로스파이크 클러스터는 각 노드의 상태와 기본 및 복제된 데이터를 유지합니다. 노드에 장애가 생길때, 클러스터는 다른 노드의 복제 데이터를 사용하여 자동으로 XDR 쓰기를 계속합니다.

##### 원격 링크 장애

로컬과 원격 클러스터간에 연결이 중단될때, XDR은 링크를 사용할 수 없는 시간의 기간(초)을 추적합니다.  링크가 사용가능해질때, XDR은 그 링크에 대한 데이터를 운송합니다. 클러스터내의 XDR은 클러스터의 모든 노드에 의해 마지막 운송 시간을 추적합니다.  

XDR이 스타 토폴로지를 사용하도록 구성될때, 클러스터는 동시에 여러 데이터 센터에 운송할 수 있습니다. 이 경우에, 하나이상의 데이터 센터 링크는 나쁘게 갈 수 있습니다. XDR은 사용가능한 데이터 센터에 운송합니다. 이것은 구성된 각각의 데이터 센터에 대한 링크가 다운된 시간을 기억합니다. 링크가 사용가능해질때 XDR은 현재 쓰기뿐만 아니라 링크가 다운된 기간에 대한 쓰기도 운송합니다. XDR은 또한 원격 링크 장애와 결합된 로컬 노드 장애와 같이 더 복잡한 시나리오를 다룹니다.

##### 장애의 결합

XDR은 또한 원격 링크 장애를 지닌 로컬 노드 다운, XDR이 역사적 데이터 등등을 발송하는 링크의 장애와 같은 장애의 결합을 다룹니다.

##### 압축

XDR은 운송하기 전에 데이터를 압축하는 옵션을 가지고 있습니다. 이것은 데이터 센터간에 대역폭을 저장하는 데 도움이 됩니다. 운송과 최소 크기보다 더 큰 레코드가 압축을 겪기전에 관리자는 압축된 레코드의 최소 한계 크기를 구성할 수 있습니다.

##### 네임스페이스당 운송

에어로스파이크 노드는 여러 네임스페이스를 가질 수 있습니다. 너는 다른 원격 클러스터에 운송하기 위해 다른 네임스페이스를 구성할 수 있습니다. 다음은 이것을 증명하는 예시입니다. DC1은 네임스페이스 NS1과 NS2를 DC2에 운송하고 네임스페이스 NS3를 DC3에 운송합니다. 이 유연성은 다른 데이터 세트에 복제 규칙을 다르게 설정하기 위해 많은 고객을 지원하고 있습니다.

![XDR_ns_shipping.png](XDR_ns_shipping.png)

링을 형성하는 클러스터의 주위에 네임스페이스 NS1에 쓰기가 루프를 유지하는 것을 위의 예에서 알 수 있습니다. 이것을 방지하기 위해서, XDR은 다른 XDR에서 오는 쓰기 전송을 중지하는 옵션을 가집니다.

##### 좋은 세트 운송 제어

XDR은 데이터 센터에 특정 세트(테이블과 유사한)를 운송하도록 설정되어 있습니다. 이것은 운송된 데이터이상으로 좋은 제어를 허용합니다. 그래서 네임스페이스와 세트의 조합은 레코드 운송 여부를 결정합니다. 로컬 클러스터의 네임스페이스의 모든 데이터가 다른 클러스터에 복제될 필요가 없기 때문에 이것은 종종 수행됩니다.

##### 여러 다른 종류로 이뤄진 클러스터 동기화

XDR은 다른 크기, 작업 시스템, 저장소 미디어 등등을 가지는 클러스터를 위해 작동합니다. XDR의 용량을 다루는 장애는 동적으로 소스 클러스터 크기 변경을 허용합니다. 이것은 또한 여러 대상 데이터 센터가 여러번 오갈때 작동합니다.

##### 로컬 데이터 센터의 원격 클러스터

가장 일반적인 배치가 다른 데이터 센터에서 로컬 및 원격 클러스터를 가지는 동안에, 너가 동일한 데이터 센터에서 원격 클러스터를 가지길 원하는 시간이 있습니다. 이에 대한 가장 일반적인 이유는 다음과 같습니다:

* 원격 클러스터는 데이터 분석을 위해서만 의도됩니다. 이 경우에, 너는 원격 클러스터를 패시브 모드에 두고 그 클러스터의 모든 분석 작업을 수행합니다. 이것은 워크로드에서 로컬 클러스터를 고립시키고 가용성을 보장하는데 도움이 됩니다.
* 일부 데이터 센터(아마존 EC2와 같은)는 여러 가용성 영역을 가지고 있습니다. 이것은 일반적으로 다른것이 업일 가능성이 높은 하나의 가용성 영억을 가지는 큰 문제일 수 있다는 걸 의미합니다. 가용성 영역 정전을 지닌 문제를 가지는 관리자는 데이터 센터내의 여러 가용성 영역에 클러스터를 가지는 걸 선택할 수 있습니다.

##### 토폴로지

XDR은 쓰기가 한 클러스터에 생성되고 변경이 다른 또는 쓰기가 동시에 두 클러스터를 생성하는 액티브-액티브 모드에 복제되는 액티브-패시브 모드에서 클러스터를 동기화하도록 설정할 수 있습니다. 이런 모드는 복잡한 여러 마스터 링 토폴로지를 구현하기 위해 결합할 수 있습니다. XDR은 또한 한 데이터 센터가 동시에 여러 데이터 센터에 데이터를 복사하는 스타 토폴로지를 지원합니다. 스타와 동일한 배치에 복잡한 여러 마스터 링 토폴로지의 조합은 너에게 어플리케이션 요구사항을 최고로 지원하는 구조를 구현하는 전례없는 유연성을 제공합니다.

##### 운송 제거

XDR 운송은 쓰기와 같이 삭제됩니다. 삭제 운송은 모든 데이터 센터와 동기화 객체를 유지하기 위해 중요합니다. 사용자 시작 제거는 기본적으로 운송됩니다. 객체의 퇴거를 통해 생성되는 '제거'는 관리자에 의해 운송되거나 운송되지 않는 걸 선택할 수 있습니다.

### 랙 인식

에어로스파이크는 너가 마스터 데이터와 복제된 데이터가 동일한 하드웨어 장애 그룹의 서버에 저장되지 않도록 지정할 수 있습니다. 이 기능을 랙 인식이라고 부릅니다.  

기본적으로, 복제 파티션은 클러스터의 모든 노드에 고르게 분산됩니다: (N개의 노드를 포함하는 클러스터의)각 노드는 이런 파티션들이 다른 N-1노드 중에 고르게 분산되기 위한 데이터 파티션과 복제본의 1/N을 위한 데이터 마스터입니다. 이 표준 배열은 랙에 장애가 발생할때, 랙의 노드가 가능한 데이터가 이용하지 못하는 결과인 일부 파티션에 대한 데이터 마스터 노드와 복제본 노드 둘다를 포함하는 걸 의미합니다.  

잠재적인 데이터 이용 불능을 막기위해서, 너느 노드를 그룹의 모든 서버가 단일 랙인 그룹에 설정할 수 있습니다. 그룹의 노드는 데이터 마스터 노드로 기능하지만 동일한 그룹의 다른 노드를 위한 복제본으로 기능할 자격이 없습니다. 복제본은 다른 그룹(랙)의 노드간에 분산됩니다.  

단일 노드가 다운되는 경우에, 클러스터는 일시적으로 노드가 복구될때까지 불균형하게됩니다. 이 불균형은 서비스 방해를 일으키지 않고 클러스터는 방해되지 않게 계속합니다. 노드가 재시작할때, 클러스터는 자동으로 재조정합니다.  

이 기능은 가용성 영역을 사용하는 아마존과 같은 클라우드 서비스에서 사용할 수 있습니다. 너가 가용성 영역과 상응되는 그룹을 설정할때, 너의 데이터베이스는 단일 영역에 장애가 생길때 작동을 계속합니다.

##### 랙 인식을 사용하는 클러스터를 업그레이드 하는 방법

랙 인식을 사용하는 클러스터를 업그레이드하기 위해서, 너는 클러스터의 모든 노드를 중지하고 그들의 설정 파일을 업그레이드하고 모든 노드를 재시작합니다. 랙 인식은 에어로스파이크의 3.x 버전에서만 사용가능하기때문에 너가 2.x버전을 사용할때 너는 소프트웨어를 업그레이드 해야합니다.  

복제 위치는 클러스터의 모든 노드에서 합의해야 하기 때문에, 너가 처음으로 랙 인식을 사용하기 위해서 시작할때, 풀 클러스터 재시작이 필요합니다.  

클러스터의 모든 노드는 랙 인식을 사용할 필요가 있습니다- 즉, 모든 노드는 아래에 묘사된대로 설정해야 합니다.  

랙 인식이 켜질때, 이것은 적어도 작동하기 위해 두 그룹을 필요로 합니다. 오직 한 노드 또는 한 그룹만이 있을때, 기본 동작(랙 인식이 없는)이 자동으로 수행됩니다. 이것은 또한 클러스터 시작에 여러 그룹이 존재하는 경우이지만, 장애의 일부는 단일 그룹(랙)에만 원인이 될 수 있습니다; 단일 나머지 그룹(랙)의 나머지 노드는 자동으로 기본 클러스터(랙 인식 없는)를 형성합니다.

##### 랙 인식을 가진 클러스터 확장

랙 인식이 배치되면, 너는 그룹에 노드를 추가하거나 전체 클러스터 재시작없이 그룹에서 노드를 제거할 수  있습니다.  

노드를 클러스터에 추가하기 위해서, 노드를 추가하기전에 단순히 그룹을 설정하고 클러스터는 일반적인 방법으로 재조정합니다.  

##### 노드를 위한 그룹 설정 표시

어떤 노드가 어떤 그룹에 있는지 보기 위해서:

	clinfo -v dump-ra : verbose = true

예를들어, 우리가 노드 ID 101을 지닌 노드를 조회할때, 출력은 3개의 노드/3개의 그룹 클러스터를 위해 다음과 같습니다:

	May 28 2013 18:39:00 GMT: INFO (info): (base/cluster_config.c:267) Rack Aware is enabled.  Mode: static.
          May 28 2013 18:39:00 GMT: INFO (paxos): (base/cluster_config.c:281) SuccessionList[0]: Node bcd00cb00000069 : Port 3021 ; GroupID 203 ; NodeID 105 [Master]
          May 28 2013 18:39:00 GMT: INFO (paxos): (base/cluster_config.c:281) SuccessionList[1]: Node bc300ca00000067 : Port 3011 ; GroupID 202 ; NodeID 103
          May 28 2013 18:39:00 GMT: INFO (paxos): (base/cluster_config.c:281) SuccessionList[2]: Node bb900c900000065 : Port 3001 ; GroupID 201 ; NodeID 101 [Self]


##### 모범 사례

일반적으로, 우리는 클러스터의 노드가 SSDs의 50%의 사용량을 초과하지 않고 단일 노드의 장애를 처리하는 데 충분한 과잉 용량을 가지는 걸 추천합니다. 그룹화 된 노드의 경우에, 우리는 클러스터의 노드가 랙 장애를 처리하는 데 충분한 여분의 용량을 가지는 걸 추천합니다. 예를들어, N개 노드 클러스터에서 랙당 3개 노드를 가진다면, N-3노드는 전체 데이터베이스 로드를 캐리하는데 충분한 용량을 가져야 합니다.  

각 랙은 동일한 수의 노드를 가져야 하고 데이터가 균형되고 랙이 다운될때 트래픽이 처리되도록 모든 랙은 동일하게 구성되어야 합니다. 예를들어, 12개 노드 클러스터에서, 첫번째 랙에 장애가 발생할때 한 랙의 10개 노드와 다른 랙의 2개 노드는 문제가 됩니다. 12개 노드 클러스터의 예시 경우에서, 이것은 랙당 3개 노드를 지닌 4개 랙을 가지거나 랙당 2개 노드를 지닌 6개 랙을 가지는 것이 좋습니다.  

노드값(포트+그룹+노드로 구성된 64 비트 식별자) 고유해야 합니다. 너가 처음에 랙 인식을 설정할때, 이 유일함을 설정하기 쉽습니다. 그러나 하드웨어가 업그레이드되고 IP 주소 변경으로 시간이 지나서, 유일함을 특히 너가 정적 및 동적 노드 값의 혼합을 가질때 유지하기 어려울 수 있습니다. 그러므로, 우리는 너가 노드 값의 현재 목록을 생성하고 이것을 신중하게 유지하는 걸 추천합니다. 새로운 기계가 클러스터로 들어가고 노드값 충돌이 있을때, 노드간 통신 장애 때문에 클러스터의 잘못된 몇 가지 동작이 있을 수 있습니다.

## 사용자 정의 함수

#### 사용자 정의 함수

사용자 정의 함수(UDF)는 에어로스파이크 데이터베이스 서버에서 실행되는 사용자(또는 개발자)에 의해 쓰여진 코드입니다. UDFs는 기능성과 성능 모두에서 에어로스파이크 데이터베이스 엔진의 능력을 크게 확장할 수 있습니다. 현재, 에어로스파이크는 UDF 언어로 [루아](http://www.lua.org/)를 지원합니다.  

UDFs의 사용을 시작하기 위해서 [UDF 기능 가이드](http://www.aerospike.com/docs/guide/udf.html)를 참조하세요.

##### 왜 루아인가?

다른 스크립트 언어와 비교해서, 루아는 매우 간단하고 힘있는 언어입니다. 루아 웹사이트에서:  

루아는 강력하고,빠르고,가볍고,내장 가능한 스크립트 언어입니다. 루아는 연관 배열과 확장가능한 의미에 기반한 강력한 데이터 기술 구조를 가진 간단한 절차의 구문을 갖춥니다.  

루아는 아파치 스퀴드 프록시, Redis와 Postgres 둘의 UDFs,그리고 다른 프로젝트 내에서 임의의 다시쓰기 규칙과 같이 비슷한 프로젝트의 수에 큰 효과를 위해 사용됩니다.  

에어로스파이크는 스레드당,등록된 UDFs당 보다 크지 않게 크게 지연시간을 줄이고 성능을 증가시키면서 루아 문맥의 큐를 생성합니다.

##### 레코드 UDF

레코드 UDF는 단일 데이터베이스 레코드에서 실행됩니다. 그들은 레코드를 생성,업데이트,또는 제거하는 기능을 가집니다.  

레코드 UDF API 제공:  

* 이것의 빈과 메타데이터를 포함하는 레코드 객체에 대한 접근(세대, 생존시간)
* 맵과 리스트 같은 복잡한 데이터 타입의 쉬운 조작
* blob 데이터 타입에 대한 쉬운 바이너리 접근

레코드 UDF는 트랜젝션의 주요 흐름으로 실행됩니다. 모든 레코드 UDF는 데이터베이스의 열에 접근하고, 루아 레코드 객체를 생성하고, 작동하기 위해 UDF를 허용하는 루아 기능을 작동시키는 흐름의 부분입니다. 레코드를 생성하거나 생성하지 않기 위해 UDF를 허용하고 레코드의 모든 조작을 허용하면서 종종 레코드는 존재하지 않습니다.  

레코드 UDF는 다음 시나리오에서 작동할 수 있습니다:  

* 기본 키 조작(put과 get 같은)
* 스캔 작업(데이터베이스의 제거 허용)
* 보조 인덱스 쿼리 작업(30에서 40에 나이를 지닌 레코드 실행)

##### 스트림 UDF

스트림 UDF는 레코드 컬렉션의 작업(읽기 전용)을 실행하는데 사용됩니다. 스트림 UDF 시스템은 감소 단계에서 계산되는 "탑 결과"를 가지는 각 열이 접근되고 워드의 목록과 그들의 카운트가 방출되는 "워드 카운트"와 같은 일반적인 고급 병렬 MapReduce 작업에 사용하는 프로그래밍의 MapReduce 스타일을 허용합니다. 객체를 지속적으로 생성하고 파괴하는 대신에 카운터가 단순히 맥락에서 증가되는 단순한 집합을 바랄때 에어로스파이크는 더 최적의 구현을 제공합니다.  

에어로스파이크의 스트림 UDF 스트림과 일반적인 MapReduce 프레임워크 사이의 중요한 차이점은 스트림 UDF가 매우 낮은 지연시간과 비공유된 구조에서 더 높은 안정성을 가지고 작동하도록 설계되어 있다는 점입니다.  

조정된 작업 제어를 가지는 대신에, 스트림 UDF 쿼리는 클라이언트를 요청함으로써 클러스터의 모든 노드에 전송됩니다. 그들은 각 서버에서 관리되고 우선 순위됩니다. 결과는 클라이언트에 결과를 제시하기 전에 최종 작업(감소 또는 최종 집합 단계같은)을 수행한 요청 클라이언트에 다시 전송됩니다.  

이것이 클라이언트의 높은 메모리 사용을 야기하더라도, 서버 클러스터는 안좋게 형성된 쿼리에 의해 방해되지 않습니다. 경량 앱 서버가 큰 최종 감소 단계를 요구하는 요청을 만들길 원하고 중간 어플리케이션 서버가 추가될때, 이 서버는 조정 에이전트 같이 수행하는 REST 또는 SOA API를 사용할 수 있고, 그 서버는 어플리케이션 로드에 적합한 메모리 프로파일을 가질 수 있습니다.

##### 클러스터의 UDF 코드 관리

UDFs는 실행하는 파일내에서 파일 이름(UDF 모듈), 기능 이름,그리고 선택적으로 하나이상의 매개변수를 지정함으로써 작동됩니다.  

UDFs는 클러스터의 시스템 메타데이터(SMD) 구성 요소에 의해 관리됩니다. 파일이 등록될때, 이것은 한 노드에만 전송됩니다. 그 노드는 이전에 받은 버전과 이 들어오는 버전을 비교하는 현재 클러스터 주체에 요청을 전송합니다. 새로운 버전일때, 이것은 파일을 로컬 저장소에 계속되고 또한 이것을 남은 클러스터 노드에 전송합니다.  

등록동안에, 파일은 또한 해석됩니다. 이것은 바로 감지되는 간단한 구문 분선 오류를 허용하고 그 오류는 등록 API에 의해 반환됩니다.

##### 시스템 UDFs 와 사용자 UDFs

에어로스파이크 서버 설치는 먼저 개발된 일부 UDFs를 포함합니다. 이것은 UDFs를 실행하기 위한 UDF 헬퍼 루틴입니다. 그들은 UDF "시스템" 디렉토리에 있습니다. 사용자에 의해 등록된 분명한 UDFs는 다른 "사용자" 디렉토리에 배치됩니다. 두 디렉토리 위치는 에어로스파이크 구성 파일에서 설정할 수 있습니다.  

###### 멀티코어

많은 다른 해석 언어는 프로세스당 실행의 한 스레드만 실행할 수 있습니다. 예를들어, CPython은 프로세스당 여러 Python 맥락을 실행하는 능력을 크게 줄이는 코드 베이스에 글로벌을 사용합니다. 자바스크립트의 구글 구현인 V8은 여러 코어를 동시에 실행하는 능력을 내세우지만, 우리의 측정에서, 성능은 루아에 비해 매우 나빴습니다.  

###### C의 게이트웨이

그것은 루아에서 C라고 불리는 코드를 쓰는 것은 간단합니다. 이렇게 수행하는 루아 오버헤드가 측정가능하더라도, 그것도 간단합니다. 에어로스파이크는 통지되는 다른 프로세스를 허용하여 에어로스파이크 UDF에서 C의 지명된 파이프로 쓰기의 예시를 제공합니다.

###### 다른 언어

에어로스파이크 코어는 작동되는 다른 언어를 허용하기 위해 추상화 계층을 제공합니다. 심은 맥락으로 파일의 구문분석 또는 컴파일,그리고 매개변수와 레코드 정보를 지닌 언어 메소드를 실행하는 해석 맥락의 생성을 가능하게 하려면 생성되어야 합니다. 다른 언어의 적응은 간단합니다.

##### 보호와 샌드박싱

에어로스파이크의 UDFs는 인-프로세스로 작동합니다. 이것은 성능의 최대량을 위하지만, 안좋게 쓰여진 UDF가 성능 문제를 일으키는 경우를 초래할 수 있습니다.  

에어로스파이크는 UDFs에서 유사한 에러를 방지하는 기능을 제공합니다. 무한 루프는 UDF에서 소비된 시간 제한을 통해 보호됩니다.  

##### 저장 방법 VS UDF

저장 방법의 다른 용어가 있습니다, 그것은 흔히 데이터베이스 시스템에서 사용되고 사용자 정의 함수와 비슷한 의미를 가집니다. 저장 방법은 기본적으로 관계형 데이터베이스 관리 시스템에서 저장되고 실행하는 사용자 어플리케이션 프로그램입니다. 저장 방법은 하나이상의 레코드를 읽기 또는 쓰기를 할 수 있는, 범용 메커니즘입니다.  

대조적으로, UDF는 더 제한됩니다. UDFs는 단일 레코드(레코드 UDF)나 레코드의 선택된 스트림(스트림 UDF) 중 하나에 작동합니다. 그래서, 에어로스파이크 용어에서, 레코드 UDF는 거의 기존 UDF 같이 행동하고 스트림 UDF는 여러 레코드를 처리할 수 있으므로 약간 저장 방법같이 행동합니다.

## 클라이언트

#### 클라이언트 구조

##### 개요

에어로스파이크 데이터베이스는 종종 국적없는 어플리케이션이 에어로스파이크 데이터베이스 서버에서 분리된 서버의 세트에 있는 클라이언트-서버 구조입니다.

![ARCH_user_mw_as.png](ARCH_user_mw_as.png)

에어로스파이크 클러스터와 소통하기 위해서, 우리는 데이터베이스 에어로스파이크 클러스터에 대한 접근을 허용하는 클라이언트-드라이버의 세트를 제공합니다. 이런 모든 클러스터는 클러스터 상태를 감지, 효율적으로 트랜젝션 루팅,페일오버, 그리고 효율적으로 네트워크 연결 풀링을 포함하는 동일한 기본 기능을 제공합니다.  

이런 클라이언트 라이브러리는 소스 형식으로 너의 어플리케이션 서버 계층으로 구축하기 위해 분산됩니다. 그들은 로드 균형자 계층이 고 가용성을 가지고 실행하는 걸 요구하지 않도록 기능을 제공합니다.  

너가 에어로스파이크 클라이언트 API 라이브러리를 지닌 너의 어플리케이션을 컴파일할때(예를들어, C 또는 자바 클라이언트 라이브러리), 이것은 클러스터의 서버에 연결하는 바이너리 와이어 프로토콜을 사용하는 에어로스파이크 스마트 클라이언트^tm^을 포함합니다. 에어로스파이크 클라이언트 API는 고성능과 쉬운 개발에 필수적인 몇 가지 기능을 가지고 있습니다:

* 개발자가 필요없도록 클러스터 상태를 추적합니다. 어떤 순간에서, 클라이언트는 클러스터와 정기적으로 소통하고 클러스터를 구성하는 노드의 목록을 유지하는 정보 프로토콜을 사용합니다. 이것은 또한 데이터의 특정 파티션에 어떤 노드를 저장할지 결정하는 에어로스파이크 스마트 파티션^tm^ 알고리즘을 사용합니다. 클러스터 크기에 대한 모든 변경은 자동으로 클라이언트에 의해 추적됩니다; 그런 변경은 완전히 어플리케이션에 명백합니다. 사실, 이것은 트랜젝션이 이행동안에 장애가 발생하지 않는 걸 의미하고, 어플리케이션이 노드 도착과 출발동안 재시작될 필요가 없습니다.
* 연결 풀링을 구현해서, 클러스터에 연결의 풀을 설정또는 관리하는 코드가 필요없습니다.
* 타임아웃을 감시하고 요청을 재송신하는 트랜젝션을 관리합니다.
* 스레드가 안전하면, 프로세스에 한 인스턴스가 필요합니다.

##### 클라이언트 라이브러리 기능

![architecture-client.jpg](architecture-client.jpg)

> 클라이언트 구조

에어로스파이크는 다양한 언어를 위한 클라이언트 라이브러리를 가집니다. 자바,C,C#,그리고 PHP는 현재 모든 에어로스파이크의 기능을 지원합니다.  

일부 클라이언트는 오직 향상된 키-값 작업만 지원합니다. 기본 put()과 get()작업 외에도, 에어로스파이크는 "CAS"(안전 읽기/수정/쓰기)작업,인데이터베이스 카운터 그리고 맴캐쉬 작업을 지원합니다. 일괄 작업은 여러개의 키 중 하나 왕복 반입을 허용하고 있습니다. 데이터는 각 빈이 정수,스트링,바이너리 객체, 또는 언어 직렬화된 객체 같은 타입을 가지는 빈(일반 관계형 시스템의 행과 비숫한)으로 구성되어 있습니다.  

에어로스파이크는 또한 다음을 포함하도록 확장되었습니다:

* 빈의 복잡한 데이터 타입(중첩될 수 있는 리스트와 맵)
* 빈 값이 인덱스되고 데이터베이스가 동등 또는 범위로 검색되는 쿼리
* 에어로스파이크의 실행중인 어플리케이션 코드에 의해 확장되는 데이터베이스 처리를 허용하는 사용자 정의 함수
* 레코드의 컬렉션이 사용자 정의 함수와 반환된 집계 값으로 작동될 수 있는 집합
* 빈이 최적으로 저장되는 매우 큰(1GB 통해 1 MB) 스택,리스트,또는 맵이 될 수 있는 데이터 구조를 포함하는 대규모 데이터 타입

이러한 각 기능은 개별 기능 가이드에 잘 설명되어 있습니다.  

에어로스파이크는 기능의 여러 수준을 가진 다음 클라이언트 라이브러리를 제공:

 | 키-값 | 스캔 | CDT | 쿼리 | UDF | 집계 | LDT | 배치 | 보안 
---------|---------|--------|-------|-------|--------|---------|---------|---------|---------
C/C++ | O | O | O | O | O | O | O | O | O
자바 | O | O | O | O | O | O | O | O | O
C# | O | O | O | O | O | O | O | O | O
PHP | O | O | O | O | O | O | O | O | X
Go | O | O | O | O | O | X | O | O | O
Python | O | O | O | O | O | O | X | O | O
Node.js | O | O | O | O | O | O | X | O | X
Ruby | O | O | O | O | O | X | O | O | O
Erlang | O | X | X | X | X | X | X | X | X
libevent2(C) | O | O | X | X | X | X | X | X | X
Perl | O | X | X | X | X | X | X | X | X

CDT = 복잡한 데이터 타입(리스트,맵)  

자세한 내용을 위해서, 구조 가이드나 '개발' 탭 아래에 언어별 클라이언트 메뉴얼을 확인하세요.

## ACID

#### ACID

[CAP 정리](http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed)는 일관성,가용성,그리고 분할 내성의 세 가지 속성 중 2개만 특정 시간에 분산된 시스템에서 보장되는 걸 상정합니다. 가용성이 대부분의 배치에서 가장 중요하기 때문에, 시스템은 일관성이나 분할 내성 중 하나를 제공할 수 있습니다. 그러나, 이런 세 속성이 바이너리 보다 더 연속적임을 유의하세요. 에어로스파이크는 다음과 같은 기슬울 사용함으로써 높은 일관성을 제공합니다(Aerospike is by and large an AP system that provides high consistency by using the following techniques):

* 각 서브시스템에서 더 미세한 입도의 가용성과 일관성의 균형을 이룹니다.
* 하위 밀리초인 노드간 소통 지연시간을 제한합니다.
* 클러스터 크기가 작게(노드 1~100사이) 머무는 걸 보장하는 에어로스파이크의 높은 수직 규모의 영향력(백만 TPS와 노드당 여러 테라바이트 용량)
* 가상으로 데이터 센터와 클라우드 환경에서 배치의 연도를 통해 증명된 파티션 형식을 제거
* 노드에 장애가 발생하고 롤링 업그레이드(드문 파티션의 부재에) 동안 극도로 높은 일관성과 가용성을 보장
* 클러스터 형성동안 더 오래된 데이터를 새로운 데이터가 오버라이드 하는 걸 보장하기 위해 자동 충돌 해결책을 제공

노드 장애의 존재에서 에어로스파이크가 ACID 일관성을 제공하는 방법의 더 자세한 내용은 이 [문서](http://www.aerospike.com/docs/architecture/assets/AerospikeACIDSupport.pdf)에서 설명됩니다.

# 기능 가이드- 무엇인지

## 키-값 저장

#### 키-값 저장

에어로스파이크 키-값 저장 작동은 표준 RDBMS 용어의 ==열==과 비슷한 지명된 값의 세트를 가진 키와 연관된 메커니즘을 지원합니다.  

최고 수준에서, 데이터는 RDBMS 시스템의 ==데이터베이스==와 의미상 비슷한 ==네임스페이스==라고 불리는 정책 컨테이너에 모입니다. 네임스페이스는 클러스터가 시작될때 설정되고, 주어진 데이터 세트를 위한 저장과 신뢰성 요구사항을 제어하는데 사용됩니다. 예를들어, (네임스페이스 수준에서 정의된)복제 요소는 클러스터에 보관되는 각 레코드의 복제본 수를 결정하는데 사용됩니다.  

네임스페이스내에서 데이터는 ==세트==(==테이블==과 비슷한)와 ==레코드==(==열==과 비슷한)로 세분화됩니다. 각 레코드는 세트에서 고유한 인덱스된 ==키==와 하나이상의 레코드와 연관된 값을 가지는 지명된 '빈'(행과 비슷한)을 가집니다.  

어플리케이션 개발자를 위해서, 명심해야할 몇 가지 중요한 것이 있습니다:

* 에어로스파이크는 스키마가 없습니다. 세트 또는 빈을 먼저 업으로 정의할 필요가 없습니다- 너가 새로운 빈 또는 세트를 추가할 필요가 있을때, 표준 APIs 와 ==세트==를 사용하는 것은 너를 위해 생성됩니다.
* 시스템은 기본적으로 키-값 저장소입니다. 레코드는 레코드의 데이터를 얻기위해 공급되는 키에 의해 인덱스됩니다.
* 빈 값은 강력하게 입력되지만, 빈은 스스로 입력되지 않습니다. 이것은 다른 레코드가 동일한 빈의 값에 대해 다른 타입을 가지고 있다는 걸 의미합니다. 예를들어, 빈 '이름'을 가지는 세트를 고려하자. 일부 레코드는 스트링으로 이 빈을 채우고(표준 케이스), 일부는 정수로 빈을 채우고(에러 케이스) 나머지는 전혀 그 빈 값을 가지고 있지 않을 수 있습니다. 이 특징이 사용되는 방법은 어플리케이션 개발자까지 완전합니다.
* 각 레코드는 데이터의 추가 비트, 데이터가 수정된 횟수를 반영하는 세대 카운트를 포함합니다. 이 숫자는 읽기의 어플리케이션에 다시 전달되고 기록된 데이터가 마지막 읽기 이후 수정되지 않았음을 확인하는데 사용될 수 있습니다(이것은 맴캐쉬에서 사용되는 동일한 패러다임입니다). 이것은 낙관적인 동시 실행이고 '체크하고 설정하는' 패턴을 사용하는 어플리케이션 개발자를 허용합니다.

##### 데이터 모델

에어로스파이크는 어플리케이션 개발을 위해 풍부한 데이터모델을 제공합니다. 데이터모델에 대한 자세한 내용은 [데이터모델](http://www.aerospike.com/docs/architecture/data-model.html)에서 찾을 수 있습니다.

### 단일 키

##### 단일 레코드

에어로스파이크는 에어로스파이크 클러스터에서 데이터를 읽고 쓰기 위해 간단한 인터페이스를 제공합니다.  

다음은 키-값 저장소 작동입니다:  

작업 | 설명
--------|-------------------------------------------------
세트 | 이것의 존재에 관계없이, 레코드를 작성합니다.
생성 | 레코드가 없는 경우, 레코드를 생성하고 지정된 빈을 추가합니다.
업데이트 | 레코드가 없는 경우, 지정된 빈을 추가하거나 업데이트합니다. 지정되지 않은 빈은 그래도 유지됩니다.
대체 | 레코드가 없는 경우, 기존에 있는 모든 빈을 대체하는 지정된 빈을 작성합니다.
제거 | 데이터베이스에서 레코드를 제거합니다.
얻다 | 레코드를 읽습니다. 구체적인 빈을 예상할 수 있습니다.
추가 | 정수 빈에 값을 추가(또는 빼기)합니다.
덧붙이기 | 스트링 또는 바이트 배열 빈에 값을 덧붙입니다.

##### 이것을 사용하는 방법

이 섹션은 [aql](http://www.aerospike.com/docs/tools/aql/index.html)도구를 사용하여 레코드를 ==생성==/==얻기==/==업데이트==하는 간단한 단계를 걸쳐 개발자를 나타냅니다.  

새로운 레코드를 생성하자

	aql> select * from test.demo whe02re PK = 'key'
               Error : (602) AEROSPIKE_ERR_RECORD_NOT_FOUND

			  aql> insert into test.demo(PK,bin) values ('key', 'Bin Value')
			  OK, 1 record affected.
	
    		  aql> select * from test.demo where PK = 'key'
    		  +--------------+
    		  | bin          |
    		  +--------------+
    		  | "Bin Value"  |
    		  +--------------+
    		  1 row in set (0.000 secs )

기존 레코드의 값을 업데이트

	aq1> inset into test.demo (PK, bin) values ('key', 'Updated Bin Value')
    OK, 1 record affected.
	
    aq1> select * from test.demo where PK = 'key'
	+--------------------+
    | bin                |
	+--------------------+
    | "Updated Bin Value"|
	+--------------------+
    1 row in set (0.000 secs)

==빈==에서 정수 값(이전 레코드와 다른)을 가진 새로운 레코드 생성

	aql> insert into test.demo (PK, bin) values ('key1', 1)
    OK, 1 record affected.
	
    aql> select * from test.demo where PK = 'key1'
	+------+
    | bin  |
	+------+
    | 1    |
	+------+
    1 row in set (0.000 secs)
	
    aql> sekect * from test.demo
	+----------------------+
    | bin                  |
	+----------------------+
    | 1                    |
    | "Updated Bin Value"  |
	+----------------------+
    2 row in set (0.016 secs)

마지막으로 ==키==의 레코드를 삭제

	aql> delete from test.demo where PK = 'key'
    OK, 1 record affected.
	
    aql> select * from test.demo
	+--------------+
    | bin          |
	+--------------+
    | "Bin Value"  |
	+--------------+
    1 rows in set (0.010 secs)

모든 겟(읽기)과 세트(쓰기) 작업은 두 개의 추가 매개변수를 취합니다

* 트랜젝션 타임아웃 시간
* 재시도 정책

기본적으로, 재시도 정책은 특정 타임아웃까지 실패한 작업을 재시도하는 것입니다. 트랜젝션 타임아웃은 재시도 정책은 트럼프합니다.  

세트(쓰기) 작업은 시스템에 의해 자동 퇴거에서 레코드가 보호되는 기간을 지정하는 선택적 time-to-live 파라미터를 취합니다. 데이터가 자동으로 퇴거되지 않는 경우에, time-to-live는 무한으로 설정될 수 있습니다.  

언어별 예시는 다음에서 찾을 수 있습니다:  

1. [Java Client - KVS](http://www.aerospike.com/docs/client/java/usage/kvs/write.html)
2. [C Client - KVS](http://www.aerospike.com/docs/client/c/usage/kvs/write.html)

### 배치

##### 배치

에어로스파이크는 배치 요청을 사용하여 네임스페이스 내에 많은 수의 레코드를 검색하는 기능을 제공합니다.  

요청이 아직도 기본 키에 기반하기 때문에 이 기능은 쿼리와 다릅니다. 프로그래머는 요청에 기본 키의 목록을 전달하고, 일련의 결과가 반환됩니다.  

배치 요청의 세가지 형식:  

* 배치 읽기
* 배치 존재
* 배치 읽기 헤더 : 빈이 아닌 메타데이터 레코드만 읽기(expiration/ttl 및 세대)

> 배치 **쓰기**는 아직 지원되지 않습니다. 개별 요청을 통해 쓰는 것은 매우 빠르고, 멀티스레딩 쓰기 요청은 높은 처리량을 얻기 위해 선호되는 방법입니다.

##### 사용

배치 요청은 다음에 사용됩니다:  

* 효율적으로 클라이언트 측 합류 구현
* 계산의 여러 데이터 포인트를 저장하고 검색
* 키의 만료 또는 아직 존재하고 있는지 여부를 결정

##### 예시

다음의 자바 코드는 단일 배치 콜의 여러 레코드를 읽습니다.

	void batchRead(
       AerospikeClient client,
       BatchPolicy policy,
       String namespace,
       String set,
       String binName,
       int size
    ) throws Exception {
        Key[] keys = new Key[size];
        for(int i = 0; i < size; i++) {
           keys[i] = new Key(namespace, set, i+1);
        }

	  Record[] records = client.get(policy, keys, binName);
	
      for (int i = 0; i < records.length; i++) {
          Key key = keys[i];
          Record record = records[i];
	
      if(record != null) {
         Object value = record.getValue(binName);
         // Process value here.
      }
     }
    }

자바 클라이언트 패키지는 또한 배치 존재, 배치 읽기 헤더 그리고 비동기 배치의 사용을 보여주는 예시를 포함합니다.

##### 구현

내부적으로, 클라이언트는 어떤 레코드가 어떤 서버에 있는 지를 결정하고, 각 서버에 특별한 배치 요청을 만듭니다. 이 요청은 검색되는 기본 키의 목록과 선택적인 빈 이름을 가지고 있습니다. 이런 요청은 배치 정책에 따라서 직렬 또는 병렬로 발생합니다. 동기 모드의 병렬 요청은 스레드 풀에서 생성되거나 가져오는 여분의 스레드 사용을 요청합니다.  

일부 클라이언트는 가장 빠른 첫번째 서버에서 데이터를 처리하는 클라이언트 어플리케이션을 허용하면서 이것이 도착하자마자 각 레코드의 전송을 지원합니다.  

스스로 요청을 병렬화하는 것과 비교하여 더 좋은 프로그래밍 인터페이스를 제공할 뿐만아니라, 배치 요청은 각 서버에 단일 네트워크 트랜젝션을 사용합니다. 여러 키는 한 네트워크 요청에 반환됩니다.  

이것은 많은 수의 작은 레코드에서 유용하고, 서버당 레코드수가 적거나 레코드당 반환되는 데이터가 클때 유용하지 않습니다. 모든 데이터가 네트워크에 배치되기 전에 모든 키가 저장소에서 검색되기 때문에 배치 요청은 일부 요청의 지연시간을 증가시킬수 있습니다.  

언어별 예시는 다음에서 찾을 수 있습니다:  

1. [Java Client - Batch](http://www.aerospike.com/docs/client/java/usage/kvs/batch.html)
2. [C Client - Batch](http://www.aerospike.com/docs/client/c/usage/kvs/batch.html)
3. [C# Client - Batch](http://www.aerospike.com/docs/client/csharp/usage/kvs/batch.html)

##### 서버 설정

서버는 배치 성능 조율을 위한 다음과 같은 구성 변수를 제공합니다. 동적 변수는 서버가 실행되는 동안에 변경될 수 있습니다.  

이름 | 기본값 | 최대 | 동적 | 설명
-----|-------|-----|------|------------
batch-max-requests | 5000 |  | 참 | 배치에서 겟/존재 명령의 최대 수. 과도한 메모리 사용때문에 발생하는 서버 불안정에서 예기치못한 큰 배치 요청을 방지하는데 사용됩니다.
batch-priority | 200 | | 참 | 생산 전 순차 명령의 수. 숫자가 높을수록 더 높은 우선순위를 제공합니다.
batch-threads | 4 | 16 | 거짓 | 배치 워커 스레드의 수.

서버는 또한 다음과 같은 배치 통계자료를 제공:  

이름 | 설명
------|-----------------------
batch_initiate | 배치 큐에 위치한 배치의 수. 숫자는 파라미터 오류가 있는 배치를 포함하지 않습니다(즉, 네임스페이스 손실, 최대 요청 초과 등).
batch_errors | 오류때문에 거부되는 배치의 수.
batch_queue | 큐에 남아있는 배치의 수.
batch_tree_count | 모든 배치에 대한 트리 검색의 수.
batch_timeout | 처리되기 전에 서버에서 타임아웃된 배치의 수.
batch_q_process_hist | 배치 성능 히스토그램.

### 스캔

#### 스캔

에어로스파이크는 테이블 또는 네임스페이스의 모든 데이터를 읽기 및 열거하는 기능을 제공합니다.  

스캔은 다음을 하는데 사용:  

* 네임스페이스 또는 세트의 모든(또는 특정 부분의) 데이터를 검색.(읽기 전용 스캔)
* 세트 또는 네임스페이스의 모든 레코드를 스캔함으로써 표준 데이터베이스 유지를 수행하고 선택적으로 사용자 정의 함수를 통해 레코드를 업데이트(읽기 쓰기 스캔).

에어로스파이크 스캔은 기본 데이터베이스 트랜젝션에 영향을 주지않고 수행하도록 설계되었습니다. 스캔 요청은 클러스터의 모든 노드나 한 노드에만 전송됩니다. 노드내에서, 스캔은 모든 노드의 마스터 파티션이나 한 파티션에서 한번에 작업합니다.  

스캔은 다음을 위해 조율하는 파라미터를 가집니다:  

* 스캔 속도 제어
* 동적으로 동시에 실행하는 양을 설정

##### 읽기 전용 스캔

읽기 전용 스캔에서, 스캔은 클라이언트에서 명령을 병렬로 실행시킴으로써 클러스터의 모든 노드에 대한 요청을 시작합니다. 스캔이 각 파티션을 통해 반복되면, 이것은 클라이언트에 각 레코드의 현재 버전을 반환합니다.  

읽기 전용 스캔의 일부 변화는 다음을 포함:  

* 세트에 속하는 레코드에 대해서만 스캔
* 레코드 다이제스트와 메타데이터(세대 및 time-to-live)만 스캔하고 반환
* 선택된 빈을 스캔하고 반환
* 레코드의 특정(임의로 샘플되는) 부분만 스캔하고 반환

인덱스 생성과 백업과 같은 많은 데이터베이스 작업은 또한 근본적인 구현 메커니즘으로 데이터 스캔을 사용합니다.  

이 프로세스동안, 클라이언트 프로그램은 또한 데이터를 쓸 수 있습니다.  

특정 세트의 모든 데이터를 지우는 예시 프로그램은 에어로스피이크 랩에서 찾을 수 있습니다.

##### 읽기 쓰기 스캔

클라이언트에 레코드를 반환하는 순수한 읽기 전용 스캔뿐만 아니라, 이것은 또한 데이터베이스를 스캔하고 각 레코드에 루아 사용자 정의 함수(UDF)를 적용하는 것도 가능합니다. 데이터가 처리되는 경우에, 이것은 위의 클라이언트 측 스캔보다 더 효율적입니다.  

이 특징은 데이터베이스의 유지를 위해 사용할 수 있고, 데이터를 정리하기 위한 모든 규칙을 제공할 수 있습니다.  

예를들어, UDF는 레코드의 ==마지막 방문한==값을 비교하는데 사용됩니다. 값이 너무 오래된 경우(장시간동안 아무 터치가 없었다는 걸 의미)에, 레코드는 제거될 수 있습니다. 또는 ==마지막 방문한== 값이 오래되고, 고객이 지불하지않지만 개인적인 친구가 아닐때 규칙의 조합은 적용될 수 있습니다.  

스캔이 실행될때 포괄적인 정리 기능은 전달된 파라미터를 가지고 쓸 수 있습니다.  

정리 처리가 가능한 데이터 소스 근처에서 수행되기 때문에 이 방법은 매우 강력합니다. 이런 UDF 스캔은 백그라운드에서 실행하고, 클라이언트에 아무 데이터도 반환하지 않습니다. 그들은 일반적으로 관리자 도구를 사용하여 실행하고, 클라이언트 프로그래밍을 요구하지 않습니다.  

스캔 관리에 대한 자세한 내용은 스캔 관리를 참조하세요.  

너는 스캔 관련된 어플리케이션을 개발하는 방법에 대한 자세한 내용을 스캔 개발자 가이드에서 찾을 수 있습니다.

## 쿼리

#### 쿼리

에어로스파이크 쿼리는 보조 인덱스의 사용을 통해 값 기반의 검색을 제공합니다. 쿼리 결과는 간단히 레코드의 세트로 반환되거나 클라이언트에 응답을 반환하기전에 풍부한 사용자 정의 함수 인터페이스를 사용하여 먼저 처리될 수 있습니다. 예를들어:  

* 레코드의 서브세트 또는 주어진 레코드의 빈의 서브세트에만 반환하도록 결정하는 필터 기능.
* 레코드에 [집계](http://www.aerospike.com/docs/guide/aggregation.html) 기능을 수행하는 맵/감소 기능.
* 레코드를 건드는데 사용되는 [레코드 UDF](http://www.aerospike.com/docs/guide/udf.html).

에어로스파이크 쿼리는 빠르고 웹사이트에 접한 프론트 엔드를 위해 높은 동시 실행에서 실행하도록 설계됩니다. 시스템은 다음에 따라 매우 높은 입도에 조율할 수 있습니다:  

* 평균으로 쿼리에 반환되는 레코드의 수- 쿼리의 집합원 수
* 훌륭한 처리량과 지연시간
* 쿼리 로드 vs 읽기 + 쓰기 로드 - 보조 인덱스가 업데이트되는 주파수
* SSD 병렬화 - 훌륭한 쿼리 처리량을 지원하는 iops 요구사항

자세한 내용은 [작업 가이드](http://www.aerospike.com/docs/operations/manage/queries/index.html)를 참고하세요.  

##### 보조 인덱스

보조 인덱스는 SQL의 ==WHERE== 절과 비슷한 열인 빈 값에 대한 인덱스입니다. 이런 인덱스는 다음에 생성됩니다:  

* 정수 값
* 스트링 값

현재, 고유한 인덱스는 다음의 조합에 생성됩니다:  

* 네임스페이스
* 세트 이름
* 빈 이름

세트 이름은 선택적인 파라미터이지만, 세트 이름이 제공되지 않을때, 인덱스는 네임스페이스의 모든 세트가 아닌 널 세트 이름을 가진 레코드를 포함합니다.  

스트링은 내부적으로 UTP-8로 표현되고, 균등 작업은 바이너리 형식으로 지원합니다.  

복잡한 타입의 인덱스와 같은 더 많은 인덱싱 타입은 계획됩니다.  

###### 특징 및 제한

* 에어로스파이크는 시스템의 네임스페이스당 256 보조 인덱스까지 지원합니다.
* 현재 "빠른 재시작"은 지원하지 않습니다.
* 높은 선택 보조 인덱스를 사용하는 쿼리에 대한 조율
* 에어로스파이크에서 사용가능한 쿼리 조건자는 스트링과 수치 인덱스에 대한 "EQUAL"과 수치 인덱스에 대한 "RANGE"를 포함합니다. 현재 오직 한 조건자가 지원됩니다.

구조에 대한 자세한 내용은 [보조 인덱스]를 참조하세요.

##### 사용 사례

쿼리의 일반적인 용도는 다음과 같습니다:  

* 점수판, 상위 성능자, 상위 소득자 등을 보여줍니다.
* 가장 최근의 검색/쿼리/구매/활동 정보를 제공.
* 데이터 세트 검색(예를들어, 동일한 고용주를 가진 또는 내 클럽에 속한 사람)
* 여러 ID를 에 의한 사용자 검색(예를들어, 페이스북-이름, 트위터-핸들 등)

##### 어떻게 사용할 것인가?

이 섹션은 쿼리 어플리케이션을 가지는 데 필요한 단계를 거쳐 개발자를 나타냅니다.  

1. 서버 [설치](http://www.aerospike.com/docs/operations/install/index.html) 및 설정
2. 빈에 인덱스를 생성
3. 인덱스된 빈을 가지는 레코드를 삽입
4. 조건자("where" 절) 구축, 쿼리 요청을 만들기 위해 이것을 사용, 그리고 응답 레코드를 처리

##### 인덱스 생성

인덱스를 만드는 것은 일반적으로 운영 직원에 의해 수행되는 작업입니다. 인덱스는 모든 인덱스 항목을 위해 RAM을 사용하고, 백그라운드 인덱스 생성은 상당한 양의 자원을 취할 수 있습니다. 따라서, 인덱스 생성은 운영 시스템에 신중하게 계획되어야 합니다.  

에어로스파이크 클러스터의 인덱스를 생성하고 관리하는 최고의 방법은 [aql](http://www.aerospike.com/docs/tools/aql/index.html) 도구를 사용하는 것입니다.  

다음의 aql 스크립트는 'user_profile',세트 이름의 'west',빈 이름의 'last_activity'으로 불리는 네임스페이스에 정수 인덱스를 생성합니다.

	aql> CREATE INDEX ix1 ON user_profile.west (last_activity) NUMERIC OK, 1 index added.

인덱스 생성 요청이 클러스터의 한 노드에 도달할때, 에어로스파이크 클러스터는 요청이 클러스터의 모든 다른 노드에 전파되고 모든 노드에 백그라운드의 인덱스 생성을 시작하는 걸 확인합니다. 각 노드는 그 노드에 있는 데이터를 위한 보조 인덱스만 관리합니다.  

인덱스의 생태를 체크:  

	aql > show indexes
	+---------------------------------------------------------------------------------------------------+
    | ns                 bins           set   num_bins   state   index name   sync_state    type |
	+---------------------------------------------------------------------------------------------------+
    | "user_profile"  "last_activity"  "west"     1       "WO"   "ix1"   "synced"   "INT SIGNED"       |
	+---------------------------------------------------------------------------------------------------+
	1 row in set (0.000 secs)

	+---------------------------------------------------------------------------------------------------+
    | ns                 bins           set   num_bins   state   index name   sync_state    type |
	+---------------------------------------------------------------------------------------------------+
    | "user_profile"  "last_activity"  "west"     1       "WO"   "ix1"   "synced"   "INT SIGNED"       |
	+---------------------------------------------------------------------------------------------------+
    1 row in set (0.000 secs)

반환된 명령의 출력은 우리에게 다음을 알립니다:

1. 클러스터의 인덱스 생성 상태(2개 선)를 지닌 각각의 2개 노드가 있습니다.
2. 두 노드에서 인덱스는 쓰기전용("WO") 입니다. 상태가 읽기 쓰기 상태로 변할때만, 이것은 문의될 수 있습니다.

> 모든 노드가 완벽한 인덱스 생성을 가지지 않고, 쿼리가 클러스터에 대해 생성되지 않을때, 오류는 모든 데이터를 반환하지 않고 어플리케이션에 반환됩니다.

인덱스,(에어로스파이크 클러스터에 가공되지 않은 정보 명령을 전송하는)[asinfo](http://www.aerospike.com/docs/tools/asinfo/index.html) 도구,또는 자바 및 씨 에어로스파이크 클라이언트에 존재하는 인덱스 생성 그리고 삭제 API 호출을 생성하는 다른 방법이 있습니다. 하지만 이런 것들은 일반적으로 선호하지 않는 방법입니다.

##### 데이터 삽입

다음, 우리는 쿼리를 위해 준비하는 일부 레코드를 삽입할 수 있습니다.  

다시 말해서, aql이 어플리케이션에 의해 사용되지 않더라도 우리는 aql을 사용하는 방법을 보여줍니다. 데이터를 삽입하는 자바 동일 코드 정보는 [자바 클라이언트- 동기](http://www.aerospike.com/docs/client/java/usage/kvs/write.html) 데이터베이스 쓰기 예시에서 찾을 수 있습니다.  

	aql> INSERT INTO user_profile.west(PK,location,last_activity) VALUES('cookie_100','MA',342)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_101','AZ',345)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_102','CA',345)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_103','AL',340)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_104','TX',347)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_105','MA',323)
    OK, 1 record affected.

##### 간단한 범위 쿼리

데이터를 삽입하여, 우리는 "last_activity" 값의 범위를 지금 문의할 수 있습니다.

	aql> SELECT * FROM user_profile.west WHERE last_activity BETWEEN 340 AND 345
    +----------+---------------+
	| location | last_activity |
    +----------+---------------+
	| "AL"     | 340           |
    | "MA"     | 342           |
	| "CA"     | 345           |
    | "AZ"     | 345           |
	+----------+---------------+
    4 rows in set (0.001 secs)

쿼리가 이것과 연관된 인덱스가 없는 빈에 대해 만들면, 오류는 어플리케이션에 반환될 것입니다.  

쿼리동안, 데이터베이스 클러스터의 노드가 다운되면, 그 노드에 대하여 여전히 실행 진행중인 쿼리는 오류를 반환합니다. 그 결과, 호출 어플리케이션은 오류와 부분 결과를 얻습니다.  

언어별 예시는 다음에서 찾을 수 있습니다:

1. [자바 클라이언트-쿼리](http://www.aerospike.com/docs/client/java/usage/query/query.html)
2. [C 클라이언트-쿼링 레코드](http://www.aerospike.com/docs/client/c/usage/query/query.html)

## 사용자 정의 함수

사용자 정의 함수(UDF)는 에어로스파이크 데이터베이스 서버에서 실행하는 루아 프로그래밍 언어에서 작성된 코드입니다. UDF는 기능과 성능의 두 측면에서 에어로스파이크 데이터베이스 엔진의 능력을 확장하는데 사용됩니다.  

에어로스파이크에서, 우리는 대규모 데이터 타입과 같은 새로운 핵심 기능을 구현하기 위해 UDF를 사용합니다.  

UDF의 두 가지 타입이 있습니다:

* [레코드 UDF](http://www.aerospike.com/docs/guide/record_udf.html)는 단일 레코드에 작업을 수행하는데 사용됩니다. 레코드 UDFs의 용도 중 하나는 파라미터의 세트에 기반한 데이터베이스의 레코드를 업데이트하거나 생성하는 것입니다. 사용자 정의 함수의 이런 타입은 데이터베이스에서 단일 레코드가 되는 첫번째 인수를 기대합니다.  

레코드 UDF의 일반적인 용도는 다음을 포함합니다:  

  * 레코드내 데이터를 사용하여 계산을 수행하고, 결과만 반환.
  * 자동으로 목록에 삽입하고, 다른 목록 요소를 아웃
  * 전달된 인자에 기반한 새로운 레코드 생성
  * 데이터의 모든 서브세트를 반환하기 위해 쿼리를 필터
  * 데이터베이스에 레코드를 다시쓰기(읽기 쓰기 스캔)

* [스트림 UDF](http://www.aerospike.com/docs/guide/stream_udf.html)는 쿼리에서 반환되는 레코드의 스트림이 클러스터의 각 노드에 그리고 클라이언트에 대해 필터되고,변형되고 집계되는 분산된 스트림 집계를 포함하는 분산된 시스템 처리를 위해 사용합니다.  

 스트림 UDFs는 주로 다음에 사용됩니다:  

 * 쿼리의 결과를 반환
 * 쿼리의 결과를 집계

사용자 정의 함수의 이런 타입은 함수가 추가적인 작업을 가지고 처리되는 단일 스트림이 되는 첫번째 인수를 기대합니다.

##### UDF 관리

UDFs는 파일내에 파일의 이름,함수의 이름,그리고 선택적인 하나이상의 매개변수를 지정함으로써 호출됩니다.  

함수가 호출가능하기전에, UDF 파일은 클라이언트 고유 APIs(자바,씨 등) 또는 AQL같이 선택전인 도구를 사용함으로써 에어로스파이크 클러스터에 등록되어야 합니다. 등록은 클러스터의 한 노드에만 대해서 수행될 필요가 있습니다. 클러스터의 시스템 메타데이터 구성요소는 노드의 나머지에 복사본을 배포합니다.

##### UDFs 쓰기

우리는 단일 서버 노드를 사용하는 UDF 개발을 추천합니다. UDF 파일의 새로운 버전이 완료될때, 간단히 파일을 재등록하고, 서버는 최신 버전을 선택합니다. 등록 시간동안에 구문 오류는 감지됩니다. 세부사항을 반환하는 오류는 오류의 본질뿐만 아니라 에러가 발생하는 줄 번호입니다.  

로깅 구성요소는 에어로스파이크 UDF에서 사용가능합니다. 모든 로그 라인은 에어로스파이크 로그 파일로 전송됩니다. 클러스터에서 테스트하면, 이것은 어떤 노드가 함수를 실행했는지 결정하고 실행한 로그파일을 알기 어렵다는 걸 기억하세요.  

(캐치되지 않는 예외와 같이) 실행동안 런타임 오류가 있으면, 에러(루아 에러 스트링 및 줄 번호)는 호출자에게 반환됩니다.  

더 자세한 내용에 대해선 [UDF 가이드](http://www.aerospike.com/docs/udf/udf_guide.html)를 참고하세요.

### 레코드 UDF

레코드 UDF는 단일 레코드를 조작합니다. 레코드 UDF는 스캔과 보조 인덱스 쿼리와 같은 다른 시스템 특징에서 결과 레코드 세트를 실행할 수 있습니다.  

##### 레코드 UDF를 사용하는 이유

**성능**

* 복잡한 구조를 가진 대규모 레코드에 대해서, 레코드 읽기/쓰기 논리를 서버 측에 푸시하는 것은 네트워크 오버헤드를 줄이는 네트워크를 통해 전체 레코드 읽기와 쓰기의 요구사항을 제거합니다.
* 실행 호출을 데이터베이스로 옮기는 것은 복잡한 작업이 2개 트랜젝션 작업의 "비교 및 설정"(CAS)을 수행하는 것과 같은 단일 트랜젝션의 상부 아래에서 수행될 수 있는 걸 의미합니다.

**기능**

* 기본적인 타입(스트링,숫자,바이트 어레이),그리고 컬렉션 타입(리스트,맵), 거의 모든 복잡한 데이터 구조와 함수를 사용하는 것은 UDF를 가지고 생성할 수 있습니다.

[UDF 라이브러리 API 참고](http://www.aerospike.com/docs/udf/api_reference.html)를 참조하세요.  

[에어로스파이크 랩](http://www.aerospike.com/community/labs/)에서 UDFs를 사용하는 프로그램 몇 개의 예시가 있습니다:  

* [UDF 목록 예시](http://www.aerospike.com/community/labs/udf_list_examples.html)
* [JSON 문서 조작을 위한 UDFs](https://github.com/aerospike/complex-data-types)
* [샘플 웹 어플리케이션](https://github.com/aerospike/aerospike-sample-applications)

##### 그들을 어떻게 사용하는지?

이 섹션은 에어로스파이크 서버 클러스터에 레코드 UDF를 구축하고 실행하는 단계를 통해 개발자를 나타냅니다.  

다음 단계들을 포함합니다:

1. 서버를 [설치](http://www.aerospike.com/docs/operations/install/index.html)하고 설정
2. 사용자 정의 함수(UDF) 쓰기
3. 클러스터에 UDF 등록
4. 한 레코드(기본 키 쿼리를 통해) 또는 레코드의 세트(보조 인덱스 쿼리 또는 데이터베이스 스캔을 통해)에 UDF 실행

##### 레코드 UDF 쓰기

루아 프로그래밍 언어(http://www.lua.org/)에 UDF를 씁니다. [UDF 개발자 가이드](http://www.aerospike.com/docs/udf/udf_guide.html)를 참고하세요.  

다음 예시는  ==푸시==와 ==피크==인 두 개의 레코드 UDF 기능을 가집니다. ==푸시==에서, 빈 이름(스트링)과 푸시된 데이터(모든 에어로스파이크 기본 데이터 타입)==값==인 두개의 매개변수가 ==빈==에 전달됩니다. 기능은 ==빈==아래 빈 이름을 저장한 기존 목록을 검색하고 목록의 시작이 되는 들어오는 값을 덧붙입니다.(The function looks up the existing list stored under ==bin== bin name,and prepends the incoming value to be beginning of the list) 이미 존재하지 않을때, 기능은 레코드를 생성합니다.  

==팝==에서, 빈 이름(스트링)과 팝하는 요소의 수인 ==카운트==인 두 개의 매개변수는 또한 ==bein==에 전달됩니다. 기능은 ==bin==으로 불리는 빈에서 요소의 최고 카운트 수는 반환됩니다.

	function push(rec, bin, value)
       local 1 = rec[bin]
	   if (1 == nil) then
           1 = list()
	   end
       list.prepend(1,value)
	   rec[bin] = 1
       local length = #1
	   if aerospike:exists(rec) then
          aerospike:update(rec)
       else
	      aerospike:create(rec)
	   end
       return length
	end
    
    function peek(rec,bin,count)
	   if aerospike:exists(rec)
	   then
	 	  local 1 = rec[bin]
	 	  return list.take(1.count)
	   end
	   return nil
	end

> 첫번째 매개변수 rec는 암시합니다. 다른 두 개의 매개변수가 UDF 실행동안 전달됩니다.

위의 루아 코드를 "list.lua"라고 불리는 파일에 복사하고 저장합니다.

##### 레코드 UDF 등록

UDF가 작성될때, 이것은 에어로스파이크 서버 클러스터에 등록되어야 합니다.  

등록을 위해서, ==aql== 도구는 좋은 선택입니다.

	aql> register module 'list.lua'
    OK, 1 module added.

한번 등록된 UDF는 전체 클러스터 범위내에서 이용할 수 있습니다. 이것은 또한 노드에 지속되서, 등록된 UDF의 뜻은 노드와 기계 재시작을 통해 지속됩니다. 자세한 내용은 [UDF 관리](http://www.aerospike.com/docs/udf/managing_udfs.html) 섹션을 참고하세요.

##### 레코드 UDF 실행

자바에서 UDF를 실행하는 방법을 보기위해서, [자바 클라이언트 메뉴얼](http://www.aerospike.com/docs/client/java/usage/udf/apply.html)로 가세요.  

씨의 튜토리얼에 대해선, [씨 클라이언트 메뉴얼](http://www.aerospike.com/docs/client/c/usage/udf/apply.html)을 확인하세요.  

네트에서, [C# 클라이언트 메뉴얼](http://www.aerospike.com/docs/client/csharp/usage/udf/apply.html)은 저메인입니다.

##### ==aql==을 지닌 레코드 UDF 실행

UDF를 실행하는 가장 쉬운 방법은 ==aql==을 가지는 것입니다. 아래에서 우리는 기본 키 equal 1을 가진 레코드에 ==푸시==기능을 실행합니다. ==푸시==기능은 ==mylist==로 불리는 빈 아래 저장된 목록을 검색합니다.  

목록에 6개의 목록을 푸시합니다.

	aql> execute list.push('mylist',1) on test.demo where PK = '1'
    +------+
	| push |
    +------+
	| 1    |
    +------+
	1 row in set (0.000 secs)
    
    aql> execute list.push('mylist','a') on test.demo where PK = '1'
	+------+
    | push |
	+------+
    | 2    |
	+------+
    1 row in set (0.000 secs)
	
    aql> execute list.push('mylist', 2) on test.demo where PK = '1'
	+------+
    | push |
	+------+
    | 3    |
	+------+
    1 row in set (0.000 secs)
	
    aql> execute list.push('mylist', 'b') on test.demo where PK = '1'
	+------+
    | push |
	+------+
    | 4    |
	+------+
    1 row in set (0.000 secs)
	
    aql> execute list.push('mylist', 3) on test.demo where PK = '1'
	+------+
    | push |
	+------+
    | 5    |
	+------+
    1 row in set (0.000 secs)
	
    aql> execute list.push('mylist', 'c') on test.demo where PK = '1'
	+------+
    | push |
	+------+
	| 6    |
    +------+
	1 row in set (0.000 secs)

인쇄된 응답은 UDF 기느에서 반환한 값과 UDF 기능입니다. 현재 예제에서, ==푸시== 기능은 기능이 수행된 후에 목록의 요소 수를 반환합니다.  

우리는 지금 모든 요소가 정확히 푸시됬는지 확일하는 ==피크== 기능을 실행할 수 있습니다.  

	aql> execute list.peek('mylist', 6) on test.demo where PK = '1'
    +--------------------------+
	| peek                     |
    +--------------------------+
	| ["c", 3, "b", 2, "a", 1] |
    +--------------------------+
	1 row in set (0.000 secs)

UDF를 등록하고 실행하기위해 다음 중 하나(또는 더많이)가 사용됩니다:

* 에어로스파이크 쿼리 언어 [aql](http://www.aerospike.com/docs/tools/aql/) 도구
* 에어로스파이크 CLI [ascli](http://www.aerospike.com/docs/tools/ascli/) 도구
* [씨 클라이언트 - UDF](http://www.aerospike.com/docs/client/c/usage/udf/apply.html)
* [자바 클라이언트 - UDF](http://www.aerospike.com/docs/client/java/usage/udf/apply.html)
* [C# 클라이언트 - UDF](http://www.aerospike.com/docs/client/c/#/usage/udf/apply.html)

##### 제한

* 에어로스파이크 레코드 UDF 시스템은 하나의 반환 값만 지원합니다. 루아가 기능 결과 값으로 반환되는 여러 값을 허용할지라도, 클라이언트에 반환되는 최종 UDF는 반환 값으로 단일 객체를 가져야합니다. 여러 객체가 반환 값으로 필요할지라도, 그것은 그들을 유지하는 목록을 사용하는 것이 좋습니다.
* 에어로스파이크 레코드 UDF 시스템은 현재 여러 레코드 작업을 하지 않습니다.  

 예를들어, 이것은 특정 키에 쓰는 것이 또한 다른 키를 업데이트 할 수 있는 UDF를 쓰는데 편할 것입니다. 이것은 매우 복잡한 데이터 구조의 유지를 허용합니다. 또는 다른 키에서 값을 요청할 수 있는 것은 시물레이션 결합합니다. 에어로스파이크에서, 이런 키는 비동기 작업과 데드락의 가능성을 요구하는 것과 같이 다른 서버에 있을 가능성이 높습니다.

* 에어로스파이크는 제한된 샌드 박싱만 지원합니다-충돌에 대한 보호.

 에어로스파이크는 시간 제한을 제공해서, 너무 많은 시간이 걸리는 개별 UDF 혁신은 오류를 가지고 종료됩니다. 그러나, 이것은 여전히 전체 서버를 충돌할 가능성이 있습니다(특히, 루아나 매우 높은 메모리 사용에서 C 모듈을 호출함으로써).

* 에어로스파이크는 현재 배치 결과에 레코드 UDF를 지원하지 않습니다.

### 스트림 UDF

에어로스파이크는 분산 방식으로 쿼리의 결과를 필터,변형,그리고 집계하는 능력을 제공합니다.  

이것은 우리가 스트림 UDF라고 부르는 데이터의 스트림을 처리하도록 설계된 사용자 정의 함수에 의해 만들 수 있습니다. 스트림 UDF는 데이터의 스트림을 수행하는 작업의 순서를 정의하는 사용자 정의 함수입니다. 집계는 여러 기계의 힘을 이용함으로써 분산 방식으로 실행합니다.  

[에어로스파이크 랩](http://www.aerospike.com/community/labs/)은 스트림 UDFs 사용의 많은 예시를 포함합니다.

* [여러 필터를 가진 쿼리](http://www.aerospike.com/community/labs/query_multiple_filters.html)는 임의의 필터를 제공하기 위해 스트림 UDFs를 사용합니다.
* [스트림 항공 비행 시간](http://www.aerospike.com/community/labs/realtime_analytics.html) 북미 비행 데이터를 로드하고, 그 데이터세트를 넘는 쿼리 예시를 보여줍니다.
* [트윗-스파이크](https://github.com/aerospike/tweetaspike)는 사용 패턴을 결정하기 위해 스트림 UDF를 사용하는 것을 포함하는 인터넷 어플리케이션 예시입니다.

##### 작업

현재, 스트림 UDF는 다음 작업의 유형을 지원합니다:

* 필터 - 조건을 충족하는 스트림의 데이터를 유지.
* 맵 - 일부 데이터 정보를 변형.
* 집계 - 단일 값으로 데이터의 파티션을 감소.
* 감소 - 단일 값으로 데이터의 스트림을 감소.

작업은 기본으로 간주되고, 더 복잡한 작업을 구축하기위해 사용될 수 있습니다. 이런 기본을 이용하는 방법에 대한 더 자세한 내용은 [UDF 개발자 가이드](http://www.aerospike.com/docs/udf/developing_stream_udfs.html)를 참고하세요.

##### 필터

조건 ==p==를 사용하는 스트림에서 값을 차단합니다. 조건 ==p==는 스트림의 각 값을 테스트하고 값이 통과하면 ==참==을 반환하거나 값이 드롭되면 ==거짓==을 반환하는 기능입니다.

	filter(p: (a: Value) -> Boolean) -> Stream

**변수**

* ==p== - 스트림의 각 값에 적용되는 조건

**반환**

차단된 값의 스트림.

##### 맵

식별 함수 ==f==를 사용하는 다른 값으로 값을 변형합니다.

	map(f: (a: Value) -> Value) -> Strem

**변수**

* ==f== - 스트림의 각 값에 적용되는 식별 함수.

**반환**

변형된 값의 스트림.

##### 감소

각 값에 ==op== 연상 바이너리 작업을 적용하면서 단일 값에 스트림의 값을 줄입니다. ==op==에서 반환 값은 ==op== 다음 호출에 변수 ==a==로 사용됩니다.

	reduce(op: (a: Value, b : Value) -> Value) -> Stream

**변수**

* ==op== - 스트림의 각 값에 적용되는 연상 바이너리 작업.

**반환**

단일 값을 포함하는 스트림.

## 집계

연상 바이너리 연산자 ==op==를 사용하는 스트림의 값을 집계. ==op==에서 반환 값은 다음 호출==op==에 매개변수 ==a==로 사용됩니다. 첫번째 호출 ==op==에서, 값은 매개변수 ==x==입니다.

	aggregate(x: Value, op: (a: Value, b: Value) -> Value) -> Stream

**매개변수**

* ==x== - 연산자 ==op==를 통과하는 초기(중립) 값.
* ==op== - 스트림의 각 값에 적용되는 식별 기능.

**반환**

단일 값을 포함하는 스트림.

### 집계

에어로스파이크의 집계 프레임워크는 빠르고 유연성 있는 쿼리 작업을 허용합니다. 이 계획적인 프레임워크는 초기의 맵 기능이 컬렉션을 넘어 실행하는 MapReduce 시스템과 비슷하고, 매우 병렬적으로 결과를 방출합니다. 이런 결과는 다음 맵 단계,감소 단계, 그리고 집계 단계 중 하나의 파이프라인을 가로지릅니다.  

하둡이나 자바를 사용하는 다른 프레임워크와 달리, 에어로스파이크의 집계 시스템은 루아를 사용하여 구현됩니다. 각 클라이언트는 독릭접으로 결과를 카운트하는 클러스터의 모든 서버에 집계 요청을 전송하고, 요청 클라이언트에 다시 개별 결과를 전송합니다.  

에어로스파이크의 집계 프레임워크는 집계가 인덱스에 대하여 권장되는 (특히, WHERE 구) 다른 시스템과 다릅니다. 인덱스에 대하여 차단함으로써, 성능은 매우 높을 수 있습니다. 집계는 테이블과 또한 전체 네임스페이스를 넘어 지원됩니다.  

그런 다음에 클라이언트는 결과를 더하기 위해 루아에도 있는 최종 감소 단계를 실행합니다.

##### 사용 사례

집계는 종종 데이터베이스 내부의 집계 합과 카운트를 위해 사용됩니다.  

에어로스파이크 랩의 예인 [에어로스파이크를 지닌 실시간 분석](http://www.aerospike.com/community/labs/realtime_analytics.html)은 코드와, 어떤 항공이 2012년 1월 말 비행의 최대 개수를 가지는지 결정하는 실제 데이터세트를 보여줍니다.  

실시간 대시보드는 에어로스파이크 집계를 위해 훌륭한 사용법입니다. 업데이트 시간을 가진 빈에 보조 인덱스를 가짐으로써, 집계는 최근에 변경된 레코드에 통계를 빨리 모을 수 있습니다. 인덱스 없이 전체 데이터세트에 작용하는 표준 MapRededuce 시스템과 비교해서, 에어로스파이크 집계는 더 적은 레코드를 만질 수 있습니다.

##### 그들을 어떻게 사용하는지?

이 섹션은 집계 어플리케이션을 가질 필요가 있는 단계를 통해 개발자를 나타냅니다.

1. [쿼리 어플리케이션](http://www.aerospike.com/docs/guide/query.html) 설정. (섹션-그들을 어떻게 사용하는지)

  * 빈에 인덱스를 생성.
  * 인덱스된 빈을 가진 레코드를 삽입.

2. 루아에 [집계 모듈](http://www.aerospike.com/docs/udf/developing_stream_udfs.html)을 생성.
3. 집계 모듈의 경로를 설정.
4. 클러스터에 모듈을 등록.
5. ("where" 구)조건을 가진 집계 쿼리를 구축.

##### 계획적으로 집계 사용

**자바**에서, [집계에서 자바 클라이언트 메뉴얼 섹션](http://www.aerospike.com/docs/client/java/usage/query/aggregate.html)을 참고.  

**씨**에서, [집계에서 씨 클라이언트 메뉴얼 섹션](http://www.aerospike.com/docs/client/c/usage/query/aggregate.html)을 참고.  

**네트**에서, [집계에서 씨# 클라이언트 메뉴얼 섹션](http://www.aerospike.com/docs/client/csharp/usage/query/aggregate.html)을 참고.

##### ==aql==을 가진 집계 사용

애드혹 집계를 형성하는 방법을 쉽게 보기위해서, 우리는 에어로스파이크의 ==aql== 명령 줄 도구를 사용하여 단계를 보여줍니다.  

###### 인덱스 생성

다음 aql 스크립트는 'user_profile',set-name 'west',bin-name 'location'으로 불리는 네임스페이스에 스트링 인덱스를 생성합니다.  

	aql> CREATE INDEX ix2 ON user_profile.west (location) string
    OK, 1 index added.

> 위의 쿼리를 실행하기전에 네임스페이스 ==user_profile==을 위한 ==aerospike.conf== 파일을 확인합니다. 이것이 거기에 없다면 아래와 같이 이것을 추가하세요. 예를들어 목적 인메모리 저장소 엔진이 사용됩니다. 쿼리는 또한 온디스크 네임스페이스를 가지고 사용될 수 있습니다.

	namespace user_profile {
       replication-factor 2
       storage-engine memory
    }

###### 데이터 삽입

다음, 집계를 위해 준비하는 적은 수의 레코드를 삽입합니다.  

다시 말해서, aql이 어플리케이션에 의해 사용되지 않더라도, 우리는 aql 사용법을 보여줍니다. 데이터를 삽입하는 자바 동등 코드 정보는 [자바 클라이언트-동기화](http://www.aerospike.com/docs/client/java/usage/kvs/write.html) 데이터베이스 쓰기 예시에서 찾을 수 있습니다.

	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_100','MA',342)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_101','AZ',345)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_102','CA',345)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_103','AL',340)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_104','TX',347)
    OK, 1 record affected.
	aql> INSERT INTO user_profile.west (PK,location,last_activity) VALUES('cookie_105','MA',323)
    OK, 1 record affected.

###### 간단한 집계 모듈

아래의 루아 코드는 위치에서 사용자의 수를 카운트합니다. 이 방법은 ==맵== 다음에 집계 단계 대신에 ==감소== 기능을 사용합니다. 그리고 ==집계== 기능은 더 효율적이지만, ==맵==과 ==감소== 시스템은 더 융통성이 있습니다.

	file: aggregate.lua

	function count(s)
       function mapper(rec)
               return 1
       end
       local function reducer(v1, v2)
          return v1 + v2
       end
       return s : map(mapper) : reduce(reducer)
    end

스트림 작동은 다음과 같이 정의:

	- 매퍼는 각 프로파일 레코드를 위해 정수를 반환.
	- 감소는 카운트를 제공하기 위해 이런 모든 것을 추가.

자세한 내용은 [스트림 UDF 개발자 가이드](http://www.aerospike.com/docs/udf/developing_stream_udfs.html)를 참고하세요.

##### AQL에 루아 모듈의 경로 설정

사용자는 클라이언트 측에 루아 모듈 경로를 설정할 필요가 있습니다. 최종 감소 단계가 클라이언트 측에서 실행하기 때문에 또한 응답이 클러스터의 모든 노드에서 반환될때 이것은 요구됩니다. 사용자는 aql에 루아 모듈의 상대 경로를 설정할 수 있습니다. 예를들어, aggregate.lua가 '/home/user/lua_code'아래에 있고 사용자가 '/home/user'에서 시작하는 aql일때, 아래의 aql 명령은 경로를 설정합니다.

	aql> set LUA_USERPATH 'lua_code'

###### 클러스터에 루아 모듈 등록

	aql> register module 'lua_code/aggregate.lua'
    OK, 1 module added.

###### 집계 쿼리 구축

	aql> AGGREGATE aggregate.count() ON user_profile.west WHERE location = 'MA'
    +--------+
	| coount |
    +--------+
	| 2      |
    +--------+
	1 row in set (0.007 secs)

더 자세한 내용은 [aql-쿼링 레코드](http://www.aerospike.com/docs/tools/aql/querying_records.html)을 참고하세요(섹션 - '쿼리 결과에 집계').

## 데이터 타입

에어로스파이크는 데이터의 수를 위해 구축 지원을 가집니다. 이러한 데이터 타입은 아마도 [빈](http://www.aerospike.com/docs/architecture/data-model.html)과 인수의 값에 사용하고 사용자 정의 함수에서 값을 반환합니다.  

##### 기본 타입

###### 정수

정수는 64비트 부호를 가진 정수[-(2^63^)에서 2^63^-1]입니다.

* 각 정수는 저장소의 8바이트(64비트)를 요구합니다.
* [보조 인덱스](http://www.aerospike.com/docs/architecture/secondary-index.html)는 정수 타입을 지원합니다.

###### 스트링

스트링은 ==널== 종단 바이트 스트링입니다. 스트링은 인코딩에 바운드되지 않습니다. 스트링은 ==널== 종단자를 가진 불투명한 바이트 어레이로 처리됩니다. 이것은 스트링내에서 사용되는 어떤 문자 인코딩을 허용합니다.

* 스트링은 레코드 크기에 의해 임의의 크기로 바운드하지만, 이것은 매우 큰 스트링을 저장하는데 권장되지 않습니다.
* [보조 인덱스](http://www.aerospike.com/docs/architecture/secondary-index.html)는 스트링 타입에 지원합니다.

###### 바이트

바이트는 특정 크기의 바이트 배열입니다. 이것은 저장되는 모든 타입의 모든 바이너리 데이터를 허용합니다. 이것들은 널 종단이 아니라는 걸 주의하세요.

##### 복잡한 데이터 타입

###### 리스트

리스트는 정렬된 값의 모음입니다. 리스트는 지원하는 데이터 타입의 모든 값을 포함합니다. 리스트의 데이터는 순서대로 삽입하고 순서는 저장하거나 검색할때 유지됩니다.

	aql> insert into test.demo (PK, bin) values ('key', 'JSON[1,2,3]')
    OK, 1 record affected.
	
    aql> select * from test.demo where PK = 'key'
	+-----------+
    | bin       |
	+-----------+
    | [1, 2, 3] |
	+-----------+
    1 row in set (0.000 secs)

###### 맵

맵은 각 키가 모음에 한번 나타나고 값과 연관된 키 값 쌍의 모음입니다. 키와 맵의 값은 지원하는 데이터 타입 중 하나입니다.

	aql> insert into test.demo (PK, bin) values ('key', 'JSON["str1", "str2", "str3"]')
    OK, 1 record affected.
	
    aql> select * from test.demo where PK = 'key'
	+--------------------------+
    | bin                      |
	+--------------------------+
    | ["str1", "str2", "str3"] |
	+--------------------------+
    1 row in set (0.000 secs)

리스트와 맵은 다른 곳에 하나의 임의 중복을 허용합니다. 어떤 임의 문서가 생성되는 지 사용

	aql> insert into test.demo (PK, bin) values ('key', 'JSON["string", 10, ["list", "of", "strings"], {"map":1, "of":2, "items":3}]')
    OK, 1 record affected.
	
    aql> select * from test.demo where PK = 'key'
	+-------------------------------------------------------------------------+
    | bin                                                                     |
    +-------------------------------------------------------------------------+
	| ["string", 10, ["list", "of", "strings"], {"items":3, "of":2, "map":1}] |
    +-------------------------------------------------------------------------+
	1 row in set (0.000 secs)

==aql==에 전달된 JSON 문서는 이것의 스트링,정수,리스트,맵 값을 가진 목록으로 전환합니다.

##### 원초 형식

에어로스파이크는 또한 어플리케이션의 프로그래밍 환경에 직렬화 원초 형식으로 데이터를 저장하기 위한 지원을 제공합니다. 다른 지원한 타입과 달리, 이러한 타입은 사용자 정의 함수와 인덱스내에서 사용 가능하지 않습니다.  

다음은 원초 형식이 지원되는 프로그래밍 환경입니다.  

* 자바
* C#
* Python
* Ruby

언어별 예시는 다음에서 찾을 수 있습니다:

1. [자바 클라이언트-예시](http://www.aerospike.com/docs/client/java/)
2. [씨 클라이언트-예시](http://www.aerospike.com/docs/client/c/)

## 대규모 데이터 타입

##### 소개

대규모 데이터 타입(LDTs)은 수백 수천의 객체 모음을 포함하는 개별 레코드 빈을 허용합니다, 그리고 그들은 효율적으로 인데이터베이스를 저장하고 처리하기 위해 이런 컬렉션을 허용합니다. 그래서, 사용자들은 레코드 또는 레코드 빈 크기 제한과 관련없이 대규모 데이터의 양을 빠르고 효율적이게 조장하기 위해 LDTs를 고용할 수 있습니다.  

논리적으로, LDT 인스턴스는 빈 값으로 표시되지만, 이것은 레코드 자체에 연속적으로 저장되지 않습니다. LDTs는 레코드의 빈에 각각 연결된 여러 레코드간 데이터 모음을 확산하기 위해 ==서브 레코드==([LDT 구조](http://www.aerospike.com/docs/architecture/ldt.html)에서 설명되있음)라고 불리는 메커니즘을 이용합니다.  

대규모 데이터 타입 특징은 몇가지 장점을 제공:

* 개별 항목에 대한 접근은 1에서 2개의 SSD IOPs만 요구합니다. 변경 사항은 바로 메모리에 전체 객체를 읽고 이것을 처리하고,디스크에 이것을 다시 쓸 필요없는 데이터의 작은 덩어리로 이뤄집니다.
* 관련된 객체 API에서 정의된 것처럼, 처리는 이것의 일반 접근 패턴과 각각의 대규모 데이터 타입을 최적화합니다.
* 개발자는 서버에서 클라이언트에 그들이 반환되기 전에 값을 변경하거나 차단하는 UDFs를 통한 접근을 더 최적화합니다.
* 처리는 클라이언트 어플리케이션을 없애고 네트워크 대역폭 사용을 줄이면서 서버에 푸시됩니다.

##### 작동법

###### 네임스페이스 설정

너가 어플리케이션에 LDTs 사용을 시작하기 전에 너는 네임스페이스를 설정해야 합니다.  

==aerospike.conf==파일의 네임스페이스 스탠장에 ==ldt-enabled true==설정을 추가합니다.

	namespace test {
       ...
       ldt-enabled true
       ...
       storage-engine device {
          ...
       }
    }

###### ascli 또는 aql 사용

동작의 대규모 데이터 타입(LDTs)를 보는 가장 빠른 방법은 사용자 정의 함수(UDFs)라고 불리는 에어로스파이크 도구 중 하나를 사용하는 것입니다. LDT 기능이 특별한 시스템 UDF일지라도, 이것은 여전히 다른 UDF 같이 호출됩니다.  

[예시](http://www.aerospike.com/docs/guide/ldt_examples.html)는 에어로스파이크 [ascli](http://www.aerospike.com/docs/tools/ascli/) 도구와 [aql](http://www.aerospike.com/docs/tools/aql/)도구를 사용합니다. 두 도구는 에어로스파이크 서버에 작은 작업을 수행하는데 편리합니다.  

[ascli](http://www.aerospike.com/docs/tools/ascli/) 도구 또는 [aql](http://www.aerospike.com/docs/tools/aql/) 도구 중 하나를 사용하여, 단순히 LDTs와 상호작용하는 다양한 명령을 호출합니다. 리스트는 우리가 4개의 대규모 데이터 타입의 각각을 조정하기 위해 [ascli](http://www.aerospike.com/docs/tools/ascli/) 도구와 [aql](http://www.aerospike.com/docs/tools/aql/)을 사용하는 방법을 묘사한 페이지에 대한 링크를 포함합니다.

#### LDT 컬렉션

현재 각각 자신의 행동과 사용 패턴을 가진 LDT 컬렉션의 4가지 타입이 있습니다. 우리는 기본 컬렉션 작업과 일치하는 LDT 동사를 보여주기 위해서 아래의 테이블을 생성:

이름 | 쓰기 | 읽기 | 제거 | 차단
------------|---------|---------|------------|---------|
대규모 리스트 | add() | find() | remove() | filter()
대규모 맵 | put() | get() | remove() | filter()
대규모 세트 | add() | get() | remove() | filter()
대규모 스택 | push() | peek() | pop() | filter()

* **쓰기**는 컬렉션에 요소를 추가하는데 사용됩니다.
* **읽기**는 컬렉션에서 요소를 읽고 위치시키는데 사용됩니다.
* **제거**는 컬렉션에서 요소를 제거하는데 사용됩니다.
* **차단**은 컬렉션을 스캔하고 조건 필터에 적용하는데 사용됩니다.

API가 다른 LDT 중 하나와 다르다는 걸 유의하세요. 우리는 이것을 컬렉션 타입의 동작을 참으로 유지하기 위해 사용합니다(스택에 하나를 **푸시**하지만, 맵으로 **넣습니다**.).

> LDT 요소는 저장소 레코드의 크기에 의해 제한됩니다. 요소 갯수는 제한되지 않지만, 개별 요소 크기는 제한됩니다. 클러스터가 저장소(플래시 또는 디스크 백 DRAM)로 구성될때, 보통 저장소 레코드는 최대 LDT 요소 크기가 되는 128KB 또는 1MB로 제한됩니다. 에어로스파이크 서버는 현재 저장소 레코드를 1MB 크기 이상으로 지원하지 않습니다.

다음 LDT 서브 섹션에서, 우리는 순서대로 각각의 LDT를 분석합니다. 우리는 각각의 LDT 컬렉션을 소개하고, 그들의 특징을 설명하고 사용 예시를 보여줍니다.

##### 대규모 리스트(LLIST)

대규모 정렬된 리스트(LLIST)는 분류된 목록을 업데이트하고 검색하기 위해 최적화되어있습니다. 여전히 실질적으로 원하는 크기로 컬렉션이 커지는게 가능한 동안에, 이것은 컬렉션의 모든 시점에서 데이터에 접근할 수 있습니다.

![LDT_Operations_LList.png](LDT_Operations_LList.png)

> 표1  
대규모 정렬된 리스트

[대규모 리스트 세부사항](http://www.aerospike.com/docs/guide/llist.html)의 이 섹션은 사용법을 설명하고, 어플리케이션 프로그래밍 인터페이스(API)를 나타내고, 대규모 리스트 컬렉션 타입의 예를 제공합니다.

##### 대규모 맵(LMAP)

대규모 맵(LMAP)은 키(맵,해시테이블,지시,등)와 연관된 값을 위해 최적화 되어있습니다. LMAP 인스턴스는 효율적으로 키 값 쌍의 지속적으로 커지는 컬렉션을 관리하는 능력을 가진 사용자를 제공합니다.

![LDT_Operations_LMap.png](LDT_Operations_LMap.png)

> 표2  
대규모 맵

[대규모 맵 세부사항](http://www.aerospike.com/docs/guide/lmap.html)의 이 섹션은 사용법을 설명하고, 어플리케이션 프로그래밍 인터페이스(API)를 나타내고, 대규모 맵 컬렉션 타입의 예시를 제공합니다.

##### 대규모 세트(LSET)

대규모 세트(LSET)는 고유 값을 분류하고 세트의 값의 존재를 확인하기 위해 최적화 되어있습니다.

![LDT_Operations_LSet.png](LDT_Operations_LSet.png)

> 표3  
대규모 세트

[대규모 세트 세부사항](http://www.aerospike.com/docs/guide/lset.html)의 이 섹션은 사용법을 설명하고, 어플리케이션 프로그래밍 인터페이스(API)를 나타내고, 대규모 세트 컬렉션 타입의 예시를 제공합니다.  

##### 대규모 스택(LSTACK)

대규모 스택(LSTACK)은 푸시와 피크와 같은 스택에 기반한 작업을 위해 최적화된 대규모 데이터 타입입니다. lstack은 매우 큰 데이터의 컬렉션이 지속적으로 커지는 능력을 제공합니다.

![LDT_Operations_LStack.png](LDT_Operations_LStack.png)

> 표4  
대규모 스택

[대규모 스택 세부사항](http://www.aerospike.com/docs/guide/lstack.html)의 이 섹션은 사용법을 설명하고, 어플리케이션 프로그래밍 인터페이스(API)를 나타내고, 대규모 스택 컬렉션 타입의 예시를 제공합니다.

#### 기본 및 고급 LDT 특징

LDTs는 상대적으로 적은 크기(1kb 아래)의 객체의 반(수십만명 까지)을 위해 "상자밖"을 작동하도록 구성되어 있습니다. 더 큰 컬렉션(예: 엄청난 양의 객체) 또는 더 큰 컬렉션 요소(예: 수백만 킬로미터)를 요구하는 어플리케이션을 위해, 몇개의 추가 구성이 필요합니다. 간단히, 기본 LDT 작업(예: 읽기,쓰기,제거)만 요구하는 어플리케이션을 위해선, 표준 기능으로 충분합니다. 그러나, 저장소 변화(예: 압축 또는 암호화),조건 차단 또는 복잡한 객체 조정과 같은 추가 기능들을 요구하는 어플리케이션은 LDTs의 고급 특징을 이용할 필요가 있습니다.  

##### 기본 LDT 특징

각 대규모 데이터 타입은 작업의 공통 서브세트를 제공:

* 컬렉션에 객체 쓰기
* 컬렉션에서 객체 읽기
* 컬렉션에서 객체 제거
* 컬렉션을 스캔(옵션 필터 포함)
* 컬렉션의 크기를 계산
* 컬렉션 인스턴스의 구성 설정 읽기

컬렉션 타입에 따라, 컬렉션 특유의 추가 기능이 있습니다. 예를들어, 대규모 정렬된 리스트는 다른 컬렉션 타입이 수행하지 않은 쿼리의 범위를 제공합니다.

##### 고급 LDT 특징

각각의 대규모 데이터 타입은 다른 설정 매개변수와 다른 고급 기능을 가집니다. 다음 섹션인 LDT 인터널은 LDTs가 작동하는 법과 그들이 초기에 어떻게 구성되는지를 설명합니다. 그 다음에, 우리는 LDT 설정 섹션의 이런 고급 특징을 이용하는 법을 설명합니다.

##### LDT 인터널

이 섹션인 [LDT 인터널](http://www.aerospike.com/docs/guide/ldt_internals.html)은 LDTs(llist,lmap,lset,lstack)의 각각의 내부 구조와 그들이 초기에 어떻게 구성되는 지를 설명합니다. 이것은 또한 UDFs를 통해 추가 작업(조건 차단, 저장소 변환, 복잡한 객체 관리)을 제공하는데 사용되는 메커니즘을 설명합니다. 이 지식을 가지고, 이것은 LDTs의 고급 특징을 이용할 수 있습니다.

##### LDT 구성

이 섹션인 [LDT 구성](http://www.aerospike.com/docs/guide/ldt_configuration.html)은 다양한 LDT 내부 설정([LDT 인터널](http://www.aerospike.com/docs/guide/ldt_internals.html)로 덮인 )과 특정 어플리케이션의 필요를 더 좋게 지원하는 LDT 인스턴스를 가지는 설정을 변경하는 방법을 설명합니다.

### 대규모 리스트

#### 대규모 정렬된 리스트

![LDT_Operations_LList.png](LDT_Operations_LList.png)

대규모 정렬된 리스트(llist)는 분류된 리스트를 업데이트하고 검색하기 위해 최적화되어 있습니다. 여전히 실질적으로 원하는 크기로 컬렉션이 커지는게 가능한 동안에, 이것은 컬렉션의 모든 시점에서 데이터에 접근할 수 있습니다.  

큰 리스트는 특히 단순한 값(숫자,스트링)이나 복잡한 객체(리스트,맵,문서) 중 하나로 정렬된 데이터의 모든 타입을 저장하는데 적합합니다. 저장되고 있는 객체가 함축적으로 비교할 수 있는 원자 값을 가지지 않을때, 사용자는 비교를 위해 사용되는 객체에서 간단한 값을 얻는 기능을 지원해야 합니다.

##### 특징

대규모 정렬된 리스트는 다음 기능을 가집니다:

* 원자 또는 복잡한 객체 관리
* 무한 저장소
* UDF 조건 필터, UDF 변환
* 단일 항목 또는 여러 항목 삽입
* 선택 UDF 필터를 가진 단일 값 검색
* 선택 UDF 필터를 가진 범위 값 검색
* 선택 UDF 필터를 가진 풀 스캔
* 단일 아이템 업데이트
* 최소 및 최대 검색
* 단일 값 제거

##### 사용 사례

대규모 정렬된 리스트는 정렬된 데이터의 모든 타입을 저장하는데 적합합니다. 데이터는 숫자또는 스트링과 같은 단순한 원자 값 또는 리스트,맵 또는 문서와 같은 복잡한 값이 될 수 있습니다. 객체가 원자인 경우에, 대규모 정렬된 리스트는 단순한 리스트 관리를 제공할 수 있습니다(예: 이름 또는 숫자 검색). 객체가 복잡한 경우에, 대규모 정렬된 리스트는 객체의 세트를 넘어 기본 또는 보조 인덱스 같은 인덱싱 서비스를 제공합니다.  

일반적인 사용 예시는 복잡한 객체의 컬렉션이 있는 기본 키로 LLIST를 이용합니다(예: 맵). LLIST는 빠른 검색과 객체에 업데이트하는 능력을 제공합니다. LLIST는 객체와 상응하는 키 값의 검색을 지닌 LMAP와 같은 방법으로 사용됩니다. 그러나 LLIST와 LMAP의 주된 차이점은 LLIST가 범위 쿼리를 지원한다는 것입니다. 그래서 LLIST를 가지고, 이것은 "L"로 시작하는 모든 이름 또는 "L"에서 "T"까지 모든 이름에 대해서 검색할 수 있습니다. 보여지는 예시에서,  고객 연락 객체의 리스트는 성에 의해 정렬됩니다.(표 1)

![LDT_Record_LList.png](LDT_Record_LList.png)

> 표 1  
고개 연략을 관리하는 큰 리스트를 가진 레코드

#### 대규모 데이터 타입(LDT) 어플리케이션 프로그래밍 인터페이스(API)

LDTs는 다음에서 접근될 수 있습니다:

* [사용자 정의 함수](http://www.aerospike.com/docs/udf/udfs_and_ldts.html)
* [에어로스파이크 C 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/c/usage/ldt/index.html)
* [에어로스파이크 자바 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
* [에어로스파이크 C# 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/csharp/usage/ldt/ldt.html)

#### 완벽한 예시

이 예제에서 우리는 에어로스파이크 [ascli](http://www.aerospike.com/docs/tools/ascli/) 도구와 [aql](http://www.aerospike.com/docs/tools/aql/) 도구를 사용하여 각각의 대규모 리스트 기능의 사용을 설명합니다. 두 도구는 에어로스파이크 서버에 작은 기능을 수행하는데 편리합니다.  

먼저 이것과 비슷한 ==ascli== 명령을 사용하여 우리는 대규모 리스트에 요소 갯수를 삽입:

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 55

이 명령의 세부 사항을 보자. ==ascli udf-record-apply==는 네임스페이스 ==test==, 세트 ==demo==, 키 ==Key_1==을 사용하여 레코드에 UDF를 호출합니다.  

우리가 호출한 UDF는 패키지 ==llist==에 있고, 이 패키지는 대규모 리스트의 구현입니다.  

여기에서 동등한 ==aql==은 다음과 같습니다:

	execute llist.add('LLIST_BIN', 55) on test.demo where pk = 'Key_1'

==execute== 주요 단어는 네임스페이스의 레코드에 ==llist.add== 기능을 호출하고 키 ==where pk : 'Key_1'==에 ==on test.demo==를 설정합니다.

##### add()

==add()==기능은 대규모 리스트에 요소를 추가합니다, 이것은 리스트에 추가된 값인 단일 매개변수를 사용합니다.  

이것이 존재하지 않을때 ==add()== 기능은 함축적으로 탑 레코드를 생성합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 55
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 5
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 25
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 75
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 15
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 45
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 35

###### aql

	execute llist.add('LLIST_BIN', 55) on test.demo where pk = 'Key_1'
    execute llist.add('LLIST_BIN',  5) on test.demo where pk = 'Key_1'
	execute llist.add('LLIST_BIN', 25) on test.demo where pk = 'Key_1'
    execute llist.add('LLIST_BIN', 75) on test.demo where pk = 'Key_1'
	execute llist.add('LLIST_BIN', 15) on test.demo where pk = 'Key_1'
    execute llist.add('LLIST_BIN', 45) on test.demo where pk = 'Key_1'
	execute llist.add('LLIST_BIN', 35) on test.demo where pk = 'Key_1'

##### find()

대규모 리스트에서 요소를 검색하기 위해서 너는 ==find()== 기능을 사용하고, 이것은 ==요소== 매개변수 ==25==를 사용하고 ==25==의 값을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "find" "LLIST_BIN" 25

###### aql

	execute llist.find('LLIST_BIN', 25) on test.demo where pk = 'Key_1'

##### scan()

==scan()== 기능은 전체 대규모 리스트를 통해 스캔하고 대규모 리스트의 모든 값을 반환합니다.  

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "scan" "LLIST_BIN"

###### aql

	execute llist.scan('LLIST_BIN') on test.demo where pk = 'Key_1'

##### size()

==size()==는 대규모 리스트의 요소 갯수를 반환합니다.

###### ascli

ascli udf-record-apply "test" "demo" "Key_1" "llist" "size" "LLIST_BIN"

###### aql

	execute llist.size('LLIST_BIN') on test.demo where pk = 'Key_1'

##### remove()

==remove()== 기능은 대규모 리스트에서 요소를 제거하고, 이것은 ==요소== 매개변수와 요소가 ==45==인 예제에서 사용합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "remove" "LLIST_BIN" 45

###### aql

	execute llist.remove('LLIST_BIN', 45) on test.demo where pk = 'Key_1'

##### get_config()

==get_config()== 기능은 관련있는 구성 가능한 설정과 그들의 현재 값을 나타내는 맵 객체를 반환합니다.

###### ascli

	ascli udf-record--apply "test" "demo" "Key_1" "llist" "get_config" "LLIST_BIN"

###### aql

	execute llist.get_config('LLIST_BIN') on test.demo where pk = 'Key_1'

##### get_capacity()

==get_capacity()== 기능은 LDT 인스턴스의 최대 용량을 반환합니다. 대규모 리스트 LDT는 기본적으로 최대 용량(이것은 기본적으로 무한대로 커질 수 있음)을 가지지 않지만, 이것은 과용 우발적 저장소를 막기위해 최대 크기를 설정할 수 있습니다. get_capacity()가 설정 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 수를 반환합니다. 거기에 (대규모 리스트와 대규모 스택에 대한)제한이 없을때, get_capacity는 0을 반환합니다.

> 대규모 리스트 LDT는 기본적으로 최대 용량(이것은 기본적으로 무한대로 커질 수 있음)을 가지지 않지만, 이것은 과용 우발적 저장소를 막기위해 최대 크기를 설정할 수 있습니다. get_capacity()가 설정 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 수를 반환합니다. 거기에 (대규모 리스트와 대규모 스택에 대한)제한이 없을때, get_capacity는 0을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "get_capacity" "LLIST_BIN"

###### aql

	execute llist.get_capacity('LLIST_BIN') on test.demo where pk = 'Key_1'

##### destroy()

==destroy()==는 전체 대규모 리스트를 제거하고 빈 ==LLIST_BIN==을 널로 설정합니다. 이것은 효과적으로 빈을 제거합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "llist" "destroy" "LLIST_BIN"

###### aql

	execute llist.destroy('LLIST_BIN') on test.demo where pk = 'Key_1'

#### 완벽한 ASCLI 예시

이것은 완벽한 BASH shell 스크립트입니다(ascli 명령을 포함하는):

	#!/bin/bash
    echo "<< ---------------- <><><><><><><><><><> ------------------- >>"
	echo "<< ----------------  LLIST ASCLI EXAMPLE ------------------- >>"
    echo "<< ---------------- <><><><><><><><><><> ------------------- >>"
	
    echo " UDF/LDT 호출을 위한 포괄적인 형식은 :"
	echo "ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS"

	echo "대규모 리스트 명령은 : "
    echo " (*) Status = add( topRec, ldtBinName, newValue, userModule )"
	echo " (*) Status = add_all( topRec, ldtBinName, valueList, userModule)"
    echo " (*) List   = find( topRec, bin, value, module, filter, fargs )"
	echo " (*) List   = scan( topRec, ldtBinName) "
    echo " (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )"
	echo " (*) Status = remove( topRec, ldtBinName, searchValue )"
    echo " (*) Status = destroy( topRec, ldtBinName )"
	echo " (*) Number = size( topRec, ldtBinName )"
    echo " (*) Map    = get_config( topRec, ldtBinName )"
	echo " (*) Status = set_capacity( topRec, ldtBinName, new_capcity)"
    echo " (*) Status = get_capacity( topRec, ldtBinName )"
	

	echo "LDT로 몇개의 요소를 추가"
    set -v
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 55
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 5
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 25
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 75
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 15
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 45
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 35
	set +v

	echo "요소 25 찾기"
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "find" "LLIST_BIN" 25
	
    echo "LDT 스캔"
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "scan" "LLIST_BIN"

	echo "LDT의 크기 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "size" "LLIST_BIN"
	
    echo "요소 45 제거"
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "remove" "LLIST_BIN" 45

	echo "LDT(이것이 제거된걸 확인하기위해) 스캔"
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "scan" "LLIST_BIN"
	
    echo "LDT의 설정 보기"
	ascli udf-record-apply "test" "demo" "Key_1" "llist" "get_config" "LLIST_BIN"

	echo "LDT의 용량 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "get_capacity" "LLIST_BIN"
	
	echo "LDT 제거"
    ascli udf-record-apply "test" "demo" "Key_1" "llist" "destroy" "LLIST_BIN"
	
    echo " <><><> 끝!! <><><>"

우리는 다음의 출력을 기대할 수 있습니다:

	$ ./llist_example.sh
    << -------------- <><><><><><><><><><> ------------- >>
	<< --------------  LLIST ASCLI EXAMPLE ------------- >>
    << -------------- <><><><><><><><><><> ------------- >>
	UDF/LDT 호출의 포괄적인 형식은:
    ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS
	대규모 리스트 명령은:
     (*) Status = add( topRec, ldtBinName, newValue, userModule )
	 (*) Status = add_all( topRec, ldtBinName, valueList, userModule )
     (*) List   = find( topRec, bin, value, module, filter, fargs )
     (*) List   = scan( topRec, ldtBinName)
     (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )
     (*) Status = remove( topRec, ldtBinName, searchalue )
     (*) status = destroy( topRec, ldtBinName)
     (*) Number = size( topRec, ldtBinName)
     (*) Map    = get_config( topRec, ldtBinName )
     (*) Status = set_capacity( topRec, ldtBinName, new_capacity)
     (*) Status = get_capacity( topRec, ldtBinName )
     LDT에 몇가지 요소를 추가
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 55
     0
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN"  5
     0
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 25
     0
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 75
     0
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 15
     0
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 45
     0
     ascli udf-record-apply "test" "demo" "Key_1" "llist" "add" "LLIST_BIN" 35
     0
     set +v
     요소 25 찾기
     [ 25 ]
     LDT 스캔
     [ 5, 15, 25, 35, 45, 55, 75 ]
     LDT의 크기 얻기
     7
     요소 45 제거
     [ 45 ]
     (이것이 제거됬는지 확인하기 위해)LDT 스캔
     [ 5, 15, 25, 35, 45, 55, 75 ]
     LDT의 구성 보기
     { "CompactList": [ 5, 15, 25, 35, 45, 55, 75 ], "StoreMode": "L", "RootListMax": 100, "PropEsrDigest": 0, "SUMMARY": "LList Summary", "TreeLevel": 1, "RecType": 1, "PropMagic": "MAGIC", "PropCreateTime": 1400896037610, "NodeCount": 0, "PropBinName": "LLIST_BIN", "StoreState": "C", "LeafCount": 0, "PropLdtType": "LLIST", "PropVersion": 2, "PropItemCount": 7, "KeyType": "A", "PropSubRecCount": 0 }
    LDT의 용량 얻기
    0
    LDT 제거
    0
      <><><> 끝!! <><><>

#### 완벽한 AQL 예시

	print '<< ------------ <><><><><><><><><><> ----------------- >> '
    print '<< ------------  LLIST AQL EXAMPLE ------------------- >> '
	print '<< ------------ <><><><><><><><><><> ----------------- >> '

	print 'UDF/LDT 호출에 대한 포괄적인 형식:'
    print 'ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS'
	
    print '대규모 리스트 명령:'
	print ' (*) Status = add( topRec, ldtBinName, newValue, userModule )'
    print ' (*) Status = add_all( topRec, ldtBinName, valueList, userModule )'
	print ' (*) List   = find( topRec, bin, value, module, filter, fargs )'
    print ' (*) List   = scan( topRec, ldtBinName )'
	print ' (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )'
    print ' (*) Status = remove( topRec, ldtBinName, searchValue )'
	print ' (*) Status = destroy( topRec, ldtBinName )'
    print ' (*) Number = size( topRec, ldtBinName )'
	print ' (*) Map    = get_config( topRec, ldtBinName )'
    print ' (*) Status = set_capacity( topRec, ldtBinName, new_capacity )'
	print ' (*) Status = get_capacity( topRec, ldtBinName )'

	print 'LDT에 몇가지 요소를 추가'
    execute llist.add('LLIST_BIN', 55) on test.demo where pk = 'Key_1'
	execute llist.put('LLIST_BIN',  5) on test.demo where pk = 'Key_1'
    execute llist.put('LLIST_BIN', 25) on test.demo where pk = 'Key_1'
	execute llist.put('LLIST_BIN', 75) on test.demo where pk = 'Key_1'
    execute llist.put('LLIST_BIN', 15) on test.demo where pk = 'Key_1'
	execute llist.put('LLIST_BIN', 45) on test.demo where pk = 'Key_1'
    execute llist.put('LLIST_BIN', 35) on test.demo where pk = 'Key_1'
	
    print '요소 25 찾기'
	execute llist.find('LLIST_BIN', 25) on test.demo where pk = 'Key_1'

	print 'LDT 스캔'
    execute llist.scan('LLIST_BIN') on test.demo where pk = 'Key_1'
	
    print 'LDT의 크기 얻기'
	execute llist.size('LLIST_BIN') on test.demo where pk = 'Key_1'

	print '요소 45 제거'
    execute llist.remove('LLIST_BIN', 45) on test.demo whre pk = 'Key_1'
	
    print '(이것이 제거된걸 확인하기 위해) LDT 스캔'
	execute llist.scan('LLIST_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 구성 보기'
    execute llist.get_config('LLIST_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 용량 얻기'
    execute llist.get_capacity('LLIST_BIN') on test.demo where pk = 'Key_1'

	print 'LDT 제거'
    execute llist.destroy('LLIST_BIN') on test.demo where pk = 'Key_1'
	
    print ' <><><> 끝!! <><><>'

언어별 예시는 다음에서 찾을 수 있습니다:

1. [자바 클라이언트-LDT](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
2. [씨 클라이언트-LDT](http://www.aerospike.com/docs/client/c/usage/ldt/)

#### 작업(논리적인 API)

다음은 리스트를 포함하는 빈에 수행되는 작업입니다.

##### add

리스트에 ==값==을 추가.

	add(bin: Value, value: Value) -> Integer

###### 매개변수

* ==빈== - 레코드의 LDT 빈의 이름
* ==레코드== - 리스트에 추가하는 값

###### 반환

작동의 결과를 나타내는 상태 코드

##### add_all

리스트 ==값==의 각 값을 추가.

	add_all(values: LIST) -> Integer

###### 매개변수

* ==빈== - 레코드의 LDT 빈의 이름
* ==값== - 스택의 탑에 추가하는 값의 리스트

###### 반환

작동의 결과를 나타내는 상태 코드

##### find

==검색== 값과 일치하는 모든 값을 검색

	find(bin: Value, search: Value) -> List

###### 매개변수

* ==빈== - 레코드의 LDT 빈의 이름
* ==검색== - 리스트에 검색하는 값

###### 반환

리스트에서 일치하는 모든 값의 리스트.

##### 필터를 가진 find

find() 기능은 옵션의 조건 필터를 취합니다. ==검색== 값과 일치하고 조건 기능 ==p==를 사용하여 그들을 차단하는 모든 값을 검색.

	find(search: Value, p: (a: Value) -> Boolean) -> List

###### 반환

리스트의 모든 값의 목록

###### 주의

이것은 리스트에 저장된 데이터의 양에 따라 비쌀 수 있습니다.

##### 필터

리스트를 스캔하고 조건 기능 ==p==를 만족하는 값을 반환.

	filter(bin: Value, p: (value: Value) -> Boolean) -> List

###### 매개변수

* ==빈== - 레코드의 LDT 빈의 이름
* ==p== - 각 값에 적용되는 조건. 조건은 지정된 값에 대해 ==참== 또는 ==거짓== 중 하나를 반환하는 기능이어야 합니다.

###### 반환

조건 ==p==를 만족시키는 첫번째 ==n== 값의 리스트.

##### 범위

리스트에 특정 범위내에서 모든 값을 나열.

	range(bin: Value, min: Value, max: Value) -> List

###### 매개변수

* ==빈== - 레코드의 LDT 빈의 이름
* ==최소== - 범위의 시작 값(포괄적)
* ==최대== - 범위의 끝 값(포괄적)

###### 반환

리스트에 모든 한정 값의 ==리스트==

###### 주의

이것은 범위의 크기와 리스트에 저장된 데이터의 양에 따라 비쌀 수 있습니다.

##### 스캔

리스트의 모든 값을 나열.

	scan(bin: Value) -> List

###### 매개변수

* ==빈== - 레코드의 LDT 빈의 이름

###### 반환

리스트의 모든 값의 ==리스트==

###### 주의

이것은 리스트에 저장된 데이터의 양에 따라 비쌀 수 있습니다.

##### 제거

리스트에서 ==검색== 값과 일치하는 모든 값을 제거.

	remove(search: Value) -> Integer

###### 반환

작동의 결과를 나타내는 상태 코드

##### 파괴

리스트 빈과 모든 연관된 데이터를 파괴

	destroy() -> Integer

###### 반환

작동의 결과를 나타내는 상태 코드

##### 크기

리스트의 값의 수

	size() -> Integer

###### 반환

리스트의 값의 수

##### get_config

리스트의 구성 매개변수 얻음.

	get_config() -> Map

###### 반환

lstack에 대한 모든 구성 설정을 포함하는 ==맵==

##### set_capacity

리스트에 저장되는 값의 최대 수를 설정

	set_capacity(size: Integer) -> Integer

###### 매개변수

* ==크기== - 값의 최대 수.

###### 반환

작업의 결과를 나타내는 상태 코드

##### get_capacity

리스트에 저장되는 값의 최대 수를 설정

	get_capacity() -> Integer

###### 반환

저장될 수 있는 값의 최대 수를 반환

#### 제한

* 오름차순 값만
* 키 값은 숫자나 스트링이어야 햠
* 서브레코드 크기(보다 더 적은)로 제한된 개별 객체(예: 1MB)
* 바이너리 저장소 능력은 공사중
* 최소/최대 기능은 공사중

#### 향후 특징

* **캡 컬렉션**: 새로운 것을 위해 자리를 만드는 가장 오래된 시간 값을 퇴거하는 시간에 기반한 컬렉션을 허용합니다. 또는, 일반 캡 컬렉션을 구현하는 기본 키(예: SS#)와 시간 값 둘다 관리하는 대규모 리스트의 쌍을 사용합니다.

### 대규모 맵

대규모 맵(lmap)은 표준 "이름/값" 맵 기능성을 이용합니다. 이것은 연관된 키(예: 이름,숫자)를 가지는 복잡한 값(예: 맵,리스트,문서)에 대하 최적화된 대규모 데이터 타입입니다. LMAP은 해시 테이블을 가지고 구현되고, 이것은 관련된 값을 위치시키는 네임에 해시 기능을 계산합니다.

##### 특징

대규모 맵은 다음 기능을 가집니다:

* 원자 또는 복잡한 객체 관리(값 필드에서)
* 약 2GB까지의 저장소
* UDF 조건 필터, UDF 변환
* 단일 항목, 여러 항목을 삽입
* 옵션 UDF 필터를 가지는 단일 값 검색
* 옵션 UDF 필터를 가지는 풀 스캔
* 단일 항목 업데이트
* 단일 값 제거

##### 사용 사례

대규모 맵은 키("네임")가 숫자 또는 스트링이고 값이 지원된 데이터 타입인 사전을 저장하는 데 적합합니다. 맵은 사용자가 번호 또는 이름으로 인덱스된 연관 배열을 필요로 하는 모든 상황에 유용합니다. 가장 복잡한 객체는 맵으로 바로 바뀔 수 있습니다.  

표 1은 **값**이 부분이고 **이름**이 부분의 이름인걸 설명하는 문서인 일부 리스트의 예시를 보여줍니다.

![LDT_Record_LMap.png](LDT_Record_LMap.png)

> 표 1  
부분 리스트를 관리하는 대규모 맵

#### 대규모 데이터 타입(LDT) 어플리케이션 프로그래밍 인터페이스(API)

LDTs는 다음에서 접근될 수 있습니다:

* [사용자 정의 함수](http://www.aerospike.com/docs/udf/udfs_and_ldts.html)
* [에어로스파이크 씨 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/c/usage/ldt/index.html)
* [에어로스파이크 자바 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
* [에어로스파이크 씨# 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/csharp/usage/ldt/ldt.html)

#### 완벽한 예시

이 예시에서 우리는 에어로스파이크 [ascli](http://www.aerospike.com/docs/tools/ascli/) 도구와 [aql](http://www.aerospike.com/docs/tools/aql/) 도구를 사용하는 각각의 대규모 맵(lmap) 기능의 사용을 설명합니다. 두 도구 모두 에어로스파이크 서버에 작은 작업을 수행하는 데 편리합니다.  

첫번째 다음과 비슷한 ==ascli== 명령을 사용하여 우리는 대규모 맵으로 요소 갯수를 삽입:

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 55 "55 string"

이 명령의 세부 사항을 보자. ==ascli udf-record-apply==는 네임스페이스 ==test==, 세트 ==demo==와 키 ==Key_1==를 사용하여 레코드에 UDF를 호출합니다.  

우리가 패키지 ==lmap==에서 호출하는 UDF, 이 패키지는 대규모 맵의 구현입니다.  

여기에 해당하는 ==aql==:

	execute lmap.put('LMAP_BIN', 55, '55 string') on test.demo where pk = 'Key_1'

==실행== 키워드는 네임스페이스와 키 ==where pk : 'Key_1'==에 세트 ==on test.demo==의 레코드에 ==lmap.put== 기능을 호출합니다.  

##### put()

put() 기능은 대규모 맵에 항목을 두고 매개변수를 가집니다:

* 빈 - 대규모 맵 ==LMAP_BIN==을 포함하는 빈의 이름
* 키 - 대규모 맵 ==55==의 목록의 키
* 값 - 대규모 맵 ==55 스트링==의 목록의 값

==put()== 기능은 내재적으로 이것이 존재하지 않을때 탑 레코드를 생성합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 55 "55 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN"  5 "05 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 25 "25 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 75 "75 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 15 "15 string"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 45 "45 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 35 "35 string"

###### aql

	execute lmap.put('LMAP_BIN', 55, '55 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN',  5, '05 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN', 25, '25 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN', 75, '75 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN', 15, '15 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN', 45, '45 string') on test.demo where pk = 'Key_1' 
	execute lmap.put('LMAP_BIN', 35, '35 string') on test.demo where pk = 'Key_1' 

##### get()

대규모 맵에서 요소를 검색하기위해서, 너는 ==get()== 기능을 사용합니다, 이것은 키 매개변수 ==25==를 사용하고 ==25==와 ==25 스트링==의 키 값 쌍을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "get" "KMAP_BIN" 25

###### aql

	execute lmap.get('LMAP_BIN', 25) on test.demo where pk = 'Key_1'

##### scan()

==scan()== 기능은 전체 대규모 맵을 스캔하고 대규모 맵의 모든 키 값 쌍을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "scan" "LMAP_BIN"

###### aql

	execute lmap.scan('LMAP_BIN') on test.demo where pk = 'Key_1'

##### size()

==size()==는 대규모 맵의 요소 갯수를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "size" "LMAP_BIN"

###### aql

execute lmap.size('LMAP_BIN') on test.demo where pk = 'Key_1'

##### remove()

==remove()== 기능은 대규모 맵에서 요소를 제거하고, 이것은 ==키== 매개변수와 이 예제에선 키가 ==45==인 값을 사용합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "remove" "LMAP_BIN" 45

###### aql

	execute lmap.remove('LMAP_BIN', 45) on test.demo where pk = 'Key_1'

##### get_config()

==get_config()== 기능은 그들의 현재 값과 적절한 구성가능한 설정을 나타내는 맵 객체를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "get_config" "LMAP_BIN"

###### aql

	execute lmap.get_config('LMAP_BIN') on test.demo where pk = 'Key_1'

##### get_capacity()

==get_capacity()== 기능은 LDT 인스턴스의 최대 용량을 반환합니다. 대규모 리스트 LDT는 기본적으로 최대 용량을 가지지 않지만(이것은 기본적으로 무한대로 커짐), 이것은 우발적 저장소 과용을 막기위해서 최대 크기를 설정할 수 있습니다. get_capacity()가 제한 설정을 반환하는 반면에, size() 기능은 LDT의 현재 항목 카운트를 반환합니다. 대규모 맵은 총 저장소의 2 GB를 넘는 것을 방지하기 위해 100 억개 객체의 기본 설정을 가집니다. 대규모 항목이 대규모 맵에 저장되는 이런 경우에, 이것은 (2 GB/ 평균 객체 크기)에 최대 용량을 설정하는 것이 좋습니다.

> 대규모 맵은 총 저장소의 2 GB를 넘는 것을 방지하기 위해 100 억개 객체의 기본 설정을 가집니다. 대규모 항목이 대규모 맵에 저장되는 이런 경우에, 이것은 (2 GB/ 평균 객체 크기)에 최대 용량을 설정하는 것이 좋습니다.  

> ==get_cpacity()== 기능은 LDT 인스턴스의 최대 용량을 반환합니다. 대규모 맵 LDT는 거의 2GB의 크기나 8000개의 서브레코드로 바운드합니다. 이것이 8GB 총 공간에 도달하는 것과 같이 1MB의 최대 크기에 8000개의 서브레코드 각각을 푸시할 수 있더라도, 이것은 서브 레코드 크기를 128kb로 제한하는 것이 좋습니다. get_capacity()가 LMAP 항목 카운트 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 카운트를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "get_capacity" "LMAP_BIN"

###### aql

	execute lmap.get_capacity('LMAP_BIN') on test.demo where pk = 'Key_1'

##### destroy()

==destroy()==는 전체 대규모 맵을 제거하고 빈 ==LMAP_BIN==을 널로 설정합니다. 이것은 효과적으ㅗ 빈을 제거합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "destroy" "LMAP_BIN"

###### aql

	execute lmap.destroy('LMAP_BIN') on test.demo where pk = 'Key_1'

#### 완벽한 ASCLI 예시

이것은 완벽한 BASH shell 스크립트입니다:

	#!/bin/bash
    echo "<< ---------------- <><><><><><><><><><> ------------------- >>"
	echo "<< ----------------  LMAP ASCLI EXAMPLE ------------------- >>"
    echo "<< ---------------- <><><><><><><><><><> ------------------- >>"
	
    echo " UDF/LDT 호출을 위한 포괄적인 형식은 :"
	echo "ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS"

	echo "대규모 리스트 명령은 : "
    echo " (*) Status = put( topRec, ldtBinName, newName, newValue, userModule )"
	echo " (*) Status = put_all( topRec, ldtBinName, newValueMap, userModule)"
    echo " (*) List   = get( topRec, ldtBinName, searchName )"
	echo " (*) List   = scan( topRec, ldtBinName) "
    echo " (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )"
	echo " (*) Object = remove( topRec, ldtBinName, searchValue )"
    echo " (*) Status = destroy( topRec, ldtBinName )"
	echo " (*) Number = size( topRec, ldtBinName )"
    echo " (*) Map    = get_config( topRec, ldtBinName )"
	echo " (*) Status = set_capacity( topRec, ldtBinName, new_capcity)"
    echo " (*) Status = get_capacity( topRec, ldtBinName )"
	

	echo "LDT로 몇개의 요소를 추가"
    set -v
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 55 "55 string"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN"  5 "05 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 25 "25 string"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 75 "75 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 15 "15 string"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 45 "45 string"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 35 "35 string"
	set +v

	echo "요소 25 찾기"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "get" "LMAP_BIN" 25
	
    echo "LDT 스캔"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "scan" "LMAP_BIN"

	echo "LDT의 크기 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "size" "LMAP_BIN"
	
    echo "요소 45 제거"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "remove" "LMAP_BIN" 45

	echo "LDT(이것이 제거된걸 확인하기위해) 스캔"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "scan" "LMAP_BIN"
	
    echo "LDT의 설정 보기"
	ascli udf-record-apply "test" "demo" "Key_1" "lmap" "get_config" "LMAP_BIN"

	echo "LDT의 용량 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "get_capacity" "LMAP_BIN"
	
	echo "LDT 제거"
    ascli udf-record-apply "test" "demo" "Key_1" "lmap" "destroy" "LMAP_BIN"
	
    echo " <><><> 끝!! <><><>"

출력은:

    << -------------- <><><><><><><><><><> ------------- >>
	<< --------------  LMAP ASCLI EXAMPLE ------------- >>
    << -------------- <><><><><><><><><><> ------------- >>
	UDF/LDT 호출의 포괄적인 형식은:
    ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS
	대규모 맵 명령은:
     (*) Status = put( topRec, ldtBinName, newName, newValue, userModule )
	 (*) Status = put_all( topRec, ldtBinName, nameValueMap, userModule )
     (*) List   = get( topRec, ldtBinName, searchName )
     (*) List   = scan( topRec, ldtBinName )
     (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )
     (*) Object = remove( topRec, ldtBinName, searchName )
     (*) status = destroy( topRec, ldtBinName )
     (*) Number = size( topRec, ldtBinName )
     (*) Map    = get_config( topRec, ldtBinName )
     (*) Status = set_capacity( topRec, ldtBinName, new_capacity)
     (*) Status = get_capacity( topRec, ldtBinName )
     LDT에 몇가지 요소를 추가
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 55 "55 string"
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN"  5 "05 string"
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 25 "25 string"
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 75 "75 string"
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 15 "15 string"
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 45 "45 string"
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lmap" "put" "LMAP_BIN" 35 "35 string"
     0
     set +v
     요소 25 찾기
     { 25: "25 string" }
     LDT 스캔
     { 35: "35 string", 5: "05 string", 75: "75 string", 45: "45 string", 15: "15 string", 55: "55 string", 25: "25 string" }
     LDT의 크기 얻기
     7
     요소 45 제거
     0
     (이것이 제거됬는지 확인하기 위해)LDT 스캔
     { 35: "35 string", 5: "05 string", 75: "75 string", 15: "15 string", 55: "55 string", 25: "25 string" }
     LDT의 구성 보기
     { "HashDirSize": 8, "StoreMode": "L", "SUMMARY": "LMAP Summary", "RecType": 1, "PropMagic": "MAGIC", "TotalCount": 6, "PropCreateTime": 1400894213941, "LdrEntryCountMax": 100, "PropLdtType": "LMAP", "PropVersion": 2, "LdrByteCountMax": 0, "PropItemCount": 6, "KeyType": "A", "ThreshHold": 10, "PropSubRecCount": 0}
    LDT의 용량 얻기
    0
    LDT 제거
    0
      <><><> 끝!! <><><>

#### 완벽한 aql 예시

	print '<< ------------ <><><><><><><><><><> ----------------- >> '
    print '<< ------------  LMAP aql EXAMPLE -------------------- >> '
	print '<< ------------ <><><><><><><><><><> ----------------- >> '

	print 'UDF/LDT 호출에 대한 포괄적인 형식:'
    print 'execute MODULE.FUNCTION(ARGS) on NS.SET where pk = KEY'
	
    print '대규모 맵 명령:'
	print ' (*) Status = put( topRec, ldtBinName, newName, newValue, userModule)'
    print ' (*) Status = put_all( topRec, ldtBinName, nameValueMap, userModule)'
	print ' (*) List   = get( topRec, ldtBinName, searchName )'
    print ' (*) List   = scan( topRec, ldtBinName )'
	print ' (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )'
    print ' (*) Object = remove( topRec, ldtBinName, searchName )'
	print ' (*) Status = destroy( topRec, ldtBinName )'
    print ' (*) Number = size( topRec, ldtBinName )'
	print ' (*) Map    = get_config( topRec, ldtBinName )'
    print ' (*) Status = set_capacity( topRec, ldtBinName, new_capacity )'
	print ' (*) Status = get_capacity( topRec, ldtBinName )'

	print '대규모 맵에 몇가지 요소를 추가'
    execute lmap.put('LMAP_BIN', 55, '55 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN',  5, '05 string') on test.demo where pk = 'Key_1'
    execute lmap.put('LMAP_BIN', 25, '25 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN', 75, '75 string') on test.demo where pk = 'Key_1'
    execute lmap.put('LMAP_BIN', 15, '15 string') on test.demo where pk = 'Key_1'
	execute lmap.put('LMAP_BIN', 45, '45 string') on test.demo where pk = 'Key_1'
    execute lmap.put('LMAP_BIN', 35, '35 string') on test.demo where pk = 'Key_1'
	
    print '요소 25 찾기'
	execute lmap.get('LMAP_BIN', 25) on test.demo where pk = 'Key_1'

	print 'LDT 스캔'
    execute lmap.scan('LMAP_BIN') on test.demo where pk = 'Key_1'
	
    print 'LDT의 크기 얻기'
	execute lmap.size('LMAP_BIN') on test.demo where pk = 'Key_1'

	print '요소 45 제거'
    execute lmap.remove('LMAP_BIN', 45) on test.demo whre pk = 'Key_1'
	
    print '(이것이 제거된걸 확인하기 위해) LDT 스캔'
	execute lmap.scan('LMAP_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 구성 보기'
    execute lmap.get_config('LMAP_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 용량 얻기'
    execute lmap.get_capacity('LMAP_BIN') on test.demo where pk = 'Key_1'

	print 'LDT 제거'
    execute lmap.destroy('LMAP_BIN') on test.demo where pk = 'Key_1'
	
    print ' <><><> 끝!! <><><>'

언어별 예시는 다음에서 찾을 수 있습니다:

1. [자바 클라이언트-LDT](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
2. [씨 클라이언트-LDT](http://www.aerospike.com/docs/client/c/usage/ldt/)

#### 작업

다음은 lmap을 포함하는 빈에서 수행되는 작업입니다.  

용어 ==원자==는 스트링과 정수의 데이터 타입을 참고합니다.

##### put

lmap에 키 값 쌍을 추가

	put(key: Atomic, value: Value) -> Integer

###### 매개변수

* ==키== - 값과 연관되는 키
* ==값== - lmap에 저장되는 값

###### 반환

작업의 결과를 나타내는 상태 코드

##### put_all

lmap에 맵 ==소스==의 키 값 쌍 각각을 추가

	put(source: Map) -> Integer

###### 매개변수

* ==소스== - lmap에 추가되는 키 값 쌍을 포함하는 맵

###### 반환

작업의 결과를 나타내는 상태 코드

##### get

주어진 ==키==와 연관된 값을 반환

	get(key: Atomic) -> Value

###### 매개변수

* ==키== - 연관된 값을 얻는 키

###### 반환

주어진 키에 대한 값

##### scan

lmap을 스캔하고 모든 키 값 쌍을 반환

	scan() -> Map

##### 반환

lmap의 모든 키 값 쌍

###### 주의

lmap에 저장되는 데이터의 양에 따라 이것은 비싸질 수 있습니다.

##### filter

조건 ==p==를 만족시키는 키 값 쌍을 검색

	filter(p: (key: Atomic, value: Value) -> Boolean) -> Map

###### 매개변수

* ==p== - 각각의 키 값 쌍에 적용되는 조건. 조건은 주어진 값에 대해 ==참==이나 ==거짓== 중 하나를 반환하는 기능이어야 합니다.

###### 반환

조건 ==p==를 만족시키는 키 값 쌍을 포함하는 맵

##### remove

주어진 ==키==와 lmap에서 연관된 값을 제거

	remove(key: Atomic) -> Integer

###### 매개변수

* ==키== - 제거되는 키

###### 반환

작업의 결과를 나타내는 상태 코드

##### destroy

모든 연관된 데이터와 lmap 빈을 파괴

	destroy() -> Integer

###### 반환

작업의 결과를 나타내는 상태 코드

#### 제한

* **이름**은 숫자나 스트링이어야 합니다.
* 서브레코드 크기(보다 더 적은)로 제한된 개별 객체(예: 1MB)
* 바이너리 저장소 용량은 공사중

### 대규모 세트

![LDT_Operations_LSet.png](LDT_Operations_LSet.png)

대규모 세트(lset)는 고유값 분류와 세트에 값의 존재를 체크하는 데 최적화된 대규모 데이터 타입입니다.  

대규모 세트는 **고유**값의 큰 수를 저장하는데 적합합니다. lset 객체는 해시 기능이 전체 객체나 선택된 객체의 고유 서브세트에 적용되는 해시 테이블을 가지고 구현됩니다.

##### 특징

대규모 세트는 다음의 기능을 가집니다:

* 원자 또는 복잡한 객체 관리
* 약 2GB까지의 저장소
* UDF 조건 필터, UDF 변경
* 단일 항목 또는 여러 항목 삽입
* 옵션 UDF 필터를 가진 단일 값 검색
* 옵션 UDF 필터를 가진 풀 스캔
* 단일 항목 업데이트
* 단입 값 업데이트

##### 사용 사례

세트는 값 중복에 대한 걱정없이 세트로의 삽입이 "맹목적으로" 되는 고유 컬렉션을 보유하는데 편리합니다. "키"당 한 객체만 세트에 존재합니다.  

일반적인 사용 사례는 삽입이 각 URL이 마주치고 고유성이 유지되도록 하는 방문 URLs의 세트를 관리하는 것 입니다(표 1). 그 후 정기적으로 단일 URL의 존재는 체크되거나, 전체 고유 설정은 스캔됩니다.  

![LDT_Record_LSet.png](LDT_Record_LSet.png)

> 표 1
고유 URL 리스트를 관리하는 대규모 세트

#### 대규모 데이터 타입(LDT) 어플리케이션 프로그래밍 인터페이스(API)

LDTs는 다음에서 접근될 수 있습니다:

* [사용자 정의 함수](http://www.aerospike.com/docs/udf/udfs_and_ldts.html)
* [에어로스파이크 씨 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/c/usage/ldt/index.html)
* [에어로스파이크 자바 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
* [에어로스파이크 씨# 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/csharp/usage/ldt/ldt.html)

#### 완벽한 예시

이 예시에서, 우리는 에어로스파이크 [ascli](http://www.aerospike.com/docs/tools/ascli/) 도구와 [aql](http://www.aerospike.com/docs/tools/aql/) 도구를 사용하여 대규모 세트(lset) 기능각각의 사용을 설명합니다. 이 두 도구는 에어로스파이크 서버에 작은 작업을 수행하는데 편리합니다.  

먼저 우리는 이것과 비슷한 ==ascli== 명령을 사용하여 대규모 세트로 요소 갯수를 삽입합니다:

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 55

이 명령의 세부사항을 보자. ==ascli udf-record-apply==는 네임스페이스 ==test==, 세트 ==demo==와 키 ==Key_1==를 사용하여 레코드에 UDF를 호출합니다.  

우리가 호출한 UDF는 패키지 ==lset==에 있고, 이 패키지는 대규모 셑의 구현입니다.

여기에 해당하는 ==aql==:

	execute lset.add('LSET_BIN', 55) on test.demo where pk = 'Key_1'

==execute== 키워드는 키 ==where pk = 'Key_1'==에 세트 ==on test.demo==와 네임스페이스의 레코드에 ==lset.add== 기능을 호출합니다.

##### add()

==add()== 기능은 대규모 세트에 요소를 추가하고, 이것은 리스트에 추가되는 값인 단일 매개변수를 사용합니다.  

==add()== 기능은 내재적으로 존재하지 않을때 탑 레코드를 생성합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 55
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN"  5
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 25
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 75
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 15
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 45
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 35

###### aql

	execute lset.add('LSET_BIN', 55) on test.demo where pk = 'Key_1'
    execute lset.add('LSET_BIN',  5) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN', 25) on test.demo where pk = 'Key_1'
    execute lset.add('LSET_BIN', 75) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN', 15) on test.demo where pk = 'Key_1'
    execute lset.add('LSET_BIN', 45) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN', 35) on test.demo where pk = 'Key_1'

##### get()

대규모 세트에서 요소를 검색하기 위해서 너는 ==get()== 기능을 사용하고, 이것은 ==요소== 매개변수 ==25==를 사용하고 ==25==의 값을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "get" "LSET_BIN" 25

###### aql

	execute lset.get('LSET_BIN', 25) on test.demo where pk = 'Key_1'

##### scan()

==scan()== 기능은 전체 대규모 세트를 스캔하고 대규모 세트의 모든 값을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "scan" "LSET_BIN"

###### aql

	execute lset.scan('LSET_BIN') n test.demo where pk = 'Key_1'

##### size()

==size()==는 대규모 세트의 요소 갯수를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "size" "LSET_BIN"

###### aql

	execute lset.size('LSET_BIN') on test.demo where pk = 'Key_1'

##### remove()

==remove()== 기능은 대규모 세트에서 요소를 제거하고, 이것은 ==요소== 매개변수와 이 예제에선 요소가 ==45==인 걸 사용합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "remove" "LSET_BIN" 45

###### aql

	execute lset.remove('LSET_BIN', 45) on test.demo where pk = 'Key_1'

##### get_config()

==get_config()== 기능은 적절히 구성가능한 설정과 현재 값을 나타내는 맵 객체를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "get_config" "LSET_BIN"

###### aql

	execute lset.get_config('LSET_BIN') on test.demo where pk = 'Key_1'

##### get_capacity()

==get_capacity()== 기능은 LDT 인스턴스의 최대 용량을 반환합니다. 대규모 맵 LDT는 거의 2GB의 크기나 8000개의 서브레코드로 바운드합니다. 이것이 8GB 총 공간에 도달하는 것과 같이 1MB의 최대 크기에 8000개의 서브레코드 각각을 푸시할 수 있더라도, 이것은 서브 레코드 크기를 128kb로 제한하는 것이 좋습니다. get_capacity()가 LMAP 항목 카운트 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 카운트를 반환합니다.

> ==get_capacity== 기능은 LDT 인스턴스의 최대 용량을 반환합니다. 대규모 맵 LDT는 거의 2GB의 크기나 8000개의 서브레코드로 바운드합니다. 이것이 8GB 총 공간에 도달하는 것과 같이 1MB의 최대 크기에 8000개의 서브레코드 각각을 푸시할 수 있더라도, 이것은 서브 레코드 크기를 128kb로 제한하는 것이 좋습니다. get_capacity()가 LMAP 항목 카운트 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 카운트를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "get_capacity" "LSET_BIN"

###### aql

	execute lset.get_capacity('LSET_BIN') on test.demo where pk = 'Key_1'

##### destroy()

==destroy()==는 전체 대규모 세트를 제거하고 빈 ==LSET_BIN==을 널로 설정합니다. 이것은 효과적으로 빈을 제거합니다.  

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lset" "destroy" "LSET_BIN"

###### aql

	execute lset.destroy('LSET_BIN') on test.demo where pk = 'Key_1'

#### 완벽한 ASCLI 예제

이것은 완벽한 BASH shell 스크립트(ascli 명령을 포함하는)입니다:

	#!/bin/bash
    echo "<< ---------------- <><><><><><><><><><> ------------------- >>"
	echo "<< ----------------  LSET ASCLI EXAMPLE -------------------- >>"
    echo "<< ---------------- <><><><><><><><><><> ------------------- >>"
	
    echo " UDF/LDT 호출을 위한 포괄적인 형식은 :"
	echo "ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS"

	echo "대규모 세트 명령은 : "
    echo " (*) Status = add( topRec, ldtBinName, newValue, userModule )"
	echo " (*) Status = add_all( topRec, ldtBinName, valueList, userModule )"
    echo " (*) Object = get( topRec, ldtBinName, searchValue )"
	echo " (*) Number = exists( topRec, ldtBinName, searchValue )"
    echo " (*) List   = scan( topRec, ldtBinName )"
	echo " (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )"
    echo " (*) Status = remove( topRec, ldtBinName, searchValue )"
	echo " (*) Object = take( topRec, ldtBinName, searchValue )"
    echo " (*) Status = destroy( topRec, ldtBinName )"
	echo " (*) Number = size( topRec, ldtBinName )"
    echo " (*) Map    = get_config( topRec, ldtBinName )"
	echo " (*) Status = set_capacity( topRec, ldtBinName, new_capcity)"
    echo " (*) Status = get_capacity( topRec, ldtBinName )"
	

	echo "대규모 세트에 몇개의 요소를 추가"
    set -v
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 55
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 5
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 25
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 75
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 15
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 45
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 35
	set +v

	echo "요소 25 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "get" "LSET_BIN" 25
	
    echo "LDT 스캔"
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "scan" "LSET_BIN"

	echo "LDT의 크기 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "size" "LSET_BIN"
	
    echo "LDT에서 요소 45 제거"
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "remove" "LSET_BIN" 45

	echo "LDT(이것이 제거된걸 확인하기위해) 스캔"
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "scan" "LSET_BIN"
	
    echo "LDT의 설정 보기"
	ascli udf-record-apply "test" "demo" "Key_1" "lset" "get_config" "LSET_BIN"

	echo "LDT의 용량 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "get_capacity" "LSET_BIN"
	
	echo "LDT 제거"
    ascli udf-record-apply "test" "demo" "Key_1" "lset" "destroy" "LSET_BIN"
	
    echo " <><><> 끝!! <><><>"

우리는 다음의 출력을 보는 걸 기대할 수 있습니다

	$ ./lset_example.sh
    << -------------- <><><><><><><><><><> ------------- >>
	<< --------------  LSET ASCLI EXAMPLE -------------- >>
    << -------------- <><><><><><><><><><> ------------- >>
	UDF/LDT 호출의 포괄적인 형식은:
    ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS
	대규모 세트 명령은:
     (*) Status = add( topRec, ldtBinName, newValue, userModule )
	 (*) Status = add_all( topRec, ldtBinName, valueList, userModule )
     (*) Object = get( topRec, ldtBinName, searchValue )
     (*) Number = exists( topRec, ldtBinName, searchValue )
     (*) List   = scan( topRec, ldtBinName )
     (*) Status = remove( topRec, ldtBinName, searchValue )
	 (*) Object = take( topRec, ldtBinName, searchValue )
     (*) status = destroy( topRec, ldtBinName )
     (*) Number = size( topRec, ldtBinName )
     (*) Map    = get_config( topRec, ldtBinName )
     (*) Status = set_capacity( topRec, ldtBinName, new_capacity)
     (*) Status = get_capacity( topRec, ldtBinName )
     LDT에 몇가지 요소를 추가
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 55
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN"  5
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 25
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 75
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 15
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 45
     0
     ascli udf-record-apply "test" "demo" "Key_1" "lset" "add" "LSET_BIN" 35
     0
     set +v
     요소 25 얻기
     25
     LDT 스캔
     [ 55, 5, 25, 75, 15, 45, 35 ]
     LDT의 크기 얻기
     7
     LDT에서 요소 45 제거
     0
     (이것이 제거됬는지 확인하기 위해)LDT 스캔
     [ 55, 5, 25, 75, 15, 35 ]
     LDT의 구성 보기
     { "StoreMode": "L", "SetTypeStore": "R", "SUMMARY": "LSET Summary", "CreateTime": 1400895599368, "RecType": 1, "PropMagic": "MAGIC", "TotalCount": 7, "LdrEntryCountMax": 100, "PropBinName": "LSET_BIN", "StoreState": "C", "LdrByteEntrySize": 0, "PropLdtType": "LSET", "PropVersion": 2, "Modulo": 31, "LdrByteCountMax": 0, "PropItemCount": 6, "KeyType": "C", "StoreLimit": 0, "ThreshHold": 101, "PropSubRecCount": 0 }
    LDT의 용량 얻기
    0
    LDT 제거
    0
      <><><> 끝!! <><><>

#### 완벽한 AQL 예시

	print '<< -----------  <><><><><><><><><><> -------------- >> '
	print '<< -----------   LSET  ASCLI EXAMPLE -------------- >> '
	print '<< -----------  <><><><><><><><><><> -------------- >> '

	print 'UDF/LDT 호출에 관한 포괄적인 형식은:'
	print 'ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS'

	print '대규모 세트 명령은:'
	print ' (*) Status = add( topRec, ldtBinName, newValue, userModule )'
	print ' (*) Status = add_all( topRec, ldtBinName, valueList, userModule )'
	print ' (*) Object = get( topRec, ldtBinName, searchValue ) '
	print ' (*) Number = exists( topRec, ldtBinName, searchValue ) '
	print ' (*) List   = scan( topRec, ldtBinName )'
	print ' (*) List   = filter( topRec, ldtBinName, userModule, filter, fargs )'
	print ' (*) Status = remove( topRec, ldtBinName, searchValue ) '
	print ' (*) Object = take( topRec, ldtBinName, searchValue ) '
	print ' (*) Status = destroy( topRec, ldtBinName )'
	print ' (*) Number = size( topRec, ldtBinName )'
	print ' (*) Map    = get_config( topRec, ldtBinName )'
	print ' (*) Status = set_capacity( topRec, ldtBinName, new_capacity)'
	print ' (*) Status = get_capacity( topRec, ldtBinName )'


	print '대규모 세트에 몇가지 요소를 추가'
	execute lset.add('LSET_BIN',55) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN', 5) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN',25) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN',75) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN',15) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN',45) on test.demo where pk = 'Key_1'
	execute lset.add('LSET_BIN',35) on test.demo where pk = 'Key_1'

	print '요소 25 얻기'
	execute lset.get('LSET_BIN', 25) on test.demo where pk = 'Key_1'

	print 'LDT 스캔'
	execute lset.scan('LSET_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 크기 얻기'
	execute lset.size('LSET_BIN') on test.demo where pk = 'Key_1'

	print 'LDT에서 요소 45 제거'
	execute lset.remove('LSET_BIN', 45) on test.demo where pk = 'Key_1'

	print 'LDT 스캔(이것이 제거됬는지 확인하기 위해)'
	execute lset.scan('LSET_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 구성 보기'
	execute lset.get_config('LSET_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 용량 얻기'
	execute lset.get_capacity('LSET_BIN') on test.demo where pk = 'Key_1'

	print 'LDT 제거'
	execute lset.destroy('LSET_BIN') on test.demo where pk = 'Key_1'

	print ' <><><> 끝!! <><><>'

언어별 예시는 다음에서 찾을 수 있습니다:

1. [자바 클라이언트-LDT](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
2. [씨 클라이언트-LDT](http://www.aerospike.com/docs/client/c/usage/ldt/)

#### 작동

##### add

세트에 ==값==을 추가

	add(value: Value) -> Integer

###### 반환

작업의 결과를 나타내는 상태 코드

##### add_all

세트에 ==값== 리스트에서 각각의 값을 추가

	add_all(values: List) -> Integer

###### 반환

작업의 결과를 나타내는 상태 코드

##### get

==검색==과 일치하는 값을 얻음

	get(search: Value) -> Value

###### 반환

==검색== 매개변수와 상응하는 값

##### exists

세트에 ==검색== 값이 있을때 테스트

	exists(search: Value) -> Boolean

###### 매개변수

* ==검색== - 세트에 검색하는 값

###### 반환

==검색==매개변수에 상응하는 값일때 ==참==이 나옵니다. 그렇지않으면 ==거짓==이 반환됩니다.

##### scan

세트의 모든 값을 나열

	scan() -> List

###### 반환

lset의 모든 값의 ==리스트==

###### 주의

lstack에 저장되는 데이터의 양에 따라 이것은 비싸질 수 있습니다.

#### filter

조건 기능 ==p==를 만족시키는 값을 검색.

	filter(p: (value: Value) -> Boolean, pargs ) -> List

###### 매개변수

* ==p== - 각 값에 적용되는 조건. 조건은 주어진 값에 대해 ==참== 또는 ==거짓==을 반환하는 기능이어야합니다.

###### 반환

조건 ==p==를 만족시키는 값의 리스트

##### remove

세트에서 ==검색==과 상응하는 값을 제거

	remove(search: Value) -> Integer

###### 반환

작업의 결과를 나타내는 상태 코드

##### destroy

lset 빈과 모든 연관된 데이터를 파괴

	destroy() -> Integer

###### 반환

작업의 결과를 나타내는 상태 코드

##### size

세트의 값의 수

	size() -> Integer

###### 반환

세트의 값의 수

##### get_config

lset의 구성 매개변수를 얻음

	get_config() -> Map

###### 반환

lset에 대한 모든 구성 설정을 포함하는 ==맵==

##### set_capacity

lset에 저장되는 값의 최대 수를 설정

	set_capacity(size: Integer) -> Integer

###### 매개변수

* ==크기== - 값의 최대 수

###### 반환

작업의 결과를 나타내는 상태 코드

##### get_capacity

세트에 저장되는 값의 최대 수를 얻음

	get_capacity() -> Integer

###### 반환

저장되는 값의 최대 수를 반환

#### 제한

* **이름**은 숫자나 스트링이어야 합니다.
* 서브레코드 크기(보다 더 적게)로 제한되는 개별 객체(예: 1MB)
* 바이너리 저장소 용량은 공사중

### 대규모 스택

![LDT_Operations_LStack.png](LDT_Operations_LStack.png)

대규모 스택(lstack)은 푸시와 피크와 같은 스택에 기반한 작업에 대해 최적화된 대규모 데이터 타입입니다. lstack은 지속적으로 매우 큰 데이터의 컬렉셕을 키우는 능력을 제공합니다.  

대규모 스택은 특히 현재 사용자 행동이나 트위트 스트림, 본 상품과 같은 시간 직렬 데이터나 방문한 웹사이트나 만든 권장사항을 추적하는 데 적합합니다(The Large Stack is particularly suited for tracking current user behavior or time series data like tweet streams, products viewed, websites visited or recommendations made). 최근의 모든 활동은 lstack에 푸시되고 결정은 최근 데이터를 기반으로 만들어집니다.  

##### 특징

대규모 스택은 다음의 기능을 가집니다:

* 원자나 복잡한 객체 관리
* 무한 저장소
* 바이너리 저장소 모드
* 오래된 컬렉션 요소를 캡 성장과 퇴거하는 능력
* UDF 조건 필터, UDF 변환
* 단일 항목 또는 여러 항목 삽입
* 옵션 UDF 필터를 지닌 스택 지향 검색
* 옵션 UDF 필터를 지닌 풀 스캔
* 스택 지향 제거(pop)

##### 사용 사례

대규모 스택 타입은 특히 현재 사용자 행동이나 트위트 스트림, 본 상품과 같은 시간 직렬 데이터나 방문한 웹사이트나 만든 권장사항을 추적하는 데 적합합니다.  

표 1은 트위트가 대규모 스택에 축적되고 푸시되는 트위트 스트림의 예시를 보여줍니다. 쿼리는 탑 N 요소가 시험되는 스택의 탑에서 실행될 수 있습니다.

![LDT_Record_LStack.png](LDT_Record_LStack.png)

> 표 1  
고객 트위트를 과니하는 대규모 스택

#### 대규모 데이터 타입(LDT) 어플리케이션 프로그래밍 인터페이스(API)

LDTs는 다음에서 접근될 수 있습니다:

* [사용자 정의 함수](http://www.aerospike.com/docs/udf/udfs_and_ldts.html)
* [에어로스파이크 씨 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/c/usage/ldt/index.html)
* [에어로스파이크 자바 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
* [에어로스파이크 씨# 프로그래밍 언어 클라이언트](http://www.aerospike.com/docs/client/csharp/usage/ldt/ldt.html)

#### 완벽한 예시

이 예제에서 우리는 에어로스파이크 [ascli](http://www.aerospike.com/docs/tools/ascli/)도구와 [aql](http://www.aerospike.com/docs/tools/aql/)도구를 사용하여 각각의 대규모 스택(lstack) 기능의 사용을 설명합니다. 두 도구는 에어로스파이크 서버에 작은 작업을 수행하는 데 편리합니다.  

먼저 우리는 이것과 비슷한 ==ascli== 명령을 사용하여 대규모 세트로 요소의 갯수를 삽입:

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 55

이 명령의 세부사항을 살펴보자. ==ascli udf-record-apply==는 네임스페이스 ==test==, 세트 ==demo==과 키 ==Key_1==을 사용하여 레코드에 UDF를 호출합니다.  

우리가 호출하는 UDF는 패키지 ==lstack==에 있고, 이 패키지는 대규모 스택의 구현입니다.  

여기에 해당하는 ==aql==:

	execute lstack.push('LSTACK_BIN', 55) on test.demo where pk = 'Key_1'

==execute== 키워드는 키 ==where pk : 'Key_1'==에 세트 ==on test.demo==와 네임스페이스의 레코드에 ==lstackpush==기능을 호출합니다.

##### peek()

대규모 스택의 탑에서 요소를 검색하기위해서 너는 ==peek()== 기능을 사용하고, 이것은 스택에서 너가 원하는 요소의 갯수인 매개변수를 이용합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "peek" "LSTACK_BIN" 1

###### aql

	execute lstack.peek('LSTACK_BIN', 1) on test.demo where pk = 'Key_1'

##### scan()

==scan()== 기능은 전체 대규모 스택을 스캔하고 대규모 스택의 모든 값을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "scan" "LSTACK_BIN"

###### aql

	execute lstack.scan('LSTACK_BIN') on test.demo where pk = 'Key_1'

##### size()

==size()==는 대규모 스택의 요소 갯수를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "size" "LSTACK_BIN"

###### aql

	execute lstack.size('LSTACK_BIN') on test.demo where pk = 'Key_1'

##### get_config()

==get_config()== 기능은 적절히 구성하는한 설정과 현재 값을 나타내는 맵 객체를 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "get_config" "LSTACK_BIN"

###### aql

	execute lstack.get_config('LSTACK_BIN') on test.demo where pk = 'Key_1'

##### get_capacity()

==get_capacity()== 기능은 LDT 인스턴스의 최대 용량을 반환합니다. 대규모 스택 LDT는 기본적으로 최대 용량(이것은 기본적으로 무한대로 커짐)을 가지지 않지만, 이것은 우발적 저장소 과용을 막기위해 최대 크기를 설정할 수 있습니다.  

get_capacity()가 바이트가 아닌 아이템의 개념으로 설정 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 카운트를 반환합니다.  

대규모 스택은 용량이 도달했을때 오래된 데이터를 퇴거하는 특별한 능력을 가집니다. (대규모 리스트 및 대규모 스택에 가능한)설정 제한이 없을때, get_capacity는 0을 반환합니다.

> 대규모 스택 LDT는 기본적으로 최대 용량(이것은 기본적으로 무한대로 커짐)을 가지지 않지만, 이것은 우발적 저장소 과용을 막기위해 최대 크기를 설정할 수 있습니다. get_capacity()가 바이트가 아닌 아이템의 개념으로 설정 제한을 반환하는 반면에, size() 기능은 LDT의 현재 항목 카운트를 반환합니다. 대규모 스택은 용량이 도달했을때 오래된 데이터를 퇴거하는 특별한 능력을 가집니다. (대규모 리스트 및 대규모 스택에 가능한)설정 제한이 없을때, get_capacity는 0을 반환합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "get_capacity" "LSTACK_BIN"

###### aql

	execute lstack.get_capacity('LSTACK_BIN') on test.demo where pk = 'Key_1'

##### destroy()

==destroy()==는 전체 대규모 스택을 제거하고 빈 ==LSTACK_BIN==을 널로 설정합니다. 이것은 효과적으로 빈을 제거합니다.

###### ascli

	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "destroy" "LSTACK_BIN"

###### aql

	execute lstack.destroy('LSTACK_BIN') on test.demo where pk = 'Key_1'

#### 완벽한 ASCLI 예시

이것은 (ascli 명령을 포함하는)완벽한 BASH shell 스크립트 입니다:

	echo "<< -----------  <><><><><><><><><><><><> -------------- >> "
	echo "<< -----------    LSTACK  ASCLI EXAMPLE  -------------- >> "
	echo "<< -----------  <><><><><><><><><><><><> -------------- >> "

	echo "UDF/LDT 호출을 위한 포괄적인 형식은 :"
	echo "ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS"

	echo "대규모 스택 명령은: "
	echo " (*) Status = push( topRec, ldtBinName, newValue, userModule )"
	echo " (*) Status = push_all( topRec, ldtBinName, valueList, userModule )"
	echo " (*) List   = peek( topRec, ldtBinName, peekCount ) "
	echo " (*) List   = pop( topRec, ldtBinName, popCount ) "
	echo " (*) List   = scan( topRec, ldtBinName )"
	echo " (*) List   = filter( topRec, ldtBinName, peekCount,userModule,filter,fargs)"
	echo " (*) Status = destroy( topRec, ldtBinName )"
	echo " (*) Number = size( topRec, ldtBinName )"
	echo " (*) Map    = get_config( topRec, ldtBinName )"
	echo " (*) Status = set_capacity( topRec, ldtBinName, new_capacity)"
	echo " (*) Status = get_capacity( topRec, ldtBinName )"

	echo "LDT에 몇몇의 요소를 추가"
	set -v
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 55
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN"  5
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 25
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 75
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 15
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 45
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 35
	set +v

	echo "대규모 스택에서 한 요소 얻기"
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "peek" "LSTACK_BIN" 1

	echo "LDT 스캔"
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "scan" "LSTACK_BIN"

	echo "LDT의 크기 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lstack" "size" "LSTACK_BIN"
	
    echo "LDT의 구성 보기"
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "get_config" "LSTACK_BIN"

	echo "LDT의 용량 얻기"
    ascli udf-record-apply "test" "demo" "Key_1" "lstack" "get_capacity" "LSTACK_BIN"

	echo "LDT 제거"
    ascli udf-record-apply "test" "demo" "Key_1" "lstack" "destroy" "LSTACK_BIN"

	echo "  <><><>  끝!! <><><>"

우리는 다음 출력을 예상합니다:

	$ ./lstack_example.sh 
	<< -----------  <><><><><><><><><><><><> -------------- >> 
	<< -----------    LSTACK  ASCLI EXAMPLE  -------------- >> 
	<< -----------  <><><><><><><><><><><><> -------------- >> 
	UDF/LDT 호출을 위한 포괄적인 형식은 :
	ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS
	대규모 스택 명령은 :
 	(*) Status = push( topRec, ldtBinName, newValue, userModule )
 	(*) Status = push_all( topRec, ldtBinName, valueList, userModule )
 	(*) List   = peek( topRec, ldtBinName, peekCount ) 
 	(*) List   = pop( topRec, ldtBinName, popCount ) 
 	(*) List   = scan( topRec, ldtBinName )
 	(*) List   = filter( topRec, ldtBinName, peekCount,userModule,filter,fargs)
 	(*) Status = destroy( topRec, ldtBinName )
 	(*) Number = size( topRec, ldtBinName )
	 (*)  Map    = get_config( topRec, ldtBinName )
	 (*) Status = set_capacity( topRec, ldtBinName, new_capacity)
	 (*) Status = get_capacity( topRec, ldtBinName )
	LDT에 몇가지 요소를 추가
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 55
	0
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN"  5
	0
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 25
	0
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 75
	0
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 15
	0
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 45
	0
	ascli udf-record-apply "test" "demo" "Key_1" "lstack" "push" "LSTACK_BIN" 35
	0
	set +v
	대규모 스택에서 한 요소 얻기
	[ 35 ]
	LDT 스캔
    [ 35, 45, 15, 75, 25, 5, 55 ]
	LDT의 크기 얻기
	7
    LDT의 구성 보기
	{ "ColdTopFull": "F", "WarmListMax": 100, "ColdListMax": 100, "StoreMode": "L", "PropEsrDigest": 0, "SSMMARY": "LSTACK Summary", "ColdDirListHead": 0, "WarmListDigestCount": 0, "RecType": 1, "PropMagic": "MAGIC", "PropCreateTime": 1400896195085, "LdrEntryCountMax": 100, "WarmListTransfer": 2, "PropBinName": "LSTACK_BIN", "LdrByteEntrySize": 0, "PropLdtType": "LSTACK", "PropVersion": 2, "HotListTransfer": 50, "LdrByteCountMax": 0, "PropItemCount": 7, "HotEntryListItemCount": 7, "HotListMax": 100, "StoreLimit": 100000, "ColdDirRecMax": 5 }
    LDT의 용량 얻기
	100000
    LDT 제거
	0
      <><><> 끝!! <><><>

#### 완벽한 AQL 예시

	print '<< -----------  <><><><><><><><><><><><> -------------- >> '
	print '<< -----------    LSTACK  ASCLI EXAMPLE  -------------- >> '
	print '<< -----------  <><><><><><><><><><><><> -------------- >> '

	print 'UDF/LDT 호출을 위한 포괄적인 형식은 :'
	print 'ascli udf-record-apply NS SET KEY MODULE FUNCTION ARGS'

	print '대규모 스택 명령은 :'
	print ' (*) Status = push( topRec, ldtBinName, newValue, userModule )'
	print ' (*) Status = push_all( topRec, ldtBinName, valueList, userModule )'
	print ' (*) List   = peek( topRec, ldtBinName, peekCount ) '
	print ' (*) List   = pop( topRec, ldtBinName, popCount ) '
	print ' (*) List   = scan( topRec, ldtBinName )'
	print ' (*) List   = filter( topRec, ldtBinName, peekCount,userModule,filter,fargs)'
	print ' (*) Status = destroy( topRec, ldtBinName )'
	print ' (*) Number = size( topRec, ldtBinName )'
	print ' (*) Map    = get_config( topRec, ldtBinName )'
	print ' (*) Status = set_capacity( topRec, ldtBinName, new_capacity)'
	print ' (*) Status = get_capacity( topRec, ldtBinName )'

	print 'LDT에 몇가지 요소를 추가'
	execute lstack.push('LSTACK_BIN', 55) on test.demo where pk = 'Key_1'
	execute lstack.push('LSTACK_BIN',  5) on test.demo where pk = 'Key_1'
	execute lstack.push('LSTACK_BIN', 25) on test.demo where pk = 'Key_1'
	execute lstack.push('LSTACK_BIN', 75) on test.demo where pk = 'Key_1'
	execute lstack.push('LSTACK_BIN', 15) on test.demo where pk = 'Key_1'
	execute lstack.push('LSTACK_BIN', 45) on test.demo where pk = 'Key_1'
	execute lstack.push('LSTACK_BIN', 35) on test.demo where pk = 'Key_1'

	print '대규모 스택에서 한 요소 얻기'
	execute lstack.peek('LSTACK_BIN', 1) on test.demo where pk = 'Key_1'

	print 'LDT 스캔'
	execute lstack.scan('LSTACK_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 크기 얻기'
	execute lstack.size('LSTACK_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 구성 보기'
	execute lstack.get_config('LSTACK_BIN') on test.demo where pk = 'Key_1'

	print 'LDT의 용량 얻기'
	execute lstack.get_capacity('LSTACK_BIN') on test.demo where pk = 'Key_1'

	print 'LDT 제거'
	execute lstack.destroy('LSTACK_BIN') on test.demo where pk = 'Key_1'

	print ' <><><> 끝!! <><><>'

언어별 예시는 다음에서 볼 수 있습니다:

1. [자바 클라이언트-LDT](http://www.aerospike.com/docs/client/java/usage/ldt/ldt.html)
2. [씨 클라이언트-LDT](http://www.aerospike.com/docs/client/c/usage/ldt/)

#### 작업

다음은 lstack을 포함하는 빈에 수행되는 작업입니다.

##### push

lstak으로 ==값==을 덧붙임

	push(value: Value) -> Integer

###### 매개변수

* ==값== - 스택의 탑에 푸시하는 값

###### 반환

작업의 결과를 나타내는 상태 코드

##### push_all

lstack에 각 ==값==을 덧붙임

	push_all(values: List) -> Integer

###### 매개변수

* ==값== - 스택의 탑으로 푸시하는 값의 목록

###### 반환

작업의 결과를 나타내는 상태 코드

##### peek

lstack에서 탑 ==n== 값을 피크

	peek(n: Integer) -> List

###### 매개변수

* ==n== - 반환하는 값의 수

###### 반환

lstack에서 탑 ==n==값의 리스트

##### scan

lstack을 스캔하고 모든 값을 반환

	scan() -> List

###### 반환

lstack의 모든 값의 리스트

###### 주의

lstack에 저장되는 데이터의 양에 따라 이것은 비싸질 수도 있습니다.

##### filter

조건 ==p==를 만족하는 첫번째 ==n== 값을 찾기

	filter(n: Integer, p: (value: Value) -> Boolean) -> List

###### 매개변수

* ==n== - 반환하는 값과 일치하는 수
* ==p== - 각 값에 적용되는 조건. 조건은 주어진 값에 대해 ==참==이나 ==거짓==을 반환하는 기능이어야 합니다.

###### 반환

조건 ==p==를 만조하는 첫번째 ==n== 값의 리스트

##### destroy

lstack 빈과 모든 연관된 데이터를 파괴

	destroy() -> Integer

###### 반환

작업의 결과를 나타내는 상태 코드

##### size

lstack의 값의 수

	size() -> Integer

###### 반환

lstack의 값의 수

##### get_config

lstack의 구성 매개변수 얻기

	get_config() -> Map

###### 반환

lstack에 대한 모든 구성 설정을 포함하는 ==맵==

##### set_capacity

lstack에 저장되는 값의 최대수를 설정

	set_capacity(size: Integer) -> Integer

###### 매개변수

* ==크기== - 값의 최대 수

###### 반환

작업의 결과를 나타내는 상태 코드

##### get_capacity

lstack에 저장되는 값의 최대수 얻기

	get_capacity() -> Integer

###### 반환

저장되는 값의 최대수 반환

#### 제한

* 개별 객체는 설정된 서브레코드 크기보다 더 적어야 합니다.

## LDT 인터널

#### 대규모 데이터 타입 인터널

대규모 데이터 타입의 개념은 비교적 파악하기 쉽습니다- 이것은 몇몇의 추가 기능이 제공되는 레코드 빈에 UDF 호출입니다. 하지만, 커버아래에, 이것뿐만이 아닙니다-- 기계의 상당량과 너가 LDTs를 최대로 활용할때 이해하기 위한 설정이 있습니다.  

먼저, 우리는 각 LDT를 통과하고 기본적인 내용을 보여줍니다. 그리고, 우리는 많이 아는 사용자가 그들의 이익을 위해 활용할 수 있는 것들중 일부를 설명합니다.

##### 대규모 데이터 타입 파일

LDTs의 진실은 LDT 기능을 구현하는 루아 모듈을 가지는 것입니다. 물론, 이런 모듈은 어떤 내용이나 설명이 필요합니다.  

모듈 파일을 어디서 찾는 지부터 살펴보자. 너가 설치된 에어로스파이크를 가질때, 너는 다음 두 장소에서 LDT 모듈 파일을 찾을 수 있습니다:

* /opt/aerospike/sys/udf/lua/external : LDTs의 모든걸 외부적으로 볼 수 있는 기능을 유지

   * llist.lua
   * lmap.lua
   * lset.lua
   * lstack.lua
   * test.lua
   * udflib.lua

* /opt/aerospike/sys/udf/lua/ldt : LDT 라이브러리와 내부의 문서 파일을 유지

   * 주요 LDT 모듈

        * lib_llist.lua
        * lib_lmap.lua
        * lib_lset.lua
        * lib_lstack.lua

   * 설정 모듈

        * settings_llist.lua
        * settings_lmap.lua
        * settings_lset.lua
        * settings_lstack.lua

   * 일반 모듈

       * CRC32.lua
       * ldt_common.lua
       * ldt_errors.lua
       * UdfFunctionTable.lua

   * 문서 파일

       * doc_llist.md
       * doc_lmap.md
       * doc_lset.md
       * doc_lstack.md

   * 테스트 파일

       * lib_test.lua

**주요 LDT 모듈**은 실제 LDT 로직을 포함합니다. LDTs는 그들의 기능이 외부적으로 그리고 내부적으로 호출될 수 있도록 라이브러리로 쓰입니다:

* 외부적으로 - (==/opt/aerospike/sys/udf/lua/external==에서 정의된)위의 외부 기능을 호출하는 클라이언트 호출(예: 씨,자바,씨#)이나 도구(예: ascli,aql)를 통해
* 내부적으로 - 루아 API를 사용하여 LDT 라이브러리 기능을 호출하는 UDFs를 통해

##### LDT 세부사항

다음 섹션에서 우리가 다루는 몇개의 저수준 세부사항입니다:

* **LDT 빈 복잡한 객체(ldtCtrl)**:  
  각각의 대규모 데이터 타입은 (루아 코드에서 "ldtCtrl"로 불리는 )탑 레코드 빈의 복잡한 객체를 저장합니다. 각 타입이 다른 설정값과 데이터 저장소를 관리할때, 각 LDT 타입은 다른 ldtCtrl 객체를 저장합니다. 우리는 각 LDT 타입의 세부사항으로 넣습니다.

* **컴팩트 리스트**: 컬렉션 타입을 관리하는 "본격 메커니즘"으로 바뀌기전에, 각 LDT는 주요 레코드에 첫번째 N 아이템을 저장하는 메커니즘을 가집니다. 우리는 세부사항을 설명하고 예시를 보여줍니다.
* **객체 번역**: 객체가 각각의 LDT 컬렉션에 다르게 저장될 지라도, 관리의 일부는 동일하게 머뭅니다. 모든 LDT를 위해서, 이것을 저장소에서 읽은 후 객체를 **비변형**하고 저장소에 쓰이기 전에 이것은 객체를 **변형**시키는 기능의 쌍(UDFs의 형태로)을 지정할 수 있습니다.
* **저장소 형식**: 각각의 LDTs는 저장소에 대한 두가지 모드를 가집니다: 리스트 모드와 바이너리 모드. 우리는 각각의 세부사항을 보여줍니다.
* **잔여 조건에 대한 필터 사용**: LDT의 주요 접근은 기본 메커니즘(예: 스택을 위한 가장 최신 N 아이템, 리스트를 위한 범위 쿼리, 맵을 위한 이름/값 쌍, 세트를 위한 직접적인 객체)을 이용하지만, 추가적인 처리가 필요한 시간이 있습니다. 기본 결과를 이동하는 것이 배달 처리를 위해 클라이언트에 설정되는 것보다, 우리는 UDF를 통해 행해지는 추가적인 배달 처리를 허용합니다.
* **키를 위한 UDFs 또는 값 얻기의 사용**: 대규모 리스트의 경우에서, 저장된 객체를 정렬하는 데 사용되는 키는 원자 타입(예: 숫자 또는 스트링)이어야 합니다. 저장되는 올바른 객체가 복잡할때(예: 숫자 또는 스트링), "키" UDF는 적절한 키 값을 얻는 데 사용됩니다. 비슷하게, "고유 값" UDF는 대규모 세트를 가진 사용을 위해 원자 값을 얻는 데 사용됩니다.
* **서브레코드 관리**: 에어로스파이크의 서브레코드 저장소 구성요소는 우리가 서브레코드의 사용을 위해 특정 규칙을 허용하는 걸 요구합니다. 따라서, 우리가 UDF에서 LDTs 호출을 반복할때 우리는 고수준 LDT 호출을 지원해야하는 우리의 서브레코드 추적 상태의 일부를 유지해야 합니다.

#### LDT 빈 복잡한 객체(ldtCtrl)

적어도 하나의 LDT를 포함하는 레코드에서, 다음은 적어도 두 개의 빈을 사용합니다:

* 레코드,레코드 버전,레코드 다이제스트의 모든 LDTs의 카운트를 유지하는 특별한 숨겨진 시스템 빈. 이것의 이름은 **LDTCONTROLBIN**이지만, KV ==get== 호출을 가지는 모든 빈을 얻으려고 할때 너는 이것을 볼 수 없습니다; 이것은 일반 KV 작업에서 볼 수 없습니다.
* 각 LDT를 위해, 구조를 포함하는 사용자 지명 LDT 빈은 LDT 타입에 지정합니다. 그 구조는 "LDT 컨트롤" 또는 너가 코드에서 볼땐 **ldtCtrl**로 언급됩니다. LDT 컨트롤 구조는 두 개의 맵 리스트입니다. 첫번째 맵은 변함없이 모든 LDTs를 지나는 표준 LDT 구성 구조이고, 이것은 다음 정보를 포함합니다:

   * 컬렉션을 위한 아이템 카운트
   * 버전 넘버
   * 서브 레코드 카운트
   * LDT 타입(llist,lmap,lset,lstack)
   * 이 LDT를 위한 빈 이름
   * 생성 시간

* 두번째 맵은 LDT 구성과 모든 "탑 레코드" 데이터가 저장되는 곳인 특정 LDT에 관계된 모든 정보를 포함합니다. 또한, 각 LDT에 다르게 수행되더라도, 적은 아이템이 있는 컬렉션은 서브레코드의 생성을 작동합니다. 컬렉션 데이터 요소는 아이템의 **한계** 수가 삽입될때까지 탑 레코드에 보관됩니다. 다음 섹션에서, 각 LDT 타입별 구조를 보세요.

    * [대규모 정렬된 리스트 인터널](http://www.aerospike.com/docs/guide/llist_internals.html)
    * [대규모 맵 인터널](http://www.aerospike.com/docs/guide/lmap_internals.html)
    * [대규모 세트 인터널](http://www.aerospike.com/docs/guide/lset_internals.html)
    * [대규모 스택 인터널](http://www.aerospike.com/docs/guide/lstack_internals.html)
    * [일반 LDT 기능 인터널](http://www.aerospike.com/docs/guide/common_internals.html)

##### 컴팩 리스트

카운터가 몇몇 설정 가능한 한계 아래일때 각 LDT는 바로 메인 레코드에 항목 갯수를 저장하는 메커니즘을 가집니다. 그러나, 각 LDT는 컴팩 리스트를 다르게 관리합니다. 대규모 스택은 내재적으로 핫 리스트 오버플로우처럼 훌륭하게 웜 리스트에서 나온 객체를 숙성하는 핫 리스트를 관리합니다. 아이템이 핫 리스트 "언더 플로우"와 스택의 밖으로 팝될때, 아이템은 다시 웜 리스트에서 핫 리스트로 이동합니다. 대규모 세트, 대규모 맵과 대규모 정렬된 리스트 각각은 LDT 카운트가 한계값 아래에 있을때 데이터 아이템을 유지하는 ==컴팩 리스트==라고 불리는 LDT 컨트롤 구조의 필드를 가집니다. 컬렉션 아이템이 클 때 한계값은 적절하게(아주 느린 세트처럼) 설절되어야 합니다. 매우 큰 아이템 크기와 대규모 한계값은 레코드 최대 크기를 초과하는 LDT를 야기시킵니다.

##### 객체 변형과 비변형

이것이 저장소에 쓰이기전과 이것을 저장소에서 읽은 후에 사용자는 크기와 객체의 모양을 바꾸는 기회를 가집니다. LDT 생성 시간(암시 또는 명시 생성)에서, 사용자모듈은 쓰기 및 읽기 전에 옵셕적으로 호출될 수 있는 **transform()**과 **untransform()** 기능을 지정합니다.

###### 예제

이 예제에서, 우리는 LStack의 인터널 바이트 저장소에 고정된 크기 객체를 저장하는 데 사용되는 크기 18의 바이트 어레이에 5개 숫자의 리스트를 변환합니다(아래 참조).

* [변화 예시](http://www.aerospike.com/docs/guide/examples/transformation.html)

##### 물리적 저장소

LDTs의 각각은 데이터 저장소를 위해 "리스트 모드"나 "바이너리 모드"를 사용하는 구성 설정을 가집니다. 리스트 모드는 객체를 저장하는 루아 리스트 메커니즘을 사용합니다(아마 크기 변화). 바이너리 모드는 고정된 크기 객체로 변형시킨 객체를 유지하는 바이너리 어레이를 사용합니다(변형 UDF가 필요함). 바이너리 모드는 저장되는 특정 객체의 상태에 따라 표준 리스트 모드를 넘어 일부 저장소나 성능 향상의 결과를 가져옵니다.

###### 예시

이 예제에서 우리는 위에서 생성된 transform()과 untransform()기능을 이용하고, 우리는 바이너리 모드를 선택하는 LDT 구성 설정을 적용하고 적절한 객체 크기를 설정합니다.

* [물리적 저장소 예시](http://www.aerospike.com/docs/guide/examples/physical_storage.html)

###### 주의

현재 대규모 스택에서만 사용될지라도, **바이너리** 저장소 모드 옵션은 모든 LDT 타입에 대해서 곧 사용될 수 있습니다.

##### LDT 필터

LDT의 많은 읽기 기능과 명확하게 LDT 필터 기능: (lstack.filter(),llist.filter(),lmap.filter(),lset.filter())은 읽기/스캔 작업의 결과가 추가 작업의 일부를 수행하는 옵션 UDF를 통과하는 추가 필터링 기능을 제공합니다. LDT 필터는 복잡한 객체(스트림 UDF 필터같은 불린 보단)를 반환해서, 단순히 필터링 이상의 일을 할 가능성이 있습니다. 일반적으로, 초기 LDT 컬렉션 검색후 LDT 필터는 보조 또는 남은 조건의 일부 유형을 평가하는데 사용됩니다. 하지만, 사실, LDT 필터가 거의 모든 걸 할 수 있는 일반용도의 UDF이기 때문에 이것은 개발자의 상상에 의해서만 제한됩니다.  

LDT 필터는 여러 방법으로 관리됩니다:

* LDT 필터는 UdfFunctionTable.lua 파일(LDT 시스템 파일 중 하나)에서 찾을 수 있는 표준 UDFs 중 하나가 될 수 있습니다. 우리는 그 파일에 유용한 UDFs 일부를 넣고, 우리는 우리가 더 유용한 UDFs를 구축하거나 발견할때 커지는 루아 파일을 기대합니다; 이 파일은 변형,비변형,키 얻음,고유 식별자 얻음 및 필터링에 대한 유용한 기능을 포함합니다. 이 특정 시스템의 루아 파일에서 사용하는 UDFs의 장점 중 하나는 그들이 일반 사용자가 제공하는 UDF에 대한 경우와 같이 등록될 필요가 없다는 것입니다.
* LDT 필터는 초기 LDT 생성의 일부로 지정된 사용자의 **사용자모듈**에 포함될 수 있습니다. 이 루아 사용자모듈은 일반적인 방법으로 등록되야 합니다.(아래 예시)
* LDT 필터는 읽기 기능 자체에 포함되는 "오버라이드" 모듈에 포함될 수 있습니다. 이 루아 모듈은 일반적인 방법으로 등록되어야 합니다(또한, 아래 예시). LDTs의 각각은 다음과 같은 filter() 기능을 가집니다:

	(List)  = filter( topRec, ldtBinName, userModule, filter, fargs )

리스트로 **사용자모듈**이 특별한 루아 파일을 지명하고, **필터**가 실제 필터 기능을 지명하고, **fargs**가 필터 기능에 전달되는 인수의 리스트를 나타내는 곳

###### 우선

동일한 이름을 가진 필터는 위에 언급된 위치 각각에 존재할 수 있습니다. 필터의 우선 순위는 다음과 같습니다:

1. 오버라이드 모듈에 지명된 필터가 있을때, 이것이 먼저 선택됩니다.
2. 오버라이드 모듈에 지명된 필터가 없을때, 이것은 생성 모듈에 존재하지 않고, 생성 모듈 필터가 선택됩니다.
3. 오버라이드 또는 생성 모듈에 지명된 필터가 없을때, 표준 시스템 파일인 UdfSystemTable이 실행되고 거기에서 지명된 파일을 발견할때, 그것이 선택됩니다.

###### 예시

우리는 두 예시를 보여줍니다. 첫번째(선택 필터)는, 특정 요소를 선택하는 하드 코드된 UDF입니다. 이것이 일반적으로 사용되는 고정된 쿼리(즉, 고정 조건)에 나타날때 UDF 필터의 이 타입은 그런 경우에 대해서 일반적입니다. 두번째 예(범위 필터)는 합성 범위 조건을 나타내느 JSON 객체에 전달하는 호출자를 허용하는 유연성 있는 UDF입니다. 범위 필터 예는 상한 및 하한 바운드를 가진 각각에 전달되는 여러 필드를 허용합니다.

1. [선택 필터 예시](http://www.aerospike.com/docs/guide/examples/selection_filter.html)
2. [범위 필터 예시](http://www.aerospike.com/docs/guide/examples/range_filter.html)

##### 키와 고유 값 얻기

###### 예시

우리가 복잡한 객체(예: 리스트나 맵)에서 값을 얻을 필요가 있는 두 개의 다른 상황이 있습니다. 대규모 정렬된 리스트 컬렉션의 사용에 대한 복잡한 객체에서 원자 값(예: 숫자나 스트링)을 얻을 필요가 있는 것이 첫번째 경우입니다. 그 값은 간단하고 순서대로 넣어야 합니다. 두번째 경우는 우리가 대규모 세트 컬렉션의 사용을 위한 해시 기능으로 공급하는 원래 객체보다 더 작은 객체 일부를 얻을 필요가 있는 것입니다.

1. [키 기능 예시](http://www.aerospike.com/docs/guide/examples/key_function.html)
2. [고유 값 기능 예시](http://www.aerospike.com/docs/guide/examples/unique_function.html)

### 대규모 리스트 인터널

### 대규모 정렬된 리스트 인터널

#### 소개

대규모 정렬된 리스트(LLIST)는 객체가 바로 비교할 수 있거나 이것이 비교가능한 값을 생산하는 객체를 허용하는 "Key()" 기능을 가지는 것 중 하나로 제공되는 객체의 모든 타입을 받아들입니다. 이것은 비교를 위해 사용되는 값이 모두 동일한 타입인 제한을 가지고, 그 타입은 함축적으로 리스트에 삽인되는 첫번째 값의 타입에 의해 결정됩니다. 보조 LDT 기능 설정에 대한 자세한 내용은 [LDT 설정](http://www.aerospike.com/docs/guide/ldt_configuration.html)섹션에서 다룹니다.

#### LDT 컨트롤 구조

사용자가 LLIST 빈을 생성할때, 새로운 LDT 빈은 LDT 데이터 구조와 구성 설정을 유지하는 복잡한 LDT 컨트롤 구조를 제공합니다.(표 1과 2)

 	"ldtCtrl"로 알려진 LDT 빈의 내용은 두개 맵의 리스트로 이뤄진 구조를 제어합니다. 첫번째 맵(LDT 속성 맵)은 모든 LDTs를 공통으로 지나는 필드를 가집니다. 두번째 맵(LDT 컨트롤 맵)은 LDT의 특정 타입에 지정하는 필드와 LDT 인스턴스에 지정하는 값을 가집니다.

	 DB 레코드: 표준 "서브레코드" 모드
	 +----+----+----+---+------+---+-----+
	 |LDT |User|User| o |LLIST | o |User |
	 |Ctrl|Bin |Bin | o |Bin   | o |Bin  |
	 |    |1   |2   | o |      | o |N    |
	 +----+----+----+---+------+---+-----+
	                      |
	                      V
	                   +==================+
	 ldtCtrl: 두 맵의  | LDT Property Map |
	 리스트 :          +------------------+
	 (1) ldtProp       | LDT Control Map  |
	 (2) ldtMap        +==================+

	 표 1: DB 레코드의 시각 설명과 LDT 빈

적어도 한 LDT를 포함하는 데이터베이스 레코드는 (사용가 숨긴)특별한 시스템 LDT 컨트롤 빈과 (이 경우엔, LLIST 빈)한 LDT 빈을 가집니다. 대규모 맵 컨트롤 구조(ldtCtrl)는 두 맵의 리스트입니다.

#### LDT 속성 맵

첫번째 맵(LDT 속성 맵)은 모든 LDTs의 공통 필드 세트입니다:

* ItemCount : LDT의 모든 아이템의 카운트
* Version : 코드 버전
* SubRecCount : LDT의 서브레코드 수
* LdtType : 타입: 스택,세트,맵,리스트
* BinName : LDT 빈 이름
* Magic : 특별한 상수(확인을 위한)
* CreateTime : LDT의 서버 생성 시간
* EsrDigest : ESR의 다이제스트
* RecType : 레코드의 타입

#### LDT 컨트롤 맵

 	       LLIST 컨트롤 맵
           +============+
           |   LLIST    |
           |   control  |
           +<><><><><><>+
           | (Root Dir) |
           |  Key List  |
           |  SRP List  |
           +============+

	표 2: LLIST 컨트롤 맵 구조

두번째 맵(표 2)은 모든 LDTs에 공통인 일부와 대규모 맵에 지정하는 일부인 값의 세트를 보유합니다:

* 이 필드는 모든 LDTs 전체에서 동일합니다. 그들은 ldt_common.lua 기능에 의해 관리됩니다:

     * UserModule : 구성과 오버라이드에 대한 사용자의 루아 파일
     * KeyFunction : 사용자 지원 키 얻기 기능
     * KeyType : 사용된 키의 타입(원자,복잡한)
     * StoreMode : 리스트 모드나 바이너리 모드
     * StoreLimit : 퇴거를 위해 사용되는
     * Transform : 루아를 바이트 형식으로 변환
     * UnTransform : 바이트에서 루아 형식으로 변환

* 이런 필드는 대규모 세트에 고유하고, 그들은 lib_llist.lua 기능에 의해 관리됩니다:

     * **트리 수준 값**
     * TotalCount : LLIST에서 사용되는 모든 "공간"의 카운트
     * LeafCount : 모든 leaf 노드의 카운트
     * NodeCount : 모든 노드의 카운트(leaves를 포함하는)
     * TreeLevel : 트리 레벨(루트;;내부 노드;;leaves)
     * KeyDataType : 키의 데이터 타입(숫자,스트링)
     * KeyUnique : 키들이 고유한지?(참 또는 거짓으로)
     * StoreState : 컴패트나 일반 저장소
     * Theshold : # 후 : 컴팩트를 트리 모드로 이동
     * **고정된 길이의 바이트 어레이를 사용할때, 키와 객체의 크기**
     * R_KeyByteSize : 키의 고정된 크기(바이트로)
     * R_ObjectByteSize : 객체의 고정된 크기(바이트로)
     * **상위 노드 트리 루트 디렉토리**
     * RootListMax : 키 리스트의 길이(서브 레코드 Ptr 리스트는 KL +1)
     * RootByteCountMax : 루트의 키공간에 관한 바이트의 최대 #
     * KeyByteArray : 압축 모드일때, 바이트 어레이
     * DigestByteArray : 압축 모드일때, 바이트 어레이
     * RootKeyList : 리스트 모드일때, 루트 키 리스트
     * RootDigestList : 리스트 모드일때, 다이제스트 리스트
     * CompactList : "트리 모드" 전에 단순한 컴팩 리스트
     * **LLIST 내부 노드 설정**
     * NodeListMax : 노드의 아이템의 최대 수(키 + 다이제스트)
     * NodeByteCountMax : 노드의 키공간에 대한 바이트의 최대 수
     * **LLIST 트리 leaves(데이터 페이지)**
     * LeafListMax : leaf 노드의 아이템의 최대 수
     * LeafByteCountMax : leaf의 객체 공간에 관한 바이트의 최대 수
     * LeftLeafDigest : Left-most leaf의 레코드 Ptr
     * RightLeafDigest : Right-most leaf의 레코드 Ptr

이런 컨트롤 맵 항목 각각은 런타임 값(예: RootKeyList, StoreState)이나 설정 매개변수(예: RootListMax, Theshold)를 나타냅니다.  

LDT 컨트롤 맵에 키 항목과 서브레코드 포인터(SRPtr)로 구성되는 B+ 트리 루트 노드가 있습니다.

#### 대규모 정렬된 리스트 B+ 트리 구현

대규모 정렬된 리스트는 B+ 트리 구조로 구현됩니다. B+ 트리는 인기있는 인덱스 메커니즘이고, 이것은 데이터가 지속적인 저장소일때 정렬된 리스트를 관리하는 데 효율적입니다.

	이건 B+ 트리의 샘플 : N 키와 (N+1) 포인터(다이제스트)가 내부 노드(루트를 포함하는)에 있습니다. 모든 데이터는 leaves에 있고, 내부 노드는 키와 포인터뿐 입니다. 실제 B+ 트리 노드가 약 100개(키 크기에 따라 더 많거나 더 적은)의 팬아웃을 가지지만, 여기에서 표현하기엔 너무 어렵습니다.

 	 	 						   _________
 	           (Root 노드)          |_30_|_60_|
	                              _/      |      \_
	                            _/        |        \_
	                          _/          |          \_
 	                       _/            |            \_
	                      _/              |              \_
	(internal 노드 )    _/                |                \_
	         ________ _/          ________|              ____\_________
	        |_5_|_20_|           |_40_|_50_|            |_70_|_80_|_90_|
	       /    |    |          /     |    |           /     |    |     \
	      /     |    |         /      |    |          /      |    |     |
	     /     /     |        /      /     |        _/     _/     |     |
	    /     /      /       /      /      /       /      /      /      |
	 +-^-++--^--++--^--+ +--^--++--^--++--^--+ +--^--++--^--++--^--++---^----+
	 |1|3||6|7|8||22|26| |30|39||40|46||51|55| |61|64||70|75||83|86||90|95|99|
	 +---++-----++-----+ +-----++-----++-----+ +-----++-----++-----++--------+
	(Leaf 노드)

	루트,인터널 노드와 Leaf 노드는 다음 속성을 가집니다:

    (1) leaf 페이지의 실제 값과 일치하거나 일치하지 않는 루트와 인터널 노드는 키 값을 저장합니다.
	(2) 키 값과 객체 값은 오름차순으로 저장됩니다. 우리는 (아직) 오름차순/내림차순을 제공하지 않습니다.
    (3) 루트, 노드와 Leaves는 키와 객체의 가변수를 가집니다.
	(4) 루트, 노드와 Leaves는 각각 다른 용량을 가집니다.


	표 3: B+ 트리의 예시

LLIST B+ 트리는 서브레코드의 다른 두 유형을 사용합니다. 내부 트리 노드가 키와 노드 포인터를 가지기 때문에, 그들은 데이터 객체만 가지는 leaf 노드에서 다릅니다.

	(내부 노드 서브 레코드)
	 +------+------+------+
	 | LDT  | Key  |SR Ptr|
	 | CTRL | List | List |
	 | Bin  | Bin  | Bin  |
	 +------+------+------+
	    |      |      |
	    V      V      V
	 +------+------+------+
	 | Ctrl |Entry |Entry |
	 |Struct|Entry |Entry |
	 |Values|Entry |Entry |
	 +------+Entry |Entry |
	        |* * * |* * * |
	        |Entry |Entry |
	        +------+------+

	표 4: 내부 트리 노드 서브레코드 구조


	(Leaf 노드 서브레코드)
	 +------+------+------+
	 | LDT  |Object|Binary|
	 | CTRL | List |Value |
	 | Bin  | Bin  |Array |
	 +------+------+------+
	    |      |      |
	    V      V      V
	 +------+------+------+
	 | Ctrl |Entry |Bits  |
	 |Struct|Entry |Bits  |
	 |Values|Entry |Bits  |
	 +------+Entry |Bits  |
	        |* * * |* * * |
	        |Entry |Bits  |
	        +------+------+

	표 5: Leaf 노드 서브레코드 구조

##### LDT 구성 매개변수

구성 매개변수는 LDT의 행동을 결정합니다.

##### 일반 매개변수

* UserModule : 사용자가 루아 모듈을 생성(또는 처음 쓰기)에서 정의할때, 루아 모듈 이름은 여기에 저장됩니다. 사용자모듈 내부의 기능은 읽기 및 쓰기 작업의 행동을 결정합니다.
* KeyFunction : LMAP에서 사용되지 않음
* KeyType : LMAP에서 사용되지 않음
* StoreMode : StoreMode 설정은 값 리스트나 바이너리 값 어레이인 값을 사용하는 서브레코드의 빈을 결정합니다. 변형 기능에 따라 이것은 상당한 압축 또는 암호화의 장점을 얻을 수 있습니다.
* StoreLimit : 항목(또는 무제한의 경우 0)의 최대 수. 퇴거를 위해 사용됩니다.
* Transform : 저장 전에 루아를 변형
* UnTransform : 바이트에서 루아 형식으로 변형

##### LLIST-특정 매개변수

우리는 설명과 영향과 함께 상당한 구성 매개변수를 나열합니다.

* **트리 수준 값**
* KeyDataType : 키가 KT_ATOMIC 일때, 그들을 직접 비교할 수 있습니다. 하지만 그들이 KT_COMPLEX가 아닐때 그들은 원자 키를 얻기위해 KeyFunction()을 필요로 합니다.
* KeyUnique : 참일때, 단일 키 값에 관한 중복 값은 허용하지 않습니다.
* StoreState : 일반적으로, 모든 LDTs는 첫 ==Threshold== 삽입이 모두 (컴팩리스트의)탑레코드에 머무는 걸 의미하는 "컴팩 모드"로 시작하고, 모든 서브레코드를 발생시키지 않습니다. (threshold + 1) 삽입의 모든 시점에서, 컴팩리스트는 서브레코드 저장소로 전환되고나서 제거됩니다.
* Threshold : "일반" 서브레코드 모드로 바뀌기전에 컴팩 리스트에서 가지는 아이템의 수
* **고정된 길이의 바이트 어레이를 사용할때, 키와 객체의 크기**
* R_KeyByteSize : 키의 고정된 크기(바이트로)
* R_ObjectByteSize : 객체의 고정된 크기(바이트로)
* **탑 노드 트리 루트 디렉토리**
* RootListMax : 키 리스트의 길이(서브레코드 Ptr 리스트는 KL + 1)
* RootByteCountMax : 루트의 키공간에 관한 바이트의 최대 #
* **LLIST 내부 노드 설정**
* NodeListMax : 노드의 아이템의 최대 수(키 + 다이제스트)
* NodeByteCountMax : 노드의 키공간에 관한 바이트의 최대 수
* **LLIST 트리 Leaves(데이터 페이지)**
* LeafListMax : leaf 노드의 아이템의 최대 수
* LeafByteCountMax : leaf의 객체 공간에 관한 바이트의 최대 수

#### 표준리스트 구성 설정

다음 패키지인 **표준리스트**는 "중간" LMAP 인스턴스를 정의하는 구성 매개변수 설정의 예입니다. [LDT 구성](http://www.aerospike.com/docs/guide/ldt_configuration.html)섹션에서, 우리는 여러 설정 옵션을 설명합니다.

	  -- ======================================================================
	  -- 이것은 표준(기본) 설정입니다.
	  -- 패키지 = "StandardList"
	  -- ======================================================================
	    function package.StandardList( ldtMap )

	    -- General Parameters
	    ldtMap[T.M_Transform] = nil;
	    ldtMap[T.M_UnTransform] = nil;
	    ldtMap[T.R_StoreState] = SS_COMPACT; -- "컴팩 모드"로 시작
	    ldtMap[T.M_StoreMode] = SM_LIST; -- 리스트 모드 사용
	    ldtMap[T.R_BinaryStoreSize] = nil; -- 우리가 이것을 사용하지 않을 때 공간을 낭비하지 않음
	    ldtMap[T.M_KeyType] = KT_ATOMIC; -- 원자 키
	    ldtMap[T.R_Threshold] = DEFAULT_THRESHOLD; -- 이것을 많이 삽입후 REDO
	    ldtMap[T.M_KeyFunction] = nil; -- 특별한 주의 업음
	    -- Top Node Tree Root Directory
	    ldtMap[T.R_RootListMax] = 100; -- 키 리스트의 길이(페이지 리스트는 KL + 1)
	    ldtMap[T.R_RootByteCountMax] = 0; -- 루트의 키공간에 관한 최대 바이트

	    -- LLIST 내부 노드 설정
	    ldtMap[T.R_NodeListMax] = 100;  -- 아이템의 최대 # (키 + 다이제스트)
	    ldtMap[T.R_NodeByteCountMax] = 0; -- 바이트의 최대 #

	    -- LLIST 트리 Leaves (데이터 페이지)
	    ldtMap[T.R_LeafListMax] = 100;  -- 아이템의 최대 #
	    ldtMap[T.R_LeafByteCountMax] = 0; -- 데이터 페이지당 바이트의 최대 #

	    return 0;
	  end -- package.StandardList()

### 대규모 맵 인터널

##### 소개

대규모 맵은 값의 쌍을 받아들입니다: 이름/값 쌍. 이름 객체는 숫자나 스트링같은 원자 타입이어야 합니다. 값 객체는 불린을 제외한 모든 루아 타입(숫자,스트링,바이트,리스트,맵)입니다.

#### LDT 컨트롤 구조

사용자가 LMAP 빈을 생성할때, 새로운 LDT 빈은 LDT 데이터 구조와 구성 설정을 가지는 복잡한 LDT 컨트롤 구조를 제공합니다.

	"ldtCtrl"로 알려진 LDT 빈의 내용은 두 맵의 리스트로 구성된 컨트롤 구조입니다. 첫번째 맵(LDT 속성 맵)은 모든 LDTs에서 공통인 필드를 가집니다. 두번째 맵(LDT 컨트롤 맵)은 LDT의 특정 타입에서 지정한 필드를 가지고, LDT 인스턴스에서 지정한 값을 가집니다.

	DB 레코드: 표준 "서브레코드" 모드
	 +----+----+----+---+------+---+-----+
	 |LDT |User|User| o |LMAP  | o |User |
	 |Ctrl|Bin |Bin | o |Bin   | o |Bin  |
	 |    |1   |2   | o |      | o |N    |
	 +----+----+----+---+------+---+-----+
	                      |
	                      V
	                  +==================+
	 ldtCtrl: a list  | LDT Property Map |
	 of two maps:     +------------------+
	 (1) ldtProp      | LDT Control Map  |
	 (2) ldtMap       +==================+

	표 1: LDT 빈과 DB 레코드의 그림 설명

적어도 한 LDT를 포함하는 데이터베이스 레코드는 (숨겨진)특별한 시스템 LDT 컨트롤 빈과 (이 경우에선, LMAP 빈)한 LDT 빈을 가집니다. 대규모 맵 컨트롤 구조(ldtCtrl)는 두 맵의 리스트입니다.

##### LDT 속성 맵

첫번째 맵(LDT 속성 맵)은 모든 LDTs에 공통 필드의 세트입니다:

* ItemCount : LDT의 모든 아이템의 카운트
* Version : 코드 버전
* SubRecCount : LDT의 서브레코드 수
* LdtType : 타입 : 스택,세트,맵,리스트
* BinName : LDT 빈 이름
* Magic : 특별한 상수(확인 위한)
* CreateTime : LDT의 서버 생성 시간
* EsrDigest : ESR의 다이제스트
* RecType : 레코드의 타입

##### LDT 컨트롤 맵

		LMAP 컨트롤 맵
           +============+
           |   LMAP     |
           |   control  |
           +<><><><><><>+
           |  Hash Dir  |
           +VVVVVVVVVVVV|+                          LDR 1
           |Cell Anchor |----------------------->+--------+
           |------------|              LDR 2      |Entry 1 |
           |Cell Anchor |+------------>+--------+ |Entry 2 |
           +------------+              |Entry 1 | |   o    |
           |   o o o    |              |Entry 2 | |   o    |
           |----------- |    LDR N     |   o    | |   o    |
           |Cell Anchor |+->+--------+ |   o    | |Entry n |
           +<><><><><><>+   |Entry 1 | |   o    | +--------+
                            |Entry 2 | |Entry n |
                            |   o    | +--------+
                            |   o    |
                            |   o    |
                            |Entry n |
                            +--------+

	표 2: 대규모 맵 제어 구조

둘째 맵(표 2)은 모든 LDTs에 공통으로 가지는 일부와 대규모 맵에 지정한 일부인 값의 세트를 가집니다:

* 이런 필드는 모든 LDTs에서 동일합니다. 그들은 ldt_common.lua 기능에 의해 관리됩니다:

     * UserModule : 구성과 오버라이드에 관한 사용자의 루아 파일
     * KeyFunction : 키 얻기 기능이 제공되는 사용자
     * KeyType : 키의 타입(항상 LMAP을 위한 원자)
     * StoreMode : 리스트 모드나 바이너리 모드
     * StoreLimit : 퇴거를 위해 사용
     * Transform : 루아를 바이트 형식으로 변형
     * UnTransform : 바이트에서 루아 형식으로 변형

* 이런 필드는 대규모 세트에 고유하고, 그들은 lib_lmap.lua 기능에 의해 관리됩니다:

    * LdrEntryCountMax : LDR의 아이템의 최대 #
    * LdrByteEntrySize : 고정된 객체 크기(바이너리 모드로)
    * LdrByteCountMax : 서브레코드 바이트 제한
    * StoreState : "컴팩트 리스트"나 "일반 해시"
    * TotalCount : 총 삽입 카운트(dels은 카운트 하지않음)
    * HashDirMark : 선형 해시 어디에 있는지 보여줌
    * Threshold : 간단한 리스트에서 해시 테이블로 전환
    * BinListThreshold : Thershold 전환(컴팩 리스트에서 해시 Dir)
    * CompactNameList : 이름 리스트를 컴팩(컴팩 모드)
    * CompactValueList : 값 리스트를 컴팩(컴팩 모드)
    * OverWrite : 주어진 값의 오버라이트 허용
    * HashDirectory : 해시 항목의 디렉토리
    * HashCellMaxList : 전환 전에 셀 앵커의 최대 리스트 크기

이런 컨트롤 맵 항목 각각은 런타임 값(예: 해시디렉토리, 저장상태)이나 구성 매개변수(예: LdrEntyCountMax, Theshold)를 나타냅니다.  

LDT 컨트롤 맵에 해시 디렉토리가 있습니다. 해시 디렉토리의 항목 각각에 "셀 앵커"가 있습니다. 셀 앵커는 다음 값을 가집니다:

* 빈 : 해시 디렉토리 셀에 값이 없음
* 리스트 : 셀에 바로 저장되는 값의 최소 갯수
* 다이제스트 : 서브레코드에 대한 참조
* 트리 : 라딕스 트리의 형태로 구성되는 서브레코드 참조(다이제스트)의 리스트

		 (서브 레코드)
		 +------+------+------+------+
		 | LDT  | Name |Value |Binary|
		 | CTRL | List | List |Value |
		 | Bin  | Bin  | Bin  |Array |
		 +------+------+------+------+
		    |      |      |      |
		    V      V      V      V
		 +------+------+------+------+
		 | Ctrl |Entry |Entry| Bits  |
		 |Struct|Entry |Entry| Bits  |
		 | o o o|Entry |Entry| Bits  |
		 +------+Entry |Entry| Bits  |
		        |o o o |o o o| o o o |
		        |Entry |Entry| Bits  |
		        +------+-----+-------+

		표 3: 서브레코드 구조

서브레코드의 구조는 다음(표 3)과 같습니다. 값은 모두 레코드 빈에 저장됩니다 -- 데이터베이스 "탑-레코드"가 사용되는 같은 방식으로 사용되는

* LDT CTRL 빈 : 주요 LDT Ctrl에 비슷하게 상태 값을 보유
* 네임 리스트 빈 : LMAP 네임의 리스트를 보유
* 값 리스트 빈 : 리스트 모드일때, LMAP 값의 리스트를 보유
* 바이너리 값 어레이 빈 : 바이너리 모드일때, LMAP 값의 바이너리 어레이를 보유

#### LDT 구성 매개변수

구성 매개변수는 LDT의 행동을 결정합니다.

##### 일반 매개변수

* UserModule : 사용자가 생성(또는 처음 쓰기)에 루아 모듈을 정의할때, 그 루아 모듈은 여기에 저장됩니다. 사용자모듈 내부의 기능은 읽기 및 쓰기 기능의 행동을 결정합니다.
* KeyFunction : LMAP에서 사용되지 않음
* KeyType : LMAP에서 사용되지 않음
* StoreMode : StoreMode 설정은 값 리스트나 바이너리 값 어레이인 값에 대해 사용되는 서브레코드의 리스트를 결정합니다. 변형 기능에 따라, 이것은 상당한 압축 또는 암호화의 장점을 얻을 수 있습니다.
* StoreLimit : 아이템의 최대 수(무제한일때 0). 퇴거를 위해 사용
* Transform : 저장전에 루아 변형
* UnTransform : 바이트에서 루아 형식으로 변형

##### LMAP 특정 매개변수

우리는 그들의 설명과 영향과 함께 상당한 구성 매개변수를 나열합니다.

* LdrEntryCountMax : 각 서브레코드는 값의 리스트와 이름의 리스트를 가집니다. 서브레코드 오버플로우를 막기위해서, 리스트의 크기는 캡되어야 합니다. 평균 객체 크기를 고려해볼때, 값은 개별 서브레코드가 가져오는 양(대략)을 결정합니다.
* LdrByteCountMax : "바이너리 모드"일때, 서브레코드 바이트 어레이에 대한 최대 용량(바이트로)
* LdrByteEntrySize : (값 리스트 대신에 사용되는 **바이너리 값 어레이**를 의미하는)"바이너리 모드"일때, 이 값은 객체의 고정된 크기(바이트로)를 보여줍니다. 바이너리 값 어레이가 "EntrySize" 증가의 리스트로 접근되기 때문에 바이너리 객체는 고정된 크기여야 합니다.
* StoreState : 일반적으로, 모든 LDTs는 처음 ==Threshold== 삽입 모두 (컴팩리스트의)탑레코드에 머무는 걸 의미하는 "컴팩 모드"로 시작하고, 모든 서브레코드를 발생시키지 않습니다. (Threshold + 1) 삽입의 시점에서, 컴팩리스트는 서브레코드 저장소로 전환되고나서 제거됩니다.
* Threshold : "일반" 서브레코드 모드로 전환되기 전에 컴팩 리스트에서 보유하는 아이템의 수.
* OverWrite : 우리가 ==put()== 호출에 의해 오버라이트된 기존 값을 허용하는 경우에 따라 'T'(참) 또는 'F'(거짓) 값으로 오버라이트
* HashCellMaxList : 해시 디렉토리 셀에서, 우리가 셀을 서브레코드로 변환하기전에 우리는 (리스트의)셀의 아이템의 적은 수를 유지하는 옵션을 허용합니다. 이 값은 그 리스트의 최대 크기를 결정합니다. 너무 많은 대규모 객체(여러 셀 이상)가 레코드 저장 오버플로우를 야기하도록 이 리스트 크기를 설정할때 저장중인 객체의 평균 크기를 고려해야 합니다.

#### 표준List 구성 설정

다음 패키지인 **표준List**는 "중간" LMAP 인스턴스를 정의하는 설정 매개변수의 세트의 예입니다. [LDT 구성](http://www.aerospike.com/docs/guide/ldt_configuration.html)섹션에서, 우리는 여러 설정 옵션을 설명합니다.

	-- ======================================================================
	-- 이것은 표준 (기본) 설정 입니다.
	-- 패키지 = "StandardList"
	-- 서브레코드 디자인, 리스트 모드, 풀 객체 비교, 50,000 객체 제한
    -- ======================================================================
	function package.StandardList( ldtMap )
	  ldtMap[T.M_StoreMode]             = SM_LIST; -- 리스트 모드 사용
	  ldtMap[T.M_StoreLimit]            = 50000; -- 기본 최대 용량 : 50,000
	  ldtMap[T.M_Transform]             = nil; -- Std 리스트에서 사용되지 않음
	  ldtMap[T.M_UnTransform]           = nil; -- Std 리스트에서 사용되지 않음
	  ldtMap[T.M_StoreState]            = SS_COMPACT; -- "컴팩 모드"로 시작
	  ldtMap[T.M_BinaryStoreSize]       = nil; -- Std 리스트에서 사용되지 않음
	  ldtMap[T.M_Modulo]                = DEFAULT_DISTRIB; -- 해시 Dir 크기
	  ldtMap[T.M_ThreshHold]            = DEFAULT_THRESHHOLD; -- # 이후에 재해시
	  ldtMap[T.M_LdrEntryCountMax]      = 100; -- 서브레코드당 100 객체
	  ldtMap[T.M_LdrByteEntrySize]      = nil; -- 여기서 사용하지 않음
	  ldtMap[T.M_LdrByteCountMax]       = nil; -- 여기서 사용하지 않음
 	 ldtMap[T.M_HashType]              = HT_STATIC; -- 스태틱 해시 Dir 사용
	  ldtMap[T.M_BinListThreshold]      = DEFAULT_BINLIST_THRESHOLD;
	end -- package.StandardList()

### 대규모 세트 인터널

##### 소개

대규모 세트는 불린을 제외한 모든 루아 타입(숫자,스트링,바이트,리스트,맵)의 객체를 받아들입니다.

#### LDT 컨트롤 구조

사용자가 LSET 빈을 생성할때, 새로운 LDT 빈은 LDT 데이터 구조와 구성 설정을 가지는 복잡한 LDT 제어 구조(표 1과 2)를 제공합니다.

	"ldtCtrl"로 알려진 LDT 빈의 내용은 두 맵의 리스트로 구성된 제어 구조입니다. 첫번째 맵(LDT 속성 맵)은 모든 LDTs에서 동일한 필드를 가집니다. 두번째 맵(LDT 컨트롤 맵)은 LDT의 특정 타이에 지정하는 필드와 LDT 인스턴스에서 지정하는 값을 가집니다.

	DB 레코드: 표준 "서브레코드" 모드
	 +----+----+----+---+------+---+-----+
	 |LDT |User|User| o |LSET  | o |User |
	 |Ctrl|Bin |Bin | o |Bin   | o |Bin  |
	 |    |1   |2   | o |      | o |N    |
	 +----+----+----+---+------+---+-----+
	                      |
	                      V
	                  +==================+
	 ldtCtrl: a list  | LDT Property Map |
	 of two maps:     +------------------+
	 (1) ldtProp      | LDT Control Map  |
	 (2) ldtMap       +==================+

	표 1: LDT 빈과 DB 레코드의 그림 설명

적어도 한 LDT를 포함하는 데이터베이스 레코드는 (숨겨진)특별한 시스템 LDT 컨트롤 빈과 한 LDT 빈(이 경우엔, LSET 빈)을 가집니다. 대규모 세트 컨트롤 구조(ldtCtrl)는 두 맵의 리스트입니다.

##### LDT 속성 맵

첫번째 맵(LDT 속성 맵)은 모든 LDTs에 동일한 필드의 세트입니다:

* ItemCount : LDT의 모든 아이템의 수
* Version : 코드 버전
* SubRecCount : LDT의 서브레코드의 수
* LdtType : 타입: 스택,세트,맵,리스트
* BinName : LDT 빈 이름
* Magic : 특별한 상수(확인을 위한)
* CreateTime : LDT의 서버 생성 시간
* EsrDigest : ESR의 다이제스트
* RecType : 레코드의 타입

##### LDT 컨트롤 맵

			 LSET 컨트롤 맵
	         +============+
             |   LSET     |
             |   control  |
             +<><><><><><>+
             |  Hash Dir  |
             +VVVVVVVVVVVV|+                          LDR 1
             |Cell Anchor |----------------------->+--------+
             |------------|              LDR 2      |Entry 1 |
             |Cell Anchor |+------------>+--------+ |Entry 2 |
             +------------+              |Entry 1 | |   o    |
             |   o o o    |              |Entry 2 | |   o    |
             |----------- |    LDR N     |   o    | |   o    |
             |Cell Anchor |+->+--------+ |   o    | |Entry n |
             +<><><><><><>+   |Entry 1 | |   o    | +--------+
                              |Entry 2 | |Entry n |
                              |   o    | +--------+
                              |   o    |
                              |   o    |
                              |Entry n |
                              +--------+

		표 2: 대규모 세트 컨트롤 구조

두번째 맵(표 2)은 모든 LDTs에 동일한 값의 세트와 대규모 세트에서 지정한 값의 세트를 가집니다:

* 이런 필드는 모든 LDTs에서 동일합니다. 그들은 ldt_common.lua 기능에 의해 관리됩니다:

   * UserModule : 구성과 오버라이드에 관한 사용자의 루아 파일
   * KeyFunction : 키 얻기 기능이 지원되는 사용자
   * KeyType : 키의 타입(항상 LSET에 관한 원자)
   * StoreMode : 리스트 모드나 바이너리 모드
   * StoreLimit : 퇴거를 위해 사용
   * Transform : 루아에서 바이트 형식으로 변형
   * UnTransform : 바이트에서 루아 형식으로 변형

* 이런 필드는 대규모 세트에 고유하고, 그들은 lib_lset.lua 기능에 의해 관리됩니다:

   * LdrEntryCountMax : LDR의 아이템의 최대 #
   * LdrByteEntrySize : 고정된 객체 크기(바이너리 모드에서)
   * LdrByteCountMax : 서브레코드 바이트 제한
   * StoreState : "컴팩 리스트"나 "정규 해시"
   * TotalCount : 총 삽입 카운트(dels는 카운트하지 않음)
   * HashDirSize : 현재 해시 디렉토리 크기 보여주기
   * HashDirMark : 선형 해시에 있는 위치 보여주기
   * Threshold : 단순 리스트에서 해시 테이블로 전환
   * BinListThreshold : Threshold 전환 (컴팩 리스트에서 해시 디렉토리)
   * CompactNameList : 네임 리스트 컴팩 (컴팩 모드)
   * CompactValueList : 값 리스트 컴팩 (컴팩 모드)
   * OverWrite : 주어진 값의 오버라이트 허용
   * HashDirectory : 해시 항목의 디렉토리
   * HashCellMaxList : 전환 전에 셀 앵커의 최대 리스트 크기

이런 컨트롤 맵 항목의 각각은 런타임 값(예: 해시디렉토리, 저장상태) 또는 구성 매개변수(예: LdrEntryCountMax, Threshold)를 나타냅니다.  

LDT 컨트롤 맵에 해시 디렉토리가 있습니다. 해시 디렉토리의 항목 각각에 "셀 앵커"가 있습니다. 셀 앵커는 다음 값을 가질 수 있습니다:

   * 빈 : 해시 디렉토리 셀에 값이 없음
   * 리스트 : 셀에 바로 저장되는 값의 적은 수
   * 다이제스트 : 서브레코드에 대한 참조
   * 트리 : 라딕스 트리의 형식으로 구성된 서브레코드 참고의 리스트

			(서브 레코드)
		 +------+------+------+------+
		 | LDT  | Name |Value |Binary|
		 | CTRL | List | List |Value |
		 | Bin  | Bin  | Bin  |Array |
		 +------+------+------+------+
		    |      |      |      |
		    V      V      V      V
		 +------+------+------+------+
		 | Ctrl |Entry |Entry| Bits  |
		 |Struct|Entry |Entry| Bits  |
		 | o o o|Entry |Entry| Bits  |
		 +------+Entry |Entry| Bits  |
		        |o o o |o o o| o o o |
		        |Entry |Entry| Bits  |
		        +------+-----+-------+

		표 3: 서브레코드 구조

서브레코드의 구조는 다음(표 3)과 같습니다. 값은 모두 레코드 빈에 저장됩니다 -- 데이터베이스 "탑레코드"가 사용되는 동일한 방식으로 사용

* LDT CTRL 빈 : 주요 LDT Ctrl에 비슷한 상태 값을 유지
* 값 리스트 빈 : 리스트 모드일때, LSET 값의 리스트를 유지
* 바이너리 값 어레이 빈 : 바이너리 모드일때, LSET 값의 바이너리 어레이를 유지

#### LDT 구성 매개변수

구성 매개변수는 LDT의 행동을 결정합니다.

#### 일반 매개변수

* UserModule : 사용자가 생성(또는 처음 쓰기)에 루아 모듈을 정의할때, 그 루아 모듈 이름은 여기에 저장됩니다. 사용자모듈의 내부 기능은 읽기 및 쓰기 작업의 행동을 결정합니다.
* KeyFunction : "고유_식별자()" 기능은 여기에 저장됩니다. 이것은 전체 객체보다 해시 기능에 적용되는 고유 식별자로 사용하는 LSET 객체의 서브세트를 얻는 KeyFunction에 비슷하게 기능을 사용하는 LSET에 고유한 개념입니다.
* KeyType : LSET에서 사용하지 않음
* StoreMode : StoreMode 설정은 값 리스트나 바이너리 값 어레이인 값에 대해 사용되는 서브레코드의 리스트를 결정합니다. 변형 기능에 따라, 이것은 상당한 압축 또는 암호화의 장점을 얻을 수 있습니다.
* StoreLimit : 아이템의 최대 수(또는 제한이 없을때 0), 퇴거를 위해 사용
* Transform : 저장전에 루아를 변경
* UnTransform : 바이트에서 루아 형식으로 변형

##### LSET 특정 매개변수

우리는 설명과 영향과 함께 상당한 구성 매개변수를 나열합니다.

* LdrEntryCountMax : 서브레코드 각각은 이름의 리스트와 값의 리스트를 가집니다. 서브레코드 오버플로우를 예방하기 위해서, 리스트의 크기는 캡되야 합니다. 평균 객체 크기를 고려하면, 이 값은 개별 레코드가 얻는 양(대략적으로)을 결정합니다.
* LdrByteCountMax : "바이너리 모드"일때, 서브레코드 바이트 어레이에 관한 최대 용량(바이트로)
* LdrByteEntrySize : (**값 리스트** 대신에 사용되는 **바이너리 값 어레이**를 의미하는)"바이너리 모드"일때, 이 값은 객체의 고정된 길이를 보여줍니다. 바이너리 값 어레이가 "EntrySize" 증가의 리스트로 접근되기 때문에 바이너리 객체는 고정된 길이여야 합니다.
* StoreState : 일반적으로, 모든 LDTs는 처음 ==Threshold== 삽입 모두 (컴팩리스트의)탑레코드에 머무는 걸 의미하는 "컴팩 모드"로 시작하고, 모든 서브레코드를 발생시키지 않습니다. (Threshold + 1) 삽입의 시점에서, 컴팩리스트는 서브레코드 저장소로 전환되고나서 제거됩니다.
* Threshold : "일반" 서브레코드 모드로 전환되기 전에 컴팩 리스트에서 보유하는 아이템의 수.
* OverWrite : 우리가 ==put()== 호출에 의해 오버라이트된 기존 값을 허용하는 경우에 따라 'T'(참) 또는 'F'(거짓) 값으로 오버라이트
* HashCellMaxList : 해시 디렉토리 셀에서, 우리가 셀을 서브레코드로 변환하기전에 우리는 (리스트의)셀의 아이템의 적은 수를 유지하는 옵션을 허용합니다. 이 값은 그 리스트의 최대 크기를 결정합니다. 너무 많은 대규모 객체(여러 셀 이상)가 레코드 저장 오버플로우를 야기하도록 이 리스트 크기를 설정할때 저장중인 객체의 평균 크기를 고려해야 합니다.

#### 표준List 구성 설정

다음 패키지인 **표준List**는 "중간" LMAP 인스턴스를 정의하는 설정 매개변수의 세트의 예입니다. [LDT 구성](http://www.aerospike.com/docs/guide/ldt_configuration.html)섹션에서, 우리는 여러 설정 옵션을 설명합니다.

	-- ======================================================================
	-- 이것은 표준(기본) 설정입니다.
	-- 패키지 = "StandardList"
	-- 서브레코드 디자인, 리스트 모드, 풀 객체 비교, 50,000 객체 제한
	-- ======================================================================
	function package.StandardList( ldtMap )
	  ldtMap[T.M_StoreMode]             = SM_LIST; -- 리스트 모드 사용
	  ldtMap[T.M_StoreLimit]            = 50000; -- 기본 최대 용량: 50,000
	  ldtMap[T.M_Transform]             = nil; -- Std 리스트에서 사용하지 않음
	  ldtMap[T.M_UnTransform]           = nil; -- Std 리스트에서 사용하지 않음
	  ldtMap[T.M_StoreState]            = SS_COMPACT; -- "컴팩 모드"로 시작
	  ldtMap[T.M_BinaryStoreSize]       = nil; -- Std 리스트에서 사용하지 않음
	  ldtMap[T.M_Modulo]                = DEFAULT_DISTRIB; -- 해시 디렉토리 크기
	  ldtMap[T.M_ThreshHold]            = DEFAULT_THRESHHOLD; -- # 후에 리해시
	  ldtMap[T.M_LdrEntryCountMax]      = 100; -- 서브레코드당 100 객체
	  ldtMap[T.M_LdrByteEntrySize]      = nil; -- 여기에서 안씀
	  ldtMap[T.M_LdrByteCountMax]       = nil; -- 여기에서 안씀
	  ldtMap[T.M_HashType]              = HT_STATIC; -- Static Hash Dir 사용
	  ldtMap[T.M_BinListThreshold]      = DEFAULT_BINLIST_THRESHOLD;
	end -- package.StandardList()

### 대규모 스택 인터널

##### 소개

대규모 스택은 에어로스파이크 객체의 모든 타입을 받아들입니다: 스트링,숫자,리스트,맵,바이트. push() 기능은 스택에 LIFO 데이터 구조로 객체를 추가합니다. 실질적으로, 스택은 저종소의 다른 3가지 타입으로 구현됩니다. ("핫 리스트"로 알려진 )스택의 탑은 빠른 접근과 추가적인 I/Os 필요없이 제공하는 탑 레코드에 바로 유지되는 요소의 리스트입니다. ("웜 리스트"로 알려진) 스택의 중간은 데이터 페이지(서브레코드)를 참조하는 서브레코드 포인터(aka 다이제스트)의 목록입니다. 그래서, 적절한 서브레코드 포인트에 관한 접근은 즉각적이고, 데이터 접근은 한 I/O 방식입니다. ("콜드 리스트"로 알려진) 스택의 바닥은  데이터 페이지를 가리키는 디렉토리 페이지의 연관된 리스트입니다. ㅡ래서, 콜드 리스트의 데이터는 두 I/Os 방식입니다 -- 전체 스택의 스캔이 기본적으로 데이터 페이지 읽기의 모든곳에 콜드 디렉토리 I/O로 상환되더라도, 이것은 2 I/Os로 콜드 리스트 읽기의 생각을 속입니다.

#### LDT 컨트롤 구조

사용자가 LSET 빈을 생성할때, 새로운 LDT 빈은 LDT 데이터 구조와 구성 설정을 가지는 복잡한 LDT 제어 구조(표 1과 2)를 제공합니다.

	"ldtCtrl"로 알려진 LDT 빈의 내용은 두 맵의 리스트로 구성된 컨트롤 구조입니다. 첫번째 맵(LDT 속성 맵)은 모든 LDTs에서 공통인 필드를 가집니다. 두번째 맵(LDT 컨트롤 맵)은 LDT의 특정 타입에서 지정한 필드를 가지고, LDT 인스턴스에서 지정한 값을 가집니다.

	 DB 레코드: 표준 "서브레코드" 모드
	 +----+----+----+---+------+---+-----+
	 |LDT |User|User| o |LSTACK| o |User |
	 |Ctrl|Bin |Bin | o |Bin   | o |Bin  |
	 |    |1   |2   | o |      | o |N    |
	 +----+----+----+---+------+---+-----+
	                      |
	                      V
	                  +==================+
	 ldtCtrl: a list  | LDT Property Map |
	 of two maps:     +------------------+
	 (1) ldtProp      | LDT Control Map  |
	 (2) ldtMap       +==================+

	표 1: LDT 빈과 DB 레코드의 그림 설명

적어도 한 LDT를 포함하는 데이터베이스 레코드는 (숨겨진)특별한 시스템 LDT 컨트롤 빈과 한 LDT 빈(이 경우엔, LSET 빈)을 가집니다. 대규모 세트 컨트롤 구조(ldtCtrl)는 두 맵의 리스트입니다.

##### LDT 속성 맵

첫번째 맵(LDT 속성 맵)은 모든 LDTs에 동일한 필드의 세트입니다:

* ItemCount : LDT의 모든 아이템의 수
* Version : 코드 버전
* SubRecCount : LDT의 서브레코드의 수
* LdtType : 타입: 스택,세트,맵,리스트
* BinName : LDT 빈 이름
* Magic : 특별한 상수(확인을 위한)
* CreateTime : LDT의 서버 생성 시간
* EsrDigest : ESR의 다이제스트
* RecType : 레코드의 타입

##### LDT 컨트롤 맵

	 LSTACK 컨트롤 맵
    +-------------------+
    | LSO 컨트롤 정보     | About 20 different values kept in Ctrl info
    |...................|
    |...................|< Oldest ................... Newest>
    +-------------------+========+========+=======+=========+
    |<Hot Entry Cache>  | Entry 1| Entry 2| o o o | Entry n |
    +-------------------+========+========+=======+=========+
    |...................|HotCache 항목은 레코드에 바로 저장됩니다.
    |...................|
    |...................|WarmCache 다이제스트는 레코드에 바로 저장됩니다.
    |...................|< Oldest ................... Newest>
    +-------------------+========+========+=======+=========+
    |<Warm Digest List> |Digest 1|Digest 2| o o o | Digest n|
    +-------------------+===v====+===v====+=======+====v====+
	 +-<@>Cold Dir List Head|   |        |                 |
	 |  +-------------------+   |        |                 |
	 |                    +-----+    +---+      +----------+
	 |                    |          |          |     Warm Data(WD)
	 |                    |          |          |      WD Rec N
	 |                    |          |          +---=>+--------+
	 |                    |          |     WD Rec 2   |Entry 1 |
	 |                    |          +---=>+--------+ |Entry 2 |
	 |                    |      WD Rec 1  |Entry 1 | |   o    |
	 |                    +---=>+--------+ |Entry 2 | |   o    |
	 |                          |Entry 1 | |   o    | |   o    |
	 |                          |Entry 2 | |   o    | |Entry n |
	 |                          |   o    | |   o    | +--------+
	 |                          |   o    | |Entry n |
	 |                          |   o    | +--------+
	 |                          |Entry n | "LDR" (LSTACK Data Record) Pages
	 |                          +--------+ [Warm Data (LDR) Chunks]
	 |
	 |
	 |                           <Newest Dir............Oldest Dir>
	 +-------------------------->+-----+->+-----+->+-----+-->+-----+-+
	(DirRec Pages DoubleLink)<-+Rec  |<-+Rec  |<-+Rec  | <-+Rec  | V
	   The cold dir is a linked  |Chunk|  |Chunk|  |Chunk| o |Chunk|
	   list of dir pages that    |Dir  |  |Dir  |  |Rec  | o |Dir  |
	   point to LSO Data Records +-----+  +-----+  +-----+   +-----+
	   that hold the actual cold [][]:[]  [][]:[]  [][]:[]   [][]:[]
	   data (cold chunks).       +-----+  +-----+  +-----+   +-----+
                              | |  |   | |  |   | |  |    | |  |
	   LDRS (per dir) have age:   | |  V   | |  V   | |  V    | |  V
	   <Oldest LDR .. Newest LDR> | |::+--+| |::+--+| |::+--+ | |::+--+
	   As "Warm Data" ages out    | |::|Cn|| |::|Cn|| |::|Cn| | |::|Cn|
	   of the Warm Dir List, the  | V::+--+| V::+--+| V::+--+ | V::+--+
	   LDRs transfer out of the   | +--+   | +--+   | +--+    | +--+
	   Warm Directory and into    | |C2|   | |C2|   | |C2|    | |C2|
	   the cold directory.        V +--+   V +--+   V +--+    V +--+
	                              +--+     +--+     +--+      +--+
	                              |C1|     |C1|     |C1|      |C1|
                                  +--+     +--+     +--+      +--+
                                   A        A        A         A
                                   |        |        |         |
        [콜드 데이터 (LDR) 청크]  ---+--------+--------+----------+

		표 2: 대규모 스택 컨트롤 구조

두번째 맵(표 2)은 모든 LDTs에 동일한 값의 세트와 대규모 세트에서 지정한 값의 세트를 가집니다:

* 이런 필드는 모든 LDTs에 공통입니다. 그들은 ldt_common.lua 기능에 의해 관리됩니다:

	* UserModule : 사용자가 생성(또는 처음 쓰기)에 루아 모듈을 정의할때, 그 루아 모듈은 여기에 저장됩니다. 사용자모듈 내부의 기능은 읽기 및 쓰기 기능의 행동을 결정합니다.
	* KeyFunction : LMAP에서 사용되지 않음
	* KeyType : LMAP에서 사용되지 않음
	* StoreMode : StoreMode 설정은 값 리스트나 바이너리 값 어레이인 값에 대해 사용되는 서브레코드의 리스트를 결정합니다. 변형 기능에 따라, 이것은 상당한 압축 또는 암호화의 장점을 얻을 수 있습니다.
	* StoreLimit : 아이템의 최대 수(무제한일때 0). 퇴거를 위해 사용
	* Transform : 저장전에 루아 변형
	* UnTransform : 바이트에서 루아 형식으로 변형

이런 필드는 대규모 스택에 고유하고, 그들은 lib_lstack.lua 기능에서 관리됩니다:

* 일반 LSO 팜:

    * StoreMode : 리스트 모드나 바이너리 모드
    * Transform : 저장전에 객체를 변환하는 UDF
    * UnTansform : 저장후에 객체를 변환하는 UDF

* LSO 데이터 레코드(LDR) 청크 설정: "청크 생성"으로 통과

   * LdrEntryCountMax : LDR에 아이템의 최대 수(리스트 모드)
   * LdrByteEntrySize : 고정된 크기 바이트 엔트리의 바이트 크기
   * LdrByteCountMax : LDR의 바이트의 최대 수(바이너리 모드)

* Hot 엔트리 리스트 설정: 사용자 엔트리의 리스트

   * HotListMax : 우리가 전송할때 리스트의 최대 수
   * HotListTransfer : 동시에 전송하는 시간

* 웜 다이제스트 리스트 설정: LSO 데이터 레코드의 다이제스트의 리스트

   * WarmListMax : 웜 데이터 레코드 청크의 최대 수
   * WarmListTransfer : 콜드 저장소로 전송하는 웜 데이터 ㄹ코드의 수

* 콜드 디렉토리 리스트 설정: 디렉토리 페이지의 리스트

   * ColdListMax : 콜드 디렉토리 노드의 리스트 항목 수
   * ColdDirRecMax : 콜드 디렉토리 레코드의 최대 수

스택,더 길거나 더 짧은 리스트에 저장되는 객체가 나타나는 경우에 타입에 따라  

이 트레이드오프는 [LDT 구성](http://www.aerospike.com/docs/guide/ldt_configuration.html)섹션에서 설명합니다.

	 (Sub-Record)
	 +------+------+------+
	 | LDT  |Value |Binary|
	 | CTRL | List |Value |
	 | Bin  | Bin  |Array |
	 +------+------+------+
	    |      |      |
	    V      V      V
	 +------+------+-----+
	 | Ctrl |Entry |Bits |
	 |Struct|Entry |Bits |
	 | o o o|Entry |Bits |
	 +------+Entry |Bits |
	        |* * * |* * *|
	        |Entry |Bits |
	        +------+-----+

		표 3: 서브레코드 구조

##### 스택 push 작업

lstack의 push() 기능은 다음같이 작동합니다:

* 새로운 아이템은 반대로 유지되는 핫 리스트에 추가됩니다.
* 핫 리스트가 풀일때, 핫 리스트에 추가되기전에, ("HotListTransfer" 양으로 언급된)핫 리스트의 부분은 웜 리스트에 전송됩니다. 일반적으로, 우리는 핫 리스크 크기의 반으로 "HotListTransfer"을 설정합니다. 그래서, 핫 리스트의 크기가 100일때, 전송량은 50 입니다. 그것은 49에서 50 삽입이 탑레코드만 건들고 추가 I/O가 발생하지 않습니다. 1에서 50 삽입은 삽입의 결과로 보조 I/O를 일으킵니다.
* 핫리스트,웜 리스트 같이 반대로 유지되고, 데이터 항목 대신에 서브레코드 포인터를 관리하는 걸 기대합니다.
* 웜리스트에 추가되기전에 웜 리스트가 풀일때, 웜 리스트의 부분은 콜드 리스트에 전송됩니다. 일반적으로, 우리는 웜리스트의 반으로 "WarmListTransfer"을 설정합니다. 그래서, 웜리스트의 기본 크기가 100일때, 우리는 페이지 포인터의 50 서브레코드 가치를 콜드 리스트 디렉토리 헤드의 헤드에 전송합니다.
* 콜드 리스트는 일반 순서로 유지되는 디렉토리 페이지의 연관된 리스트입니다.
